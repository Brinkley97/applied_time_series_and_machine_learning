{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a93950b4",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron Model\n",
    "\n",
    "- BOOK: [Predict the Future with MLPs, CNNs and LSTMs in Python](https://machinelearningmastery.com/deep-learning-for-time-series-forecasting/) by Jason Brownlee\n",
    "- NOTES: [TS -> ML split function](https://detraviousjbrinkley.notion.site/TS-ML-split-function-9ab51cbb49d244aa8b4ab434d009f8a7?pvs=4) by Detravious J.B. \n",
    "    - See for Forecast vs Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2335e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../framework_for_time_series_data/tslearn/'))\n",
    "from ml_models import MLP\n",
    "from ts_models import EvaluationMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86d7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = [10, 20, 30, 40, 50, 60, 70, 80, 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45624d9b",
   "metadata": {},
   "source": [
    "# Book's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f03ecb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out): \n",
    "    X, y = list(), list() \n",
    "    for i in range(len(sequence)): \n",
    "        # find the end of this pattern \n",
    "        end_ix = i + n_steps_in \n",
    "        out_end_ix = end_ix + n_steps_out \n",
    "        # check if we are beyond the sequence \n",
    "        if out_end_ix > len(sequence): \n",
    "            break\n",
    "        # gather input and output parts of the pattern \n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix] \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc84b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_sequence(observations, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a17514bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20, 30],\n",
       "       [20, 30, 40],\n",
       "       [30, 40, 50],\n",
       "       [40, 50, 60]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9dd5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 50, 60],\n",
       "       [50, 60, 70],\n",
       "       [60, 70, 80],\n",
       "       [70, 80, 90]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0e431",
   "metadata": {},
   "source": [
    "# My implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e506fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_uts_sequence_to_sml(uts_observations, prior_observations, forecasting_step):\n",
    "    \"\"\"Splits a given UTS into multiple input rows where each input row has a specified number of timestamps and the output is a single timestamp.\n",
    "    \n",
    "    Parameters:\n",
    "    uts_observations -- 1D np array (of UTS data to transform to SML data with size  b rows/length x 1 dimension)\n",
    "    prior_observations -- py int (of all observations before we get to where we want to start making the predictions)\n",
    "    forecasting_step -- py int (of how far out to forecast, 1 only the next timestamp, 2 the next two timestamps, ... n the next n timestamps)\n",
    "    \n",
    "    Return:\n",
    "    agg.values -- np array (of new sml data)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(uts_observations)\n",
    "    cols = list()\n",
    "    \n",
    "    lag_col_names = []\n",
    "    count_lag = 0\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for prior_observation in range(prior_observations, 0, -1):\n",
    "        # print(\"prior_observation: \", prior_observation)\n",
    "        cols.append(df.shift(prior_observation))\n",
    "        new_col_name = \"t - \" + str(prior_observation)\n",
    "        # print(new_col_name)\n",
    "        lag_col_names.append(new_col_name)\n",
    "        \n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, forecasting_step):\n",
    "        cols.append(df.shift(-i))\n",
    "        # print(f\"t + {i}\")\n",
    "        if i == 0:\n",
    "            new_col_name = f\"t\"\n",
    "        else:\n",
    "            new_col_name = f\"t + {i}\"\n",
    "        # print(new_col_name)\n",
    "        lag_col_names.append(new_col_name)\n",
    "        \n",
    "        # put it all together\n",
    "        uts_sml_df = pd.concat(cols, axis=1) \n",
    "        uts_sml_df.columns=[lag_col_names]\n",
    "        # drop rows with NaN values\n",
    "        uts_sml_df.dropna(inplace=True)\n",
    "    \n",
    "    # print(uts_sml_df)\n",
    "    \n",
    "    # colums to use to make prediction for last col\n",
    "    X_train = uts_sml_df.iloc[:, 0: -1]\n",
    "    \n",
    "    # last column\n",
    "    y_train = uts_sml_df.iloc[:, [-1]]\n",
    "    return uts_sml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c1f6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 3\n",
    "output_size = 2\n",
    "converted_seq_df = convert_uts_sequence_to_sml(observations, n_steps, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9cf9a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 3</th>\n",
       "      <th>t - 2</th>\n",
       "      <th>t - 1</th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 3 t - 2 t - 1   t t + 1\n",
       "3  10.0  20.0  30.0  40  50.0\n",
       "4  20.0  30.0  40.0  50  60.0\n",
       "5  30.0  40.0  50.0  60  70.0\n",
       "6  40.0  50.0  60.0  70  80.0\n",
       "7  50.0  60.0  70.0  80  90.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_seq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4216c4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 3</th>\n",
       "      <th>t - 2</th>\n",
       "      <th>t - 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 3 t - 2 t - 1\n",
       "3  10.0  20.0  30.0\n",
       "4  20.0  30.0  40.0\n",
       "5  30.0  40.0  50.0\n",
       "6  40.0  50.0  60.0\n",
       "7  50.0  60.0  70.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_X_train_df = converted_seq_df.iloc[:, :n_steps]\n",
    "forecast_X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3030b03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t t + 1\n",
       "3  40  50.0\n",
       "4  50  60.0\n",
       "5  60  70.0\n",
       "6  70  80.0\n",
       "7  80  90.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_y_train_df = converted_seq_df.iloc[:, -output_size:]\n",
    "forecast_y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b13497cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 1</th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70.0</td>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 1   t t + 1\n",
       "7  70.0  80  90.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_X_test_df = converted_seq_df.iloc[[-1], -n_steps:]\n",
    "forecast_X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d3307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 3</th>\n",
       "      <th>t - 2</th>\n",
       "      <th>t - 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 3 t - 2 t - 1\n",
       "3  10.0  20.0  30.0\n",
       "4  20.0  30.0  40.0\n",
       "5  30.0  40.0  50.0\n",
       "6  40.0  50.0  60.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X_train_df = converted_seq_df.iloc[:-1, :n_steps]\n",
    "predict_X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c2da8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t t + 1\n",
       "3  40  50.0\n",
       "4  50  60.0\n",
       "5  60  70.0\n",
       "6  70  80.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_train_df = converted_seq_df.iloc[:-1, -output_size:]\n",
    "predict_y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da43b0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 1</th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 1   t t + 1\n",
       "5  50.0  60  70.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X_test_df = converted_seq_df.iloc[[-n_steps], -n_steps:]\n",
    "predict_X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c11b99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t t + 1\n",
       "7  80  90.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_test_df = converted_seq_df.iloc[[-1], -output_size:]\n",
    "predict_y_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31c65e",
   "metadata": {},
   "source": [
    "# Book's implementation\n",
    "- Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c3248",
   "metadata": {},
   "source": [
    "## Forecast model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2586bf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 19:26:51.304405: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-13 19:26:58.971041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "\n",
    "forecast_model = Sequential() \n",
    "forecast_model.add(Dense(100, activation='relu' , input_dim=n_steps)) \n",
    "forecast_model.add(Dense(output_size)) \n",
    "forecast_model.compile(optimizer='adam' , loss='mse') \n",
    "\n",
    "predict_model = Sequential() \n",
    "predict_model.add(Dense(100, activation='relu' , input_dim=n_steps)) \n",
    "predict_model.add(Dense(output_size)) \n",
    "predict_model.compile(optimizer='adam' , loss='mse') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a7c14ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x199ab60d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model \n",
    "forecast_model.fit(forecast_X_train_df, forecast_y_train_df, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e475fd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[70., 80., 90.]]), 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_X_test = np.array(forecast_X_test_df)\n",
    "forecast_X_test, forecast_X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90b9f8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70., 80., 90.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = forecast_X_test.reshape((forecast_X_test.shape[0]), n_steps)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a0262d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[104.40981, 115.59957]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts = forecast_model.predict(X_test, verbose=0)\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ff7db",
   "metadata": {},
   "source": [
    "## Predict model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a17a48c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19a259430>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model.fit(predict_X_train_df, predict_y_train_df, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aea502e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[50., 60., 70.]]), 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X_test = np.array(predict_X_test_df)\n",
    "predict_X_test, predict_X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ece813e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70., 80., 90.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X_test = forecast_X_test.reshape((predict_X_test.shape[0]), n_steps)\n",
    "predict_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cabd8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.472755, 45.740124]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_model_predictions = predict_model.predict(predict_X_test, verbose=0)\n",
    "book_model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7afabf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t t + 1\n",
       "7  80  90.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67322618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 2466.079\n"
     ]
    }
   ],
   "source": [
    "EvaluationMetric.eval_mse(predict_y_test_df, book_model_predictions, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ac988a",
   "metadata": {},
   "source": [
    "## My implementation\n",
    "\n",
    "- Using my TSLearn library\n",
    "\n",
    "### Prediction model\n",
    "\n",
    "- Interpolation of in sample values \n",
    "- Use `50, 60, 70`, so X_test\n",
    "- True predictions `80, 90`, so y_test\n",
    "\n",
    "### Forecast model\n",
    "\n",
    "- Extrapolation of future values `\n",
    "- Use `70, 80, 90`, so X_test\n",
    "- Expected `100, 110`. We say expected because we don't know the actual values, thus no y_test. Expected as in we increment by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3c3df5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=3, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "\n",
    "mlp_predict_model = MLP(n_steps, hidden_size, output_size)\n",
    "mlp_predict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffb43a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=3, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_forecast_model = MLP(n_steps, hidden_size, output_size)\n",
    "mlp_forecast_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8559b466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 3</th>\n",
       "      <th>t - 2</th>\n",
       "      <th>t - 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 3 t - 2 t - 1\n",
       "3  10.0  20.0  30.0\n",
       "4  20.0  30.0  40.0\n",
       "5  30.0  40.0  50.0\n",
       "6  40.0  50.0  60.0\n",
       "7  50.0  60.0  70.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcae1763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 41/2000 [00:00<00:28, 67.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "    Predictions | Train loss: 4074.6533203125 | Test loss: 7711.736328125\n",
      "    Forecasts | Train loss: 4184.96533203125\n",
      "Epoch: 10\n",
      "    Predictions | Train loss: 2750.412841796875 | Test loss: 4833.4306640625\n",
      "    Forecasts | Train loss: 2617.53759765625\n",
      "Epoch: 20\n",
      "    Predictions | Train loss: 1705.462890625 | Test loss: 2662.55908203125\n",
      "    Forecasts | Train loss: 1431.9300537109375\n",
      "Epoch: 30\n",
      "    Predictions | Train loss: 932.5897216796875 | Test loss: 1178.873046875\n",
      "    Forecasts | Train loss: 640.198974609375\n",
      "Epoch: 40\n",
      "    Predictions | Train loss: 424.52294921875 | Test loss: 345.60784912109375\n",
      "    Forecasts | Train loss: 217.2648468017578\n",
      "Epoch: 50\n",
      "    Predictions | Train loss: 156.12008666992188 | Test loss: 41.828922271728516\n",
      "    Forecasts | Train loss: 70.5641860961914\n",
      "Epoch: 60\n",
      "    Predictions | Train loss: 59.31127166748047 | Test loss: 61.111392974853516\n",
      "    Forecasts | Train loss: 53.9788932800293\n",
      "Epoch: 70\n",
      "    Predictions | Train loss: 40.821510314941406 | Test loss: 150.7252960205078\n",
      "    Forecasts | Train loss: 57.16742706298828\n",
      "Epoch: 80\n",
      "    Predictions | Train loss: 39.34535217285156 | Test loss: 184.71917724609375\n",
      "    Forecasts | Train loss: 53.09492111206055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 163/2000 [00:01<00:07, 240.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90\n",
      "    Predictions | Train loss: 37.87683868408203 | Test loss: 169.25387573242188\n",
      "    Forecasts | Train loss: 49.59619140625\n",
      "Epoch: 100\n",
      "    Predictions | Train loss: 36.436973571777344 | Test loss: 142.86160278320312\n",
      "    Forecasts | Train loss: 48.0103874206543\n",
      "Epoch: 110\n",
      "    Predictions | Train loss: 35.4530029296875 | Test loss: 124.86209106445312\n",
      "    Forecasts | Train loss: 46.95061492919922\n",
      "Epoch: 120\n",
      "    Predictions | Train loss: 34.63003158569336 | Test loss: 117.28349304199219\n",
      "    Forecasts | Train loss: 45.82170867919922\n",
      "Epoch: 130\n",
      "    Predictions | Train loss: 33.79766082763672 | Test loss: 115.53352355957031\n",
      "    Forecasts | Train loss: 44.69575119018555\n",
      "Epoch: 140\n",
      "    Predictions | Train loss: 32.89731216430664 | Test loss: 114.94806671142578\n",
      "    Forecasts | Train loss: 43.56767654418945\n",
      "Epoch: 150\n",
      "    Predictions | Train loss: 31.886093139648438 | Test loss: 113.35980224609375\n",
      "    Forecasts | Train loss: 42.42289733886719\n",
      "Epoch: 160\n",
      "    Predictions | Train loss: 30.790496826171875 | Test loss: 110.53084564208984\n",
      "    Forecasts | Train loss: 41.26676940917969\n",
      "Epoch: 170\n",
      "    Predictions | Train loss: 29.743839263916016 | Test loss: 106.67805480957031\n",
      "    Forecasts | Train loss: 40.09967803955078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 242/2000 [00:01<00:05, 308.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180\n",
      "    Predictions | Train loss: 28.793899536132812 | Test loss: 102.15785217285156\n",
      "    Forecasts | Train loss: 38.92212677001953\n",
      "Epoch: 190\n",
      "    Predictions | Train loss: 27.825899124145508 | Test loss: 97.94282531738281\n",
      "    Forecasts | Train loss: 37.73595428466797\n",
      "Epoch: 200\n",
      "    Predictions | Train loss: 26.853010177612305 | Test loss: 94.63165283203125\n",
      "    Forecasts | Train loss: 36.552276611328125\n",
      "Epoch: 210\n",
      "    Predictions | Train loss: 25.87710189819336 | Test loss: 92.06838989257812\n",
      "    Forecasts | Train loss: 35.364967346191406\n",
      "Epoch: 220\n",
      "    Predictions | Train loss: 24.899633407592773 | Test loss: 89.8353500366211\n",
      "    Forecasts | Train loss: 34.174190521240234\n",
      "Epoch: 230\n",
      "    Predictions | Train loss: 23.932926177978516 | Test loss: 87.58013916015625\n",
      "    Forecasts | Train loss: 32.98933029174805\n",
      "Epoch: 240\n",
      "    Predictions | Train loss: 22.966880798339844 | Test loss: 84.68968200683594\n",
      "    Forecasts | Train loss: 31.802066802978516\n",
      "Epoch: 250\n",
      "    Predictions | Train loss: 22.014650344848633 | Test loss: 81.5238037109375\n",
      "    Forecasts | Train loss: 30.62737464904785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 323/2000 [00:01<00:04, 351.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 260\n",
      "    Predictions | Train loss: 21.058284759521484 | Test loss: 78.17987060546875\n",
      "    Forecasts | Train loss: 29.470529556274414\n",
      "Epoch: 270\n",
      "    Predictions | Train loss: 20.11330795288086 | Test loss: 75.32443237304688\n",
      "    Forecasts | Train loss: 28.31842041015625\n",
      "Epoch: 280\n",
      "    Predictions | Train loss: 19.181358337402344 | Test loss: 72.55296325683594\n",
      "    Forecasts | Train loss: 27.179141998291016\n",
      "Epoch: 290\n",
      "    Predictions | Train loss: 18.258710861206055 | Test loss: 69.65547180175781\n",
      "    Forecasts | Train loss: 26.053409576416016\n",
      "Epoch: 300\n",
      "    Predictions | Train loss: 17.35027503967285 | Test loss: 66.74482727050781\n",
      "    Forecasts | Train loss: 24.944257736206055\n",
      "Epoch: 310\n",
      "    Predictions | Train loss: 16.455774307250977 | Test loss: 63.84687042236328\n",
      "    Forecasts | Train loss: 23.839412689208984\n",
      "Epoch: 320\n",
      "    Predictions | Train loss: 15.577291488647461 | Test loss: 61.00595474243164\n",
      "    Forecasts | Train loss: 22.757137298583984\n",
      "Epoch: 330\n",
      "    Predictions | Train loss: 14.718477249145508 | Test loss: 58.20838165283203\n",
      "    Forecasts | Train loss: 21.690570831298828\n",
      "Epoch: 340\n",
      "    Predictions | Train loss: 13.880675315856934 | Test loss: 55.522743225097656\n",
      "    Forecasts | Train loss: 20.65055274963379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 405/2000 [00:01<00:04, 375.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350\n",
      "    Predictions | Train loss: 13.064631462097168 | Test loss: 52.86140441894531\n",
      "    Forecasts | Train loss: 19.625513076782227\n",
      "Epoch: 360\n",
      "    Predictions | Train loss: 12.269533157348633 | Test loss: 50.235816955566406\n",
      "    Forecasts | Train loss: 18.62664031982422\n",
      "Epoch: 370\n",
      "    Predictions | Train loss: 11.499849319458008 | Test loss: 47.753570556640625\n",
      "    Forecasts | Train loss: 17.653675079345703\n",
      "Epoch: 380\n",
      "    Predictions | Train loss: 10.758404731750488 | Test loss: 45.30643844604492\n",
      "    Forecasts | Train loss: 16.698932647705078\n",
      "Epoch: 390\n",
      "    Predictions | Train loss: 10.041655540466309 | Test loss: 42.9370231628418\n",
      "    Forecasts | Train loss: 15.779154777526855\n",
      "Epoch: 400\n",
      "    Predictions | Train loss: 9.351503372192383 | Test loss: 40.62732696533203\n",
      "    Forecasts | Train loss: 14.880027770996094\n",
      "Epoch: 410\n",
      "    Predictions | Train loss: 8.6897554397583 | Test loss: 38.30636978149414\n",
      "    Forecasts | Train loss: 14.012855529785156\n",
      "Epoch: 420\n",
      "    Predictions | Train loss: 8.058241844177246 | Test loss: 36.24124526977539\n",
      "    Forecasts | Train loss: 13.175374984741211\n",
      "Epoch: 430\n",
      "    Predictions | Train loss: 7.454395294189453 | Test loss: 34.21256637573242\n",
      "    Forecasts | Train loss: 12.36327838897705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 485/2000 [00:01<00:03, 385.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 440\n",
      "    Predictions | Train loss: 6.879201889038086 | Test loss: 32.14448165893555\n",
      "    Forecasts | Train loss: 11.586977005004883\n",
      "Epoch: 450\n",
      "    Predictions | Train loss: 6.336297988891602 | Test loss: 30.30518341064453\n",
      "    Forecasts | Train loss: 10.834024429321289\n",
      "Epoch: 460\n",
      "    Predictions | Train loss: 5.820835590362549 | Test loss: 28.525060653686523\n",
      "    Forecasts | Train loss: 10.119241714477539\n",
      "Epoch: 470\n",
      "    Predictions | Train loss: 5.334562301635742 | Test loss: 26.74346923828125\n",
      "    Forecasts | Train loss: 9.436281204223633\n",
      "Epoch: 480\n",
      "    Predictions | Train loss: 4.8796067237854 | Test loss: 25.12923812866211\n",
      "    Forecasts | Train loss: 8.77613353729248\n",
      "Epoch: 490\n",
      "    Predictions | Train loss: 4.4505510330200195 | Test loss: 23.587554931640625\n",
      "    Forecasts | Train loss: 8.148921966552734\n",
      "Epoch: 500\n",
      "    Predictions | Train loss: 4.050883769989014 | Test loss: 22.104421615600586\n",
      "    Forecasts | Train loss: 7.55746603012085\n",
      "Epoch: 510\n",
      "    Predictions | Train loss: 3.6791093349456787 | Test loss: 20.910316467285156\n",
      "    Forecasts | Train loss: 6.992734432220459\n",
      "Epoch: 520\n",
      "    Predictions | Train loss: 3.3339662551879883 | Test loss: 19.857948303222656\n",
      "    Forecasts | Train loss: 6.462248802185059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 609/2000 [00:02<00:03, 402.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 530\n",
      "    Predictions | Train loss: 3.0120530128479004 | Test loss: 18.90679931640625\n",
      "    Forecasts | Train loss: 5.9579596519470215\n",
      "Epoch: 540\n",
      "    Predictions | Train loss: 2.716090202331543 | Test loss: 18.021020889282227\n",
      "    Forecasts | Train loss: 5.487274646759033\n",
      "Epoch: 550\n",
      "    Predictions | Train loss: 2.4428882598876953 | Test loss: 17.10931396484375\n",
      "    Forecasts | Train loss: 5.040675163269043\n",
      "Epoch: 560\n",
      "    Predictions | Train loss: 2.193622589111328 | Test loss: 16.381338119506836\n",
      "    Forecasts | Train loss: 4.627192497253418\n",
      "Epoch: 570\n",
      "    Predictions | Train loss: 1.9659159183502197 | Test loss: 15.587031364440918\n",
      "    Forecasts | Train loss: 4.244229316711426\n",
      "Epoch: 580\n",
      "    Predictions | Train loss: 1.7552858591079712 | Test loss: 14.896323204040527\n",
      "    Forecasts | Train loss: 3.8931422233581543\n",
      "Epoch: 590\n",
      "    Predictions | Train loss: 1.5648865699768066 | Test loss: 14.2518892288208\n",
      "    Forecasts | Train loss: 3.562903881072998\n",
      "Epoch: 600\n",
      "    Predictions | Train loss: 1.3922390937805176 | Test loss: 13.584114074707031\n",
      "    Forecasts | Train loss: 3.2588183879852295\n",
      "Epoch: 610\n",
      "    Predictions | Train loss: 1.23664128780365 | Test loss: 13.049419403076172\n",
      "    Forecasts | Train loss: 2.9739387035369873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 692/2000 [00:02<00:03, 405.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 620\n",
      "    Predictions | Train loss: 1.095155119895935 | Test loss: 12.45294189453125\n",
      "    Forecasts | Train loss: 2.7127785682678223\n",
      "Epoch: 630\n",
      "    Predictions | Train loss: 0.9689192175865173 | Test loss: 11.967727661132812\n",
      "    Forecasts | Train loss: 2.4684863090515137\n",
      "Epoch: 640\n",
      "    Predictions | Train loss: 0.8546534180641174 | Test loss: 11.493032455444336\n",
      "    Forecasts | Train loss: 2.2459053993225098\n",
      "Epoch: 650\n",
      "    Predictions | Train loss: 0.7530642747879028 | Test loss: 11.0466947555542\n",
      "    Forecasts | Train loss: 2.038877010345459\n",
      "Epoch: 660\n",
      "    Predictions | Train loss: 0.6621354222297668 | Test loss: 10.65091323852539\n",
      "    Forecasts | Train loss: 1.8505827188491821\n",
      "Epoch: 670\n",
      "    Predictions | Train loss: 0.5809521675109863 | Test loss: 10.225737571716309\n",
      "    Forecasts | Train loss: 1.6757137775421143\n",
      "Epoch: 680\n",
      "    Predictions | Train loss: 0.509249746799469 | Test loss: 9.92406940460205\n",
      "    Forecasts | Train loss: 1.5154063701629639\n",
      "Epoch: 690\n",
      "    Predictions | Train loss: 0.44510072469711304 | Test loss: 9.544081687927246\n",
      "    Forecasts | Train loss: 1.3692777156829834\n",
      "Epoch: 700\n",
      "    Predictions | Train loss: 0.3888753652572632 | Test loss: 9.281070709228516\n",
      "    Forecasts | Train loss: 1.2362228631973267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 774/2000 [00:02<00:03, 407.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 710\n",
      "    Predictions | Train loss: 0.33915892243385315 | Test loss: 8.97273063659668\n",
      "    Forecasts | Train loss: 1.115315556526184\n",
      "Epoch: 720\n",
      "    Predictions | Train loss: 0.2951684296131134 | Test loss: 8.696636199951172\n",
      "    Forecasts | Train loss: 1.0052847862243652\n",
      "Epoch: 730\n",
      "    Predictions | Train loss: 0.2566041350364685 | Test loss: 8.422572135925293\n",
      "    Forecasts | Train loss: 0.9044865369796753\n",
      "Epoch: 740\n",
      "    Predictions | Train loss: 0.22282731533050537 | Test loss: 8.212607383728027\n",
      "    Forecasts | Train loss: 0.8132799863815308\n",
      "Epoch: 750\n",
      "    Predictions | Train loss: 0.1932133138179779 | Test loss: 7.996518611907959\n",
      "    Forecasts | Train loss: 0.7298198342323303\n",
      "Epoch: 760\n",
      "    Predictions | Train loss: 0.1674254834651947 | Test loss: 7.820624351501465\n",
      "    Forecasts | Train loss: 0.6548075675964355\n",
      "Epoch: 770\n",
      "    Predictions | Train loss: 0.14477409422397614 | Test loss: 7.660475730895996\n",
      "    Forecasts | Train loss: 0.5856426954269409\n",
      "Epoch: 780\n",
      "    Predictions | Train loss: 0.12502223253250122 | Test loss: 7.499889373779297\n",
      "    Forecasts | Train loss: 0.5236698985099792\n",
      "Epoch: 790\n",
      "    Predictions | Train loss: 0.10791245102882385 | Test loss: 7.343174934387207\n",
      "    Forecasts | Train loss: 0.46739572286605835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 857/2000 [00:02<00:02, 410.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 800\n",
      "    Predictions | Train loss: 0.09300696104764938 | Test loss: 7.2221479415893555\n",
      "    Forecasts | Train loss: 0.41712966561317444\n",
      "Epoch: 810\n",
      "    Predictions | Train loss: 0.08001087605953217 | Test loss: 7.107242584228516\n",
      "    Forecasts | Train loss: 0.371108740568161\n",
      "Epoch: 820\n",
      "    Predictions | Train loss: 0.06882023066282272 | Test loss: 7.001659393310547\n",
      "    Forecasts | Train loss: 0.32996755838394165\n",
      "Epoch: 830\n",
      "    Predictions | Train loss: 0.05913206934928894 | Test loss: 6.9016523361206055\n",
      "    Forecasts | Train loss: 0.2928878664970398\n",
      "Epoch: 840\n",
      "    Predictions | Train loss: 0.0507204569876194 | Test loss: 6.809441566467285\n",
      "    Forecasts | Train loss: 0.25985196232795715\n",
      "Epoch: 850\n",
      "    Predictions | Train loss: 0.043491117656230927 | Test loss: 6.724126815795898\n",
      "    Forecasts | Train loss: 0.23005786538124084\n",
      "Epoch: 860\n",
      "    Predictions | Train loss: 0.0372748002409935 | Test loss: 6.649641513824463\n",
      "    Forecasts | Train loss: 0.20340001583099365\n",
      "Epoch: 870\n",
      "    Predictions | Train loss: 0.031906966120004654 | Test loss: 6.576444149017334\n",
      "    Forecasts | Train loss: 0.17954009771347046\n",
      "Epoch: 880\n",
      "    Predictions | Train loss: 0.027297060936689377 | Test loss: 6.508275985717773\n",
      "    Forecasts | Train loss: 0.15836229920387268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 940/2000 [00:03<00:02, 408.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 890\n",
      "    Predictions | Train loss: 0.02332872711122036 | Test loss: 6.449029922485352\n",
      "    Forecasts | Train loss: 0.13948151469230652\n",
      "Epoch: 900\n",
      "    Predictions | Train loss: 0.019942570477724075 | Test loss: 6.398982524871826\n",
      "    Forecasts | Train loss: 0.12263122946023941\n",
      "Epoch: 910\n",
      "    Predictions | Train loss: 0.017030073329806328 | Test loss: 6.348197937011719\n",
      "    Forecasts | Train loss: 0.10764239728450775\n",
      "Epoch: 920\n",
      "    Predictions | Train loss: 0.014550662599503994 | Test loss: 6.300602912902832\n",
      "    Forecasts | Train loss: 0.09440206736326218\n",
      "Epoch: 930\n",
      "    Predictions | Train loss: 0.012415408156812191 | Test loss: 6.2604265213012695\n",
      "    Forecasts | Train loss: 0.08270169794559479\n",
      "Epoch: 940\n",
      "    Predictions | Train loss: 0.010602863505482674 | Test loss: 6.223752498626709\n",
      "    Forecasts | Train loss: 0.07230361551046371\n",
      "Epoch: 950\n",
      "    Predictions | Train loss: 0.009056927636265755 | Test loss: 6.191226005554199\n",
      "    Forecasts | Train loss: 0.06313695758581161\n",
      "Epoch: 960\n",
      "    Predictions | Train loss: 0.007739029824733734 | Test loss: 6.159565448760986\n",
      "    Forecasts | Train loss: 0.055043645203113556\n",
      "Epoch: 970\n",
      "    Predictions | Train loss: 0.006619299296289682 | Test loss: 6.130932807922363\n",
      "    Forecasts | Train loss: 0.047955021262168884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1022/2000 [00:03<00:02, 408.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 980\n",
      "    Predictions | Train loss: 0.005669281352311373 | Test loss: 6.104325294494629\n",
      "    Forecasts | Train loss: 0.041715703904628754\n",
      "Epoch: 990\n",
      "    Predictions | Train loss: 0.0048613036051392555 | Test loss: 6.080780506134033\n",
      "    Forecasts | Train loss: 0.036258965730667114\n",
      "Epoch: 1000\n",
      "    Predictions | Train loss: 0.004177028778940439 | Test loss: 6.059504508972168\n",
      "    Forecasts | Train loss: 0.031443726271390915\n",
      "Epoch: 1010\n",
      "    Predictions | Train loss: 0.0035983461420983076 | Test loss: 6.039910316467285\n",
      "    Forecasts | Train loss: 0.027257520705461502\n",
      "Epoch: 1020\n",
      "    Predictions | Train loss: 0.0031090148258954287 | Test loss: 6.0231218338012695\n",
      "    Forecasts | Train loss: 0.02358308434486389\n",
      "Epoch: 1030\n",
      "    Predictions | Train loss: 0.002694894792512059 | Test loss: 6.0078630447387695\n",
      "    Forecasts | Train loss: 0.020383309572935104\n",
      "Epoch: 1040\n",
      "    Predictions | Train loss: 0.0023461878299713135 | Test loss: 5.992048263549805\n",
      "    Forecasts | Train loss: 0.017583144828677177\n",
      "Epoch: 1050\n",
      "    Predictions | Train loss: 0.002051670802757144 | Test loss: 5.977683067321777\n",
      "    Forecasts | Train loss: 0.01515878550708294\n",
      "Epoch: 1060\n",
      "    Predictions | Train loss: 0.0018041216535493731 | Test loss: 5.966570854187012\n",
      "    Forecasts | Train loss: 0.013043394312262535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1146/2000 [00:03<00:02, 407.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1070\n",
      "    Predictions | Train loss: 0.0015958592994138598 | Test loss: 5.957634925842285\n",
      "    Forecasts | Train loss: 0.01120575051754713\n",
      "Epoch: 1080\n",
      "    Predictions | Train loss: 0.0014193679671734571 | Test loss: 5.948855400085449\n",
      "    Forecasts | Train loss: 0.009619029238820076\n",
      "Epoch: 1090\n",
      "    Predictions | Train loss: 0.0012691458687186241 | Test loss: 5.942605018615723\n",
      "    Forecasts | Train loss: 0.008248626254498959\n",
      "Epoch: 1100\n",
      "    Predictions | Train loss: 0.0011405679397284985 | Test loss: 5.93868350982666\n",
      "    Forecasts | Train loss: 0.007057602517306805\n",
      "Epoch: 1110\n",
      "    Predictions | Train loss: 0.0010294041130691767 | Test loss: 5.936458587646484\n",
      "    Forecasts | Train loss: 0.006029700394719839\n",
      "Epoch: 1120\n",
      "    Predictions | Train loss: 0.000933003262616694 | Test loss: 5.936595916748047\n",
      "    Forecasts | Train loss: 0.005146989598870277\n",
      "Epoch: 1130\n",
      "    Predictions | Train loss: 0.0008493338245898485 | Test loss: 5.936818599700928\n",
      "    Forecasts | Train loss: 0.004390616901218891\n",
      "Epoch: 1140\n",
      "    Predictions | Train loss: 0.0007769568474031985 | Test loss: 5.936890602111816\n",
      "    Forecasts | Train loss: 0.0037354205269366503\n",
      "Epoch: 1150\n",
      "    Predictions | Train loss: 0.0007138000219129026 | Test loss: 5.936591625213623\n",
      "    Forecasts | Train loss: 0.0031739328987896442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 1229/2000 [00:03<00:01, 408.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1160\n",
      "    Predictions | Train loss: 0.0006591663113795221 | Test loss: 5.93616247177124\n",
      "    Forecasts | Train loss: 0.0026944486889988184\n",
      "Epoch: 1170\n",
      "    Predictions | Train loss: 0.0006116688018664718 | Test loss: 5.935698509216309\n",
      "    Forecasts | Train loss: 0.002285757102072239\n",
      "Epoch: 1180\n",
      "    Predictions | Train loss: 0.0005703240167349577 | Test loss: 5.935351371765137\n",
      "    Forecasts | Train loss: 0.0019339567515999079\n",
      "Epoch: 1190\n",
      "    Predictions | Train loss: 0.0005352357402443886 | Test loss: 5.93507194519043\n",
      "    Forecasts | Train loss: 0.0016340201254934072\n",
      "Epoch: 1200\n",
      "    Predictions | Train loss: 0.0005053299246355891 | Test loss: 5.934911727905273\n",
      "    Forecasts | Train loss: 0.0013795619597658515\n",
      "Epoch: 1210\n",
      "    Predictions | Train loss: 0.00047914942842908204 | Test loss: 5.934785842895508\n",
      "    Forecasts | Train loss: 0.001163734938018024\n",
      "Epoch: 1220\n",
      "    Predictions | Train loss: 0.0004563144175335765 | Test loss: 5.93453311920166\n",
      "    Forecasts | Train loss: 0.000979290110990405\n",
      "Epoch: 1230\n",
      "    Predictions | Train loss: 0.00043640428339131176 | Test loss: 5.934349060058594\n",
      "    Forecasts | Train loss: 0.0008227283833548427\n",
      "Epoch: 1240\n",
      "    Predictions | Train loss: 0.0004187952436041087 | Test loss: 5.934125900268555\n",
      "    Forecasts | Train loss: 0.0006908654468134046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1311/2000 [00:03<00:01, 405.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1250\n",
      "    Predictions | Train loss: 0.00040339061524719 | Test loss: 5.933950424194336\n",
      "    Forecasts | Train loss: 0.000579171406570822\n",
      "Epoch: 1260\n",
      "    Predictions | Train loss: 0.0003899651928804815 | Test loss: 5.933720588684082\n",
      "    Forecasts | Train loss: 0.00048476867959834635\n",
      "Epoch: 1270\n",
      "    Predictions | Train loss: 0.00037817913107573986 | Test loss: 5.933579921722412\n",
      "    Forecasts | Train loss: 0.00040509141399525106\n",
      "Epoch: 1280\n",
      "    Predictions | Train loss: 0.0003679503861349076 | Test loss: 5.933420181274414\n",
      "    Forecasts | Train loss: 0.00033816759241744876\n",
      "Epoch: 1290\n",
      "    Predictions | Train loss: 0.0003589948173612356 | Test loss: 5.933233261108398\n",
      "    Forecasts | Train loss: 0.00028178669163025916\n",
      "Epoch: 1300\n",
      "    Predictions | Train loss: 0.0003511955146677792 | Test loss: 5.933110237121582\n",
      "    Forecasts | Train loss: 0.0002346094261156395\n",
      "Epoch: 1310\n",
      "    Predictions | Train loss: 0.0003443524765316397 | Test loss: 5.932926177978516\n",
      "    Forecasts | Train loss: 0.00019493568106554449\n",
      "Epoch: 1320\n",
      "    Predictions | Train loss: 0.00033836651709862053 | Test loss: 5.932788848876953\n",
      "    Forecasts | Train loss: 0.00016173739277292043\n",
      "Epoch: 1330\n",
      "    Predictions | Train loss: 0.00033312567393295467 | Test loss: 5.932623863220215\n",
      "    Forecasts | Train loss: 0.00013415003195405006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1394/2000 [00:04<00:01, 408.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1340\n",
      "    Predictions | Train loss: 0.0003285820712335408 | Test loss: 5.9325337409973145\n",
      "    Forecasts | Train loss: 0.00011094407818745822\n",
      "Epoch: 1350\n",
      "    Predictions | Train loss: 0.0003246006090193987 | Test loss: 5.932424545288086\n",
      "    Forecasts | Train loss: 9.168779070023447e-05\n",
      "Epoch: 1360\n",
      "    Predictions | Train loss: 0.00032119167735800147 | Test loss: 5.93230676651001\n",
      "    Forecasts | Train loss: 7.564318366348743e-05\n",
      "Epoch: 1370\n",
      "    Predictions | Train loss: 0.00031805821345187724 | Test loss: 5.932186126708984\n",
      "    Forecasts | Train loss: 6.229421705938876e-05\n",
      "Epoch: 1380\n",
      "    Predictions | Train loss: 0.0003154592704959214 | Test loss: 5.932074069976807\n",
      "    Forecasts | Train loss: 5.1260147301945835e-05\n",
      "Epoch: 1390\n",
      "    Predictions | Train loss: 0.000313091732095927 | Test loss: 5.931970596313477\n",
      "    Forecasts | Train loss: 4.2121042497456074e-05\n",
      "Epoch: 1400\n",
      "    Predictions | Train loss: 0.0003110873803962022 | Test loss: 5.931884765625\n",
      "    Forecasts | Train loss: 3.4544522350188345e-05\n",
      "Epoch: 1410\n",
      "    Predictions | Train loss: 0.00030934595270082355 | Test loss: 5.931790828704834\n",
      "    Forecasts | Train loss: 2.8314732844592072e-05\n",
      "Epoch: 1420\n",
      "    Predictions | Train loss: 0.0003076856955885887 | Test loss: 5.931660175323486\n",
      "    Forecasts | Train loss: 2.3144137230701745e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1477/2000 [00:04<00:01, 402.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1430\n",
      "    Predictions | Train loss: 0.0003062931355088949 | Test loss: 5.931574821472168\n",
      "    Forecasts | Train loss: 1.8892387743107975e-05\n",
      "Epoch: 1440\n",
      "    Predictions | Train loss: 0.0003050354134757072 | Test loss: 5.931465148925781\n",
      "    Forecasts | Train loss: 1.5428478945977986e-05\n",
      "Epoch: 1450\n",
      "    Predictions | Train loss: 0.00030388531740754843 | Test loss: 5.9313764572143555\n",
      "    Forecasts | Train loss: 1.2547288861242123e-05\n",
      "Epoch: 1460\n",
      "    Predictions | Train loss: 0.0003029317012988031 | Test loss: 5.931239128112793\n",
      "    Forecasts | Train loss: 1.0188179658143781e-05\n",
      "Epoch: 1470\n",
      "    Predictions | Train loss: 0.00030210596742108464 | Test loss: 5.931224822998047\n",
      "    Forecasts | Train loss: 8.287621312774718e-06\n",
      "Epoch: 1480\n",
      "    Predictions | Train loss: 0.00030126533238217235 | Test loss: 5.931112289428711\n",
      "    Forecasts | Train loss: 6.708863566018408e-06\n",
      "Epoch: 1490\n",
      "    Predictions | Train loss: 0.0003005456237588078 | Test loss: 5.931065559387207\n",
      "    Forecasts | Train loss: 5.417806278273929e-06\n",
      "Epoch: 1500\n",
      "    Predictions | Train loss: 0.0002998985000886023 | Test loss: 5.931002616882324\n",
      "    Forecasts | Train loss: 4.386582986626308e-06\n",
      "Epoch: 1510\n",
      "    Predictions | Train loss: 0.0002993313246406615 | Test loss: 5.930906295776367\n",
      "    Forecasts | Train loss: 3.535472160365316e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1602/2000 [00:04<00:00, 409.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1520\n",
      "    Predictions | Train loss: 0.0002988145570270717 | Test loss: 5.930814743041992\n",
      "    Forecasts | Train loss: 2.8414972348400624e-06\n",
      "Epoch: 1530\n",
      "    Predictions | Train loss: 0.00029823422664776444 | Test loss: 5.930764675140381\n",
      "    Forecasts | Train loss: 2.289096300955862e-06\n",
      "Epoch: 1540\n",
      "    Predictions | Train loss: 0.00029771641129627824 | Test loss: 5.930718421936035\n",
      "    Forecasts | Train loss: 1.8381761037744582e-06\n",
      "Epoch: 1550\n",
      "    Predictions | Train loss: 0.0002972815418615937 | Test loss: 5.930667877197266\n",
      "    Forecasts | Train loss: 1.4799850305280415e-06\n",
      "Epoch: 1560\n",
      "    Predictions | Train loss: 0.0002968228072859347 | Test loss: 5.930577278137207\n",
      "    Forecasts | Train loss: 1.1780560953411623e-06\n",
      "Epoch: 1570\n",
      "    Predictions | Train loss: 0.0002964175946544856 | Test loss: 5.930515289306641\n",
      "    Forecasts | Train loss: 9.407056609234132e-07\n",
      "Epoch: 1580\n",
      "    Predictions | Train loss: 0.00029605257441289723 | Test loss: 5.930403709411621\n",
      "    Forecasts | Train loss: 7.514623803217546e-07\n",
      "Epoch: 1590\n",
      "    Predictions | Train loss: 0.0002957358956336975 | Test loss: 5.93034553527832\n",
      "    Forecasts | Train loss: 5.98681822339131e-07\n",
      "Epoch: 1600\n",
      "    Predictions | Train loss: 0.00029539017123170197 | Test loss: 5.930274963378906\n",
      "    Forecasts | Train loss: 4.770990926772356e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1684/2000 [00:04<00:00, 408.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1610\n",
      "    Predictions | Train loss: 0.00029504921985790133 | Test loss: 5.930184364318848\n",
      "    Forecasts | Train loss: 3.7972057498336653e-07\n",
      "Epoch: 1620\n",
      "    Predictions | Train loss: 0.00029465905390679836 | Test loss: 5.930118560791016\n",
      "    Forecasts | Train loss: 3.0078081181272864e-07\n",
      "Epoch: 1630\n",
      "    Predictions | Train loss: 0.00029434970929287374 | Test loss: 5.930052757263184\n",
      "    Forecasts | Train loss: 2.3737229071230104e-07\n",
      "Epoch: 1640\n",
      "    Predictions | Train loss: 0.0002939584373962134 | Test loss: 5.929908752441406\n",
      "    Forecasts | Train loss: 1.895605237223208e-07\n",
      "Epoch: 1650\n",
      "    Predictions | Train loss: 0.0002936694072559476 | Test loss: 5.929867267608643\n",
      "    Forecasts | Train loss: 1.5062104807839205e-07\n",
      "Epoch: 1660\n",
      "    Predictions | Train loss: 0.0002933517098426819 | Test loss: 5.929821968078613\n",
      "    Forecasts | Train loss: 1.1768861440941691e-07\n",
      "Epoch: 1670\n",
      "    Predictions | Train loss: 0.0002930500195361674 | Test loss: 5.929739952087402\n",
      "    Forecasts | Train loss: 9.242212684057449e-08\n",
      "Epoch: 1680\n",
      "    Predictions | Train loss: 0.0002927607565652579 | Test loss: 5.929640769958496\n",
      "    Forecasts | Train loss: 7.289636272389544e-08\n",
      "Epoch: 1690\n",
      "    Predictions | Train loss: 0.00029240205185487866 | Test loss: 5.929546356201172\n",
      "    Forecasts | Train loss: 5.842593964189291e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1767/2000 [00:05<00:00, 408.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1700\n",
      "    Predictions | Train loss: 0.0002921119157690555 | Test loss: 5.929443359375\n",
      "    Forecasts | Train loss: 4.456815005937642e-08\n",
      "Epoch: 1710\n",
      "    Predictions | Train loss: 0.00029183353763073683 | Test loss: 5.9293904304504395\n",
      "    Forecasts | Train loss: 3.5588165303579444e-08\n",
      "Epoch: 1720\n",
      "    Predictions | Train loss: 0.0002915197401307523 | Test loss: 5.929333209991455\n",
      "    Forecasts | Train loss: 2.742599392036027e-08\n",
      "Epoch: 1730\n",
      "    Predictions | Train loss: 0.0002911713672801852 | Test loss: 5.92925500869751\n",
      "    Forecasts | Train loss: 2.134911447626564e-08\n",
      "Epoch: 1740\n",
      "    Predictions | Train loss: 0.00029085107962600887 | Test loss: 5.929193496704102\n",
      "    Forecasts | Train loss: 1.7006822616849604e-08\n",
      "Epoch: 1750\n",
      "    Predictions | Train loss: 0.00029053157777525485 | Test loss: 5.929119110107422\n",
      "    Forecasts | Train loss: 1.3441604274078145e-08\n",
      "Epoch: 1760\n",
      "    Predictions | Train loss: 0.0002902705455198884 | Test loss: 5.929066181182861\n",
      "    Forecasts | Train loss: 1.0916846981956496e-08\n",
      "Epoch: 1770\n",
      "    Predictions | Train loss: 0.0002898943203035742 | Test loss: 5.92902946472168\n",
      "    Forecasts | Train loss: 8.429924314157233e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1846/2000 [00:05<00:00, 365.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1780\n",
      "    Predictions | Train loss: 0.0002896349469665438 | Test loss: 5.9289140701293945\n",
      "    Forecasts | Train loss: 6.670597851865523e-09\n",
      "Epoch: 1790\n",
      "    Predictions | Train loss: 0.00028927301173098385 | Test loss: 5.928824424743652\n",
      "    Forecasts | Train loss: 4.997127600603335e-09\n",
      "Epoch: 1800\n",
      "    Predictions | Train loss: 0.0002889659663196653 | Test loss: 5.928713321685791\n",
      "    Forecasts | Train loss: 4.160392474972241e-09\n",
      "Epoch: 1810\n",
      "    Predictions | Train loss: 0.00028868834488093853 | Test loss: 5.928635597229004\n",
      "    Forecasts | Train loss: 3.3222022910450733e-09\n",
      "Epoch: 1820\n",
      "    Predictions | Train loss: 0.00028839107835665345 | Test loss: 5.928602695465088\n",
      "    Forecasts | Train loss: 2.310844182673577e-09\n",
      "Epoch: 1830\n",
      "    Predictions | Train loss: 0.00028806066256947815 | Test loss: 5.928487777709961\n",
      "    Forecasts | Train loss: 1.8393621070700306e-09\n",
      "Epoch: 1840\n",
      "    Predictions | Train loss: 0.00028776456019841135 | Test loss: 5.928380966186523\n",
      "    Forecasts | Train loss: 1.4129909464699608e-09\n",
      "Epoch: 1850\n",
      "    Predictions | Train loss: 0.00028748164186254144 | Test loss: 5.928332328796387\n",
      "    Forecasts | Train loss: 1.1161318536068165e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 1929/2000 [00:05<00:00, 387.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1860\n",
      "    Predictions | Train loss: 0.0002870742173399776 | Test loss: 5.9282379150390625\n",
      "    Forecasts | Train loss: 9.356881935929096e-10\n",
      "Epoch: 1870\n",
      "    Predictions | Train loss: 0.00028674627537839115 | Test loss: 5.928168296813965\n",
      "    Forecasts | Train loss: 7.392372824988058e-10\n",
      "Epoch: 1880\n",
      "    Predictions | Train loss: 0.00028645165730267763 | Test loss: 5.928094387054443\n",
      "    Forecasts | Train loss: 6.970367616432327e-10\n",
      "Epoch: 1890\n",
      "    Predictions | Train loss: 0.0002861756656784564 | Test loss: 5.928024768829346\n",
      "    Forecasts | Train loss: 6.344634817523342e-10\n",
      "Epoch: 1900\n",
      "    Predictions | Train loss: 0.00028577892226167023 | Test loss: 5.927955627441406\n",
      "    Forecasts | Train loss: 6.344634817523342e-10\n",
      "Epoch: 1910\n",
      "    Predictions | Train loss: 0.0002854835183825344 | Test loss: 5.927881240844727\n",
      "    Forecasts | Train loss: 5.937181302151373e-10\n",
      "Epoch: 1920\n",
      "    Predictions | Train loss: 0.000285144429653883 | Test loss: 5.927828311920166\n",
      "    Forecasts | Train loss: 5.675246939063072e-10\n",
      "Epoch: 1930\n",
      "    Predictions | Train loss: 0.0002848051371984184 | Test loss: 5.927799701690674\n",
      "    Forecasts | Train loss: 5.10772202311216e-10\n",
      "Epoch: 1940\n",
      "    Predictions | Train loss: 0.00028444838244467974 | Test loss: 5.927709579467773\n",
      "    Forecasts | Train loss: 5.340552999832937e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:05<00:00, 350.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1950\n",
      "    Predictions | Train loss: 0.0002841119421645999 | Test loss: 5.92763614654541\n",
      "    Forecasts | Train loss: 5.384208634495735e-10\n",
      "Epoch: 1960\n",
      "    Predictions | Train loss: 0.00028382212622091174 | Test loss: 5.927603244781494\n",
      "    Forecasts | Train loss: 4.933099484460968e-10\n",
      "Epoch: 1970\n",
      "    Predictions | Train loss: 0.0002834461338352412 | Test loss: 5.927554130554199\n",
      "    Forecasts | Train loss: 4.481989779314688e-10\n",
      "Epoch: 1980\n",
      "    Predictions | Train loss: 0.00028320151614025235 | Test loss: 5.927480220794678\n",
      "    Forecasts | Train loss: 4.176399781563589e-10\n",
      "Epoch: 1990\n",
      "    Predictions | Train loss: 0.0002827921125572175 | Test loss: 5.927406311035156\n",
      "    Forecasts | Train loss: 4.3364706270310194e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# #times to loop through the training\n",
    "# Hyperparameter\n",
    "epochs = 2000\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "predict_optimizer = torch.optim.Adam(mlp_predict_model.parameters())\n",
    "predict_configs = [criterion, predict_optimizer]\n",
    "\n",
    "forecast_optimizer = torch.optim.Adam(mlp_forecast_model.parameters())\n",
    "forecast_configs = [criterion, forecast_optimizer]\n",
    "\n",
    "# Track different setups (ie: lr, etc) to compare this experiment to future experiments\n",
    "epoch_count = []\n",
    "train_pred_values = []\n",
    "test_pred_values = []\n",
    "\n",
    "predict_train_loss_values = []\n",
    "predict_test_loss_values = []\n",
    "\n",
    "forecast_train_loss_values = []\n",
    "forecast_test_loss_values = []\n",
    "\n",
    "### Training\n",
    "# 0. Loop through the training\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # In-Sample Prediction\n",
    "    train_predictions, predict_train_loss = mlp_predict_model.train_model(predict_X_train_df, predict_y_train_df, predict_configs)\n",
    "    test_predictions, predict_test_loss = mlp_predict_model.interpolate_predictions(predict_X_test_df, predict_y_test_df, predict_configs)\n",
    "    \n",
    "    # Out-Sample Forecasts\n",
    "    train_forecasts, forecast_train_loss = mlp_forecast_model.train_model(forecast_X_train_df, forecast_y_train_df, forecast_configs)\n",
    "    test_forecasts = mlp_forecast_model.extrapolate_forecasts(forecast_X_test_df)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "\n",
    "        print(f\"    Predictions | Train loss: {predict_train_loss} | Test loss: {predict_test_loss}\")\n",
    "        # print(f\"    Predictions Parameters: {mlp_predict_model.state_dict()}\")\n",
    "        predict_train_loss_values.append(predict_train_loss)\n",
    "        predict_test_loss_values.append(predict_test_loss)\n",
    "\n",
    "        print(f\"    Forecasts | Train loss: {forecast_train_loss}\")\n",
    "        # print(f\"    Forecasts Parameters: {mlp_forecast_model.state_dict()}\")\n",
    "        forecast_train_loss_values.append(forecast_train_loss)\n",
    "        # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7683feae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 5.927\n"
     ]
    }
   ],
   "source": [
    "EvaluationMetric.eval_mse(predict_y_test_df, test_predictions, False) # Matches Test MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51305f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curves\n",
    "plt.plot(epoch_count, np.array(torch.tensor(predict_train_loss_values).numpy()), label=\"Predict train loss\")\n",
    "plt.plot(epoch_count, predict_test_loss_values, label=\"Predict test loss\")\n",
    "\n",
    "plt.plot(epoch_count, np.array(torch.tensor(forecast_train_loss_values).numpy()), label=\"Forecast train loss\")\n",
    "\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c93aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_series",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
