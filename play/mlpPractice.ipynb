{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a93950b4",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron Model\n",
    "\n",
    "- BOOK: [Predict the Future with MLPs, CNNs and LSTMs in Python](https://machinelearningmastery.com/deep-learning-for-time-series-forecasting/) by Jason Brownlee\n",
    "- NOTES: [TS -> ML split function](https://detraviousjbrinkley.notion.site/TS-ML-split-function-9ab51cbb49d244aa8b4ab434d009f8a7?pvs=4) by Detravious J.B. \n",
    "    - See for Forecast vs Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2335e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../framework_for_time_series_data/tslearn/'))\n",
    "from ml_models import MLP\n",
    "from ts_models import EvaluationMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86d7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = [10, 20, 30, 40, 50, 60, 70, 80, 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45624d9b",
   "metadata": {},
   "source": [
    "# Book's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f03ecb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out): \n",
    "    X, y = list(), list() \n",
    "    for i in range(len(sequence)): \n",
    "        # find the end of this pattern \n",
    "        end_ix = i + n_steps_in \n",
    "        out_end_ix = end_ix + n_steps_out \n",
    "        # check if we are beyond the sequence \n",
    "        if out_end_ix > len(sequence): \n",
    "            break\n",
    "        # gather input and output parts of the pattern \n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix] \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc84b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_sequence(observations, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a17514bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20, 30],\n",
       "       [20, 30, 40],\n",
       "       [30, 40, 50],\n",
       "       [40, 50, 60]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9dd5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 50, 60],\n",
       "       [50, 60, 70],\n",
       "       [60, 70, 80],\n",
       "       [70, 80, 90]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0e431",
   "metadata": {},
   "source": [
    "# My implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e506fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_uts_sequence_to_sml(uts_observations, prior_observations, forecasting_step):\n",
    "    \"\"\"Splits a given UTS into multiple input rows where each input row has a specified number of timestamps and the output is a single timestamp.\n",
    "    \n",
    "    Parameters:\n",
    "    uts_observations -- 1D np array (of UTS data to transform to SML data with size  b rows/length x 1 dimension)\n",
    "    prior_observations -- py int (of all observations before we get to where we want to start making the predictions)\n",
    "    forecasting_step -- py int (of how far out to forecast, 1 only the next timestamp, 2 the next two timestamps, ... n the next n timestamps)\n",
    "    \n",
    "    Return:\n",
    "    agg.values -- np array (of new sml data)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(uts_observations)\n",
    "    cols = list()\n",
    "    \n",
    "    lag_col_names = []\n",
    "    count_lag = 0\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for prior_observation in range(prior_observations, 0, -1):\n",
    "        # print(\"prior_observation: \", prior_observation)\n",
    "        cols.append(df.shift(prior_observation))\n",
    "        new_col_name = \"t - \" + str(prior_observation)\n",
    "        # print(new_col_name)\n",
    "        lag_col_names.append(new_col_name)\n",
    "        \n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, forecasting_step):\n",
    "        cols.append(df.shift(-i))\n",
    "        # print(f\"t + {i}\")\n",
    "        if i == 0:\n",
    "            new_col_name = f\"t\"\n",
    "        else:\n",
    "            new_col_name = f\"t + {i}\"\n",
    "        # print(new_col_name)\n",
    "        lag_col_names.append(new_col_name)\n",
    "        \n",
    "        # put it all together\n",
    "        uts_sml_df = pd.concat(cols, axis=1) \n",
    "        uts_sml_df.columns=[lag_col_names]\n",
    "        # drop rows with NaN values\n",
    "        uts_sml_df.dropna(inplace=True)\n",
    "    \n",
    "    # print(uts_sml_df)\n",
    "    \n",
    "    # colums to use to make prediction for last col\n",
    "    X_train = uts_sml_df.iloc[:, 0: -1]\n",
    "    \n",
    "    # last column\n",
    "    y_train = uts_sml_df.iloc[:, [-1]]\n",
    "    return uts_sml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c1f6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 3\n",
    "output_size = 2\n",
    "converted_seq_df = convert_uts_sequence_to_sml(observations, n_steps, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9cf9a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 3</th>\n",
       "      <th>t - 2</th>\n",
       "      <th>t - 1</th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 3 t - 2 t - 1   t t + 1\n",
       "3  10.0  20.0  30.0  40  50.0\n",
       "4  20.0  30.0  40.0  50  60.0\n",
       "5  30.0  40.0  50.0  60  70.0\n",
       "6  40.0  50.0  60.0  70  80.0\n",
       "7  50.0  60.0  70.0  80  90.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_seq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4216c4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 3</th>\n",
       "      <th>t - 2</th>\n",
       "      <th>t - 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 3 t - 2 t - 1\n",
       "3  10.0  20.0  30.0\n",
       "4  20.0  30.0  40.0\n",
       "5  30.0  40.0  50.0\n",
       "6  40.0  50.0  60.0\n",
       "7  50.0  60.0  70.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_X_train_df = converted_seq_df.iloc[:, :n_steps]\n",
    "forecast_X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3030b03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t t + 1\n",
       "3  40  50.0\n",
       "4  50  60.0\n",
       "5  60  70.0\n",
       "6  70  80.0\n",
       "7  80  90.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_y_train_df = converted_seq_df.iloc[:, -output_size:]\n",
    "forecast_y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b13497cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 1</th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70.0</td>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 1   t t + 1\n",
       "7  70.0  80  90.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_X_test_df = converted_seq_df.iloc[[-1], -n_steps:]\n",
    "forecast_X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d3307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 3</th>\n",
       "      <th>t - 2</th>\n",
       "      <th>t - 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 3 t - 2 t - 1\n",
       "3  10.0  20.0  30.0\n",
       "4  20.0  30.0  40.0\n",
       "5  30.0  40.0  50.0\n",
       "6  40.0  50.0  60.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X_train_df = converted_seq_df.iloc[:-1, :n_steps]\n",
    "predict_X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c2da8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t t + 1\n",
       "3  40  50.0\n",
       "4  50  60.0\n",
       "5  60  70.0\n",
       "6  70  80.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_train_df = converted_seq_df.iloc[:-1, -output_size:]\n",
    "predict_y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da43b0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 1</th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 1   t t + 1\n",
       "5  50.0  60  70.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X_test_df = converted_seq_df.iloc[[-n_steps], -n_steps:]\n",
    "predict_X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c11b99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t t + 1\n",
       "7  80  90.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_test_df = converted_seq_df.iloc[[-1], -output_size:]\n",
    "predict_y_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31c65e",
   "metadata": {},
   "source": [
    "# Book's implementation\n",
    "- Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c3248",
   "metadata": {},
   "source": [
    "## Forecast model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2586bf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 07:15:03.399734: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-30 07:15:08.501692: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "\n",
    "forecast_model = Sequential() \n",
    "forecast_model.add(Dense(100, activation='relu' , input_dim=n_steps)) \n",
    "forecast_model.add(Dense(output_size)) \n",
    "forecast_model.compile(optimizer='adam' , loss='mse') \n",
    "\n",
    "predict_model = Sequential() \n",
    "predict_model.add(Dense(100, activation='relu' , input_dim=n_steps)) \n",
    "predict_model.add(Dense(output_size)) \n",
    "predict_model.compile(optimizer='adam' , loss='mse') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a7c14ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19dcd4130>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model \n",
    "forecast_model.fit(forecast_X_train_df, forecast_y_train_df, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e475fd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[70., 80., 90.]]), 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_X_test = np.array(forecast_X_test_df)\n",
    "forecast_X_test, forecast_X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90b9f8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70., 80., 90.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = forecast_X_test.reshape((forecast_X_test.shape[0]), n_steps)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a0262d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102.74658 , 116.401215]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts = forecast_model.predict(X_test, verbose=0)\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ff7db",
   "metadata": {},
   "source": [
    "## Predict model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a17a48c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19dde29a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model.fit(predict_X_train_df, predict_y_train_df, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aea502e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[50., 60., 70.]]), 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X_test = np.array(predict_X_test_df)\n",
    "predict_X_test, predict_X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ece813e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70., 80., 90.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X_test = forecast_X_test.reshape((predict_X_test.shape[0]), n_steps)\n",
    "predict_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cabd8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73.85715, 67.28449]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_model_predictions = predict_model.predict(predict_X_test, verbose=0)\n",
    "book_model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7afabf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t t + 1\n",
       "7  80  90.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67322618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 276.864\n"
     ]
    }
   ],
   "source": [
    "EvaluationMetric.eval_mse(predict_y_test_df, book_model_predictions, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ac988a",
   "metadata": {},
   "source": [
    "## My implementation\n",
    "\n",
    "- Using my TSLearn library\n",
    "\n",
    "### Prediction model\n",
    "\n",
    "- Interpolation of in sample values \n",
    "- Use `50, 60, 70`, so X_test\n",
    "- True predictions `80, 90`, so y_test\n",
    "\n",
    "### Forecast model\n",
    "\n",
    "- Extrapolation of future values `\n",
    "- Use `70, 80, 90`, so X_test\n",
    "- Expected `100, 110`. We say expected because we don't know the actual values, thus no y_test. Expected as in we increment by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3c3df5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=3, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "\n",
    "mlp_predict_model = MLP(n_steps, hidden_size, output_size)\n",
    "mlp_predict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffb43a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=3, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_forecast_model = MLP(n_steps, hidden_size, output_size)\n",
    "mlp_forecast_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcae1763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 40/2000 [00:00<00:24, 80.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "    Predictions | Train loss: 4082.568603515625 | Test loss: 7801.7333984375\n",
      "    Forecasts | Train loss: 5153.3154296875\n",
      "Epoch: 10\n",
      "    Predictions | Train loss: 2974.27197265625 | Test loss: 5335.6865234375\n",
      "    Forecasts | Train loss: 3435.11328125\n",
      "Epoch: 20\n",
      "    Predictions | Train loss: 2056.011962890625 | Test loss: 3369.5048828125\n",
      "    Forecasts | Train loss: 2098.327392578125\n",
      "Epoch: 30\n",
      "    Predictions | Train loss: 1311.88232421875 | Test loss: 1862.939208984375\n",
      "    Forecasts | Train loss: 1133.962158203125\n",
      "Epoch: 40\n",
      "    Predictions | Train loss: 745.1611938476562 | Test loss: 809.2156982421875\n",
      "    Forecasts | Train loss: 518.3023681640625\n",
      "Epoch: 50\n",
      "    Predictions | Train loss: 362.3883361816406 | Test loss: 212.43104553222656\n",
      "    Forecasts | Train loss: 200.57962036132812\n",
      "Epoch: 60\n",
      "    Predictions | Train loss: 150.69720458984375 | Test loss: 6.719475746154785\n",
      "    Forecasts | Train loss: 88.98686981201172\n",
      "Epoch: 70\n",
      "    Predictions | Train loss: 66.50759887695312 | Test loss: 43.56928634643555\n",
      "    Forecasts | Train loss: 71.71699523925781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 161/2000 [00:00<00:07, 261.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80\n",
      "    Predictions | Train loss: 48.4417839050293 | Test loss: 146.49859619140625\n",
      "    Forecasts | Train loss: 72.62535858154297\n",
      "Epoch: 90\n",
      "    Predictions | Train loss: 48.60411071777344 | Test loss: 205.83245849609375\n",
      "    Forecasts | Train loss: 69.62776184082031\n",
      "Epoch: 100\n",
      "    Predictions | Train loss: 48.51105880737305 | Test loss: 208.72576904296875\n",
      "    Forecasts | Train loss: 65.83531951904297\n",
      "Epoch: 110\n",
      "    Predictions | Train loss: 47.21466064453125 | Test loss: 186.72190856933594\n",
      "    Forecasts | Train loss: 63.14654541015625\n",
      "Epoch: 120\n",
      "    Predictions | Train loss: 46.266109466552734 | Test loss: 165.19309997558594\n",
      "    Forecasts | Train loss: 61.189735412597656\n",
      "Epoch: 130\n",
      "    Predictions | Train loss: 45.7205696105957 | Test loss: 152.63827514648438\n",
      "    Forecasts | Train loss: 59.23064422607422\n",
      "Epoch: 140\n",
      "    Predictions | Train loss: 45.238189697265625 | Test loss: 148.05322265625\n",
      "    Forecasts | Train loss: 57.2569694519043\n",
      "Epoch: 150\n",
      "    Predictions | Train loss: 44.72135543823242 | Test loss: 147.67051696777344\n",
      "    Forecasts | Train loss: 55.27428436279297\n",
      "Epoch: 160\n",
      "    Predictions | Train loss: 44.188743591308594 | Test loss: 148.19317626953125\n",
      "    Forecasts | Train loss: 53.243797302246094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 241/2000 [00:01<00:05, 325.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170\n",
      "    Predictions | Train loss: 43.6480712890625 | Test loss: 147.90673828125\n",
      "    Forecasts | Train loss: 51.1898193359375\n",
      "Epoch: 180\n",
      "    Predictions | Train loss: 43.093868255615234 | Test loss: 146.54019165039062\n",
      "    Forecasts | Train loss: 49.116859436035156\n",
      "Epoch: 190\n",
      "    Predictions | Train loss: 42.524898529052734 | Test loss: 144.54002380371094\n",
      "    Forecasts | Train loss: 47.033958435058594\n",
      "Epoch: 200\n",
      "    Predictions | Train loss: 41.941219329833984 | Test loss: 142.39541625976562\n",
      "    Forecasts | Train loss: 44.95040512084961\n",
      "Epoch: 210\n",
      "    Predictions | Train loss: 41.331485748291016 | Test loss: 140.33963012695312\n",
      "    Forecasts | Train loss: 42.9213752746582\n",
      "Epoch: 220\n",
      "    Predictions | Train loss: 40.69643783569336 | Test loss: 138.36770629882812\n",
      "    Forecasts | Train loss: 40.945281982421875\n",
      "Epoch: 230\n",
      "    Predictions | Train loss: 40.0355224609375 | Test loss: 136.391357421875\n",
      "    Forecasts | Train loss: 38.98823547363281\n",
      "Epoch: 240\n",
      "    Predictions | Train loss: 39.3465690612793 | Test loss: 134.34307861328125\n",
      "    Forecasts | Train loss: 37.081390380859375\n",
      "Epoch: 250\n",
      "    Predictions | Train loss: 38.626522064208984 | Test loss: 132.20162963867188\n",
      "    Forecasts | Train loss: 35.19922637939453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 321/2000 [00:01<00:04, 358.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 260\n",
      "    Predictions | Train loss: 37.871421813964844 | Test loss: 129.97268676757812\n",
      "    Forecasts | Train loss: 33.35222625732422\n",
      "Epoch: 270\n",
      "    Predictions | Train loss: 37.076683044433594 | Test loss: 127.66363525390625\n",
      "    Forecasts | Train loss: 31.54109764099121\n",
      "Epoch: 280\n",
      "    Predictions | Train loss: 36.23834228515625 | Test loss: 125.27082824707031\n",
      "    Forecasts | Train loss: 29.793121337890625\n",
      "Epoch: 290\n",
      "    Predictions | Train loss: 35.36841583251953 | Test loss: 122.7021484375\n",
      "    Forecasts | Train loss: 28.065942764282227\n",
      "Epoch: 300\n",
      "    Predictions | Train loss: 34.453521728515625 | Test loss: 119.81637573242188\n",
      "    Forecasts | Train loss: 26.390514373779297\n",
      "Epoch: 310\n",
      "    Predictions | Train loss: 33.517822265625 | Test loss: 116.63575744628906\n",
      "    Forecasts | Train loss: 24.772232055664062\n",
      "Epoch: 320\n",
      "    Predictions | Train loss: 32.70011901855469 | Test loss: 113.15094757080078\n",
      "    Forecasts | Train loss: 23.19695281982422\n",
      "Epoch: 330\n",
      "    Predictions | Train loss: 31.87788200378418 | Test loss: 109.75419616699219\n",
      "    Forecasts | Train loss: 21.673664093017578\n",
      "Epoch: 340\n",
      "    Predictions | Train loss: 31.053691864013672 | Test loss: 106.85636901855469\n",
      "    Forecasts | Train loss: 20.2134952545166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 402/2000 [00:01<00:04, 381.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350\n",
      "    Predictions | Train loss: 30.228408813476562 | Test loss: 104.3765869140625\n",
      "    Forecasts | Train loss: 18.79545783996582\n",
      "Epoch: 360\n",
      "    Predictions | Train loss: 29.402751922607422 | Test loss: 102.03355407714844\n",
      "    Forecasts | Train loss: 17.435712814331055\n",
      "Epoch: 370\n",
      "    Predictions | Train loss: 28.57728385925293 | Test loss: 99.66683959960938\n",
      "    Forecasts | Train loss: 16.143936157226562\n",
      "Epoch: 380\n",
      "    Predictions | Train loss: 27.752347946166992 | Test loss: 97.28398895263672\n",
      "    Forecasts | Train loss: 14.893930435180664\n",
      "Epoch: 390\n",
      "    Predictions | Train loss: 26.928508758544922 | Test loss: 94.94396209716797\n",
      "    Forecasts | Train loss: 13.7139253616333\n",
      "Epoch: 400\n",
      "    Predictions | Train loss: 26.106124877929688 | Test loss: 92.672119140625\n",
      "    Forecasts | Train loss: 12.591259956359863\n",
      "Epoch: 410\n",
      "    Predictions | Train loss: 25.287124633789062 | Test loss: 90.45851135253906\n",
      "    Forecasts | Train loss: 11.525552749633789\n",
      "Epoch: 420\n",
      "    Predictions | Train loss: 24.470745086669922 | Test loss: 88.15830993652344\n",
      "    Forecasts | Train loss: 10.516473770141602\n",
      "Epoch: 430\n",
      "    Predictions | Train loss: 23.659927368164062 | Test loss: 85.61488342285156\n",
      "    Forecasts | Train loss: 9.577738761901855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 482/2000 [00:01<00:03, 390.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 440\n",
      "    Predictions | Train loss: 22.85124969482422 | Test loss: 82.97552490234375\n",
      "    Forecasts | Train loss: 8.687599182128906\n",
      "Epoch: 450\n",
      "    Predictions | Train loss: 22.048768997192383 | Test loss: 80.44856262207031\n",
      "    Forecasts | Train loss: 7.860726356506348\n",
      "Epoch: 460\n",
      "    Predictions | Train loss: 21.251502990722656 | Test loss: 78.00849151611328\n",
      "    Forecasts | Train loss: 7.0868659019470215\n",
      "Epoch: 470\n",
      "    Predictions | Train loss: 20.459150314331055 | Test loss: 75.53173065185547\n",
      "    Forecasts | Train loss: 6.3682756423950195\n",
      "Epoch: 480\n",
      "    Predictions | Train loss: 19.67556381225586 | Test loss: 73.07356262207031\n",
      "    Forecasts | Train loss: 5.709125518798828\n",
      "Epoch: 490\n",
      "    Predictions | Train loss: 18.89783477783203 | Test loss: 70.63422393798828\n",
      "    Forecasts | Train loss: 5.09881591796875\n",
      "Epoch: 500\n",
      "    Predictions | Train loss: 18.129451751708984 | Test loss: 68.23135375976562\n",
      "    Forecasts | Train loss: 4.540313720703125\n",
      "Epoch: 510\n",
      "    Predictions | Train loss: 17.370372772216797 | Test loss: 65.89228057861328\n",
      "    Forecasts | Train loss: 4.026199817657471\n",
      "Epoch: 520\n",
      "    Predictions | Train loss: 16.62237548828125 | Test loss: 63.520904541015625\n",
      "    Forecasts | Train loss: 3.5620980262756348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 604/2000 [00:02<00:03, 395.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 530\n",
      "    Predictions | Train loss: 15.89345645904541 | Test loss: 61.282569885253906\n",
      "    Forecasts | Train loss: 3.137002944946289\n",
      "Epoch: 540\n",
      "    Predictions | Train loss: 15.175085067749023 | Test loss: 59.01912307739258\n",
      "    Forecasts | Train loss: 2.7588212490081787\n",
      "Epoch: 550\n",
      "    Predictions | Train loss: 14.48808479309082 | Test loss: 56.88029479980469\n",
      "    Forecasts | Train loss: 2.411323070526123\n",
      "Epoch: 560\n",
      "    Predictions | Train loss: 13.814434051513672 | Test loss: 54.77648162841797\n",
      "    Forecasts | Train loss: 2.1044530868530273\n",
      "Epoch: 570\n",
      "    Predictions | Train loss: 13.153570175170898 | Test loss: 52.58741760253906\n",
      "    Forecasts | Train loss: 1.8284505605697632\n",
      "Epoch: 580\n",
      "    Predictions | Train loss: 12.51028823852539 | Test loss: 50.54969024658203\n",
      "    Forecasts | Train loss: 1.5832674503326416\n",
      "Epoch: 590\n",
      "    Predictions | Train loss: 11.882176399230957 | Test loss: 48.52727127075195\n",
      "    Forecasts | Train loss: 1.3691375255584717\n",
      "Epoch: 600\n",
      "    Predictions | Train loss: 11.275111198425293 | Test loss: 46.52888107299805\n",
      "    Forecasts | Train loss: 1.1769850254058838\n",
      "Epoch: 610\n",
      "    Predictions | Train loss: 10.68545913696289 | Test loss: 44.614768981933594\n",
      "    Forecasts | Train loss: 1.0094431638717651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 686/2000 [00:02<00:03, 400.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 620\n",
      "    Predictions | Train loss: 10.11506175994873 | Test loss: 42.6873664855957\n",
      "    Forecasts | Train loss: 0.8627126812934875\n",
      "Epoch: 630\n",
      "    Predictions | Train loss: 9.557247161865234 | Test loss: 40.85413360595703\n",
      "    Forecasts | Train loss: 0.7366355657577515\n",
      "Epoch: 640\n",
      "    Predictions | Train loss: 9.020241737365723 | Test loss: 39.0836067199707\n",
      "    Forecasts | Train loss: 0.6247140169143677\n",
      "Epoch: 650\n",
      "    Predictions | Train loss: 8.500743865966797 | Test loss: 37.30133819580078\n",
      "    Forecasts | Train loss: 0.5292452573776245\n",
      "Epoch: 660\n",
      "    Predictions | Train loss: 8.001798629760742 | Test loss: 35.641143798828125\n",
      "    Forecasts | Train loss: 0.4467509388923645\n",
      "Epoch: 670\n",
      "    Predictions | Train loss: 7.519644737243652 | Test loss: 33.99699783325195\n",
      "    Forecasts | Train loss: 0.3766820430755615\n",
      "Epoch: 680\n",
      "    Predictions | Train loss: 7.057275772094727 | Test loss: 32.387908935546875\n",
      "    Forecasts | Train loss: 0.3158915042877197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 768/2000 [00:02<00:03, 357.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 690\n",
      "    Predictions | Train loss: 6.614184379577637 | Test loss: 30.89086151123047\n",
      "    Forecasts | Train loss: 0.26466095447540283\n",
      "Epoch: 700\n",
      "    Predictions | Train loss: 6.190215110778809 | Test loss: 29.37818145751953\n",
      "    Forecasts | Train loss: 0.22090813517570496\n",
      "Epoch: 710\n",
      "    Predictions | Train loss: 5.782928466796875 | Test loss: 27.95938491821289\n",
      "    Forecasts | Train loss: 0.1841737926006317\n",
      "Epoch: 720\n",
      "    Predictions | Train loss: 5.395397663116455 | Test loss: 26.60717010498047\n",
      "    Forecasts | Train loss: 0.15297725796699524\n",
      "Epoch: 730\n",
      "    Predictions | Train loss: 5.025638580322266 | Test loss: 25.245447158813477\n",
      "    Forecasts | Train loss: 0.12693917751312256\n",
      "Epoch: 740\n",
      "    Predictions | Train loss: 4.675687313079834 | Test loss: 24.01026153564453\n",
      "    Forecasts | Train loss: 0.10505913197994232\n",
      "Epoch: 750\n",
      "    Predictions | Train loss: 4.341620445251465 | Test loss: 22.795495986938477\n",
      "    Forecasts | Train loss: 0.08683750778436661\n",
      "Epoch: 760\n",
      "    Predictions | Train loss: 4.026823043823242 | Test loss: 21.660404205322266\n",
      "    Forecasts | Train loss: 0.07174593210220337\n",
      "Epoch: 770\n",
      "    Predictions | Train loss: 3.7289609909057617 | Test loss: 20.569595336914062\n",
      "    Forecasts | Train loss: 0.05906546860933304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 850/2000 [00:02<00:03, 379.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 780\n",
      "    Predictions | Train loss: 3.4468038082122803 | Test loss: 19.461538314819336\n",
      "    Forecasts | Train loss: 0.04855594411492348\n",
      "Epoch: 790\n",
      "    Predictions | Train loss: 3.1827027797698975 | Test loss: 18.473217010498047\n",
      "    Forecasts | Train loss: 0.039937298744916916\n",
      "Epoch: 800\n",
      "    Predictions | Train loss: 2.933042049407959 | Test loss: 17.525371551513672\n",
      "    Forecasts | Train loss: 0.03282161429524422\n",
      "Epoch: 810\n",
      "    Predictions | Train loss: 2.699497938156128 | Test loss: 16.6082820892334\n",
      "    Forecasts | Train loss: 0.02700144611299038\n",
      "Epoch: 820\n",
      "    Predictions | Train loss: 2.4810543060302734 | Test loss: 15.756132125854492\n",
      "    Forecasts | Train loss: 0.022216223180294037\n",
      "Epoch: 830\n",
      "    Predictions | Train loss: 2.2765603065490723 | Test loss: 14.89641284942627\n",
      "    Forecasts | Train loss: 0.0183182992041111\n",
      "Epoch: 840\n",
      "    Predictions | Train loss: 2.0855817794799805 | Test loss: 14.118973731994629\n",
      "    Forecasts | Train loss: 0.015125279314815998\n",
      "Epoch: 850\n",
      "    Predictions | Train loss: 1.907665729522705 | Test loss: 13.404415130615234\n",
      "    Forecasts | Train loss: 0.01249903067946434\n",
      "Epoch: 860\n",
      "    Predictions | Train loss: 1.742395043373108 | Test loss: 12.685583114624023\n",
      "    Forecasts | Train loss: 0.010370015166699886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 932/2000 [00:02<00:02, 393.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 870\n",
      "    Predictions | Train loss: 1.5895860195159912 | Test loss: 12.038135528564453\n",
      "    Forecasts | Train loss: 0.008648985996842384\n",
      "Epoch: 880\n",
      "    Predictions | Train loss: 1.4485499858856201 | Test loss: 11.396577835083008\n",
      "    Forecasts | Train loss: 0.007253679446876049\n",
      "Epoch: 890\n",
      "    Predictions | Train loss: 1.3164596557617188 | Test loss: 10.831451416015625\n",
      "    Forecasts | Train loss: 0.0061157699674367905\n",
      "Epoch: 900\n",
      "    Predictions | Train loss: 1.1955034732818604 | Test loss: 10.27676010131836\n",
      "    Forecasts | Train loss: 0.005196911282837391\n",
      "Epoch: 910\n",
      "    Predictions | Train loss: 1.0839015245437622 | Test loss: 9.722417831420898\n",
      "    Forecasts | Train loss: 0.004454704932868481\n",
      "Epoch: 920\n",
      "    Predictions | Train loss: 0.9818292260169983 | Test loss: 9.27711009979248\n",
      "    Forecasts | Train loss: 0.003855773014947772\n",
      "Epoch: 930\n",
      "    Predictions | Train loss: 0.8875718712806702 | Test loss: 8.792357444763184\n",
      "    Forecasts | Train loss: 0.0033707101829349995\n",
      "Epoch: 940\n",
      "    Predictions | Train loss: 0.8017067909240723 | Test loss: 8.347270965576172\n",
      "    Forecasts | Train loss: 0.0029808382969349623\n",
      "Epoch: 950\n",
      "    Predictions | Train loss: 0.7230634093284607 | Test loss: 7.97191047668457\n",
      "    Forecasts | Train loss: 0.0026632496155798435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1014/2000 [00:03<00:02, 399.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 960\n",
      "    Predictions | Train loss: 0.6510964632034302 | Test loss: 7.564513206481934\n",
      "    Forecasts | Train loss: 0.002407832769677043\n",
      "Epoch: 970\n",
      "    Predictions | Train loss: 0.5858541131019592 | Test loss: 7.236928939819336\n",
      "    Forecasts | Train loss: 0.002201929222792387\n",
      "Epoch: 980\n",
      "    Predictions | Train loss: 0.5261295437812805 | Test loss: 6.888216495513916\n",
      "    Forecasts | Train loss: 0.0020353328436613083\n",
      "Epoch: 990\n",
      "    Predictions | Train loss: 0.47217947244644165 | Test loss: 6.564606189727783\n",
      "    Forecasts | Train loss: 0.0019004890928044915\n",
      "Epoch: 1000\n",
      "    Predictions | Train loss: 0.4231800436973572 | Test loss: 6.295420169830322\n",
      "    Forecasts | Train loss: 0.001791392220184207\n",
      "Epoch: 1010\n",
      "    Predictions | Train loss: 0.378704309463501 | Test loss: 6.000050067901611\n",
      "    Forecasts | Train loss: 0.0017016360070556402\n",
      "Epoch: 1020\n",
      "    Predictions | Train loss: 0.338708758354187 | Test loss: 5.7674431800842285\n",
      "    Forecasts | Train loss: 0.00162740726955235\n",
      "Epoch: 1030\n",
      "    Predictions | Train loss: 0.3023683726787567 | Test loss: 5.516548156738281\n",
      "    Forecasts | Train loss: 0.0015636930475011468\n",
      "Epoch: 1040\n",
      "    Predictions | Train loss: 0.26980507373809814 | Test loss: 5.2857489585876465\n",
      "    Forecasts | Train loss: 0.001509126741439104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1096/2000 [00:03<00:02, 396.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1050\n",
      "    Predictions | Train loss: 0.2404525727033615 | Test loss: 5.095760345458984\n",
      "    Forecasts | Train loss: 0.001461303443647921\n",
      "Epoch: 1060\n",
      "    Predictions | Train loss: 0.2140018194913864 | Test loss: 4.883667945861816\n",
      "    Forecasts | Train loss: 0.0014189378125593066\n",
      "Epoch: 1070\n",
      "    Predictions | Train loss: 0.19038791954517365 | Test loss: 4.721042633056641\n",
      "    Forecasts | Train loss: 0.0013812007382512093\n",
      "Epoch: 1080\n",
      "    Predictions | Train loss: 0.16921567916870117 | Test loss: 4.543015480041504\n",
      "    Forecasts | Train loss: 0.0013474782463163137\n",
      "Epoch: 1090\n",
      "    Predictions | Train loss: 0.15012116730213165 | Test loss: 4.390303611755371\n",
      "    Forecasts | Train loss: 0.0013172716135159135\n",
      "Epoch: 1100\n",
      "    Predictions | Train loss: 0.13311409950256348 | Test loss: 4.250165939331055\n",
      "    Forecasts | Train loss: 0.001290369895286858\n",
      "Epoch: 1110\n",
      "    Predictions | Train loss: 0.11793699860572815 | Test loss: 4.103909492492676\n",
      "    Forecasts | Train loss: 0.0012661757646128535\n",
      "Epoch: 1120\n",
      "    Predictions | Train loss: 0.10444606840610504 | Test loss: 3.9902961254119873\n",
      "    Forecasts | Train loss: 0.001244447543285787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 1179/2000 [00:03<00:02, 402.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1130\n",
      "    Predictions | Train loss: 0.09235240519046783 | Test loss: 3.861619472503662\n",
      "    Forecasts | Train loss: 0.001224992796778679\n",
      "Epoch: 1140\n",
      "    Predictions | Train loss: 0.08165983855724335 | Test loss: 3.7511041164398193\n",
      "    Forecasts | Train loss: 0.0012073360849171877\n",
      "Epoch: 1150\n",
      "    Predictions | Train loss: 0.07210825383663177 | Test loss: 3.657754898071289\n",
      "    Forecasts | Train loss: 0.0011914772912859917\n",
      "Epoch: 1160\n",
      "    Predictions | Train loss: 0.063649483025074 | Test loss: 3.556278705596924\n",
      "    Forecasts | Train loss: 0.00117741827853024\n",
      "Epoch: 1170\n",
      "    Predictions | Train loss: 0.05615340545773506 | Test loss: 3.4767837524414062\n",
      "    Forecasts | Train loss: 0.0011644457699730992\n",
      "Epoch: 1180\n",
      "    Predictions | Train loss: 0.04948144406080246 | Test loss: 3.3865203857421875\n",
      "    Forecasts | Train loss: 0.0011529179755598307\n",
      "Epoch: 1190\n",
      "    Predictions | Train loss: 0.04360818862915039 | Test loss: 3.316783905029297\n",
      "    Forecasts | Train loss: 0.0011420949595049024\n",
      "Epoch: 1200\n",
      "    Predictions | Train loss: 0.038377195596694946 | Test loss: 3.243631601333618\n",
      "    Forecasts | Train loss: 0.0011327920947223902\n",
      "Epoch: 1210\n",
      "    Predictions | Train loss: 0.03377674147486687 | Test loss: 3.1763429641723633\n",
      "    Forecasts | Train loss: 0.0011240557068958879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1263/2000 [00:03<00:01, 406.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1220\n",
      "    Predictions | Train loss: 0.02970941737294197 | Test loss: 3.1203269958496094\n",
      "    Forecasts | Train loss: 0.001116342144086957\n",
      "Epoch: 1230\n",
      "    Predictions | Train loss: 0.02611076459288597 | Test loss: 3.056741952896118\n",
      "    Forecasts | Train loss: 0.0011090830666944385\n",
      "Epoch: 1240\n",
      "    Predictions | Train loss: 0.022951118648052216 | Test loss: 3.0138914585113525\n",
      "    Forecasts | Train loss: 0.0011026434367522597\n",
      "Epoch: 1250\n",
      "    Predictions | Train loss: 0.020147401839494705 | Test loss: 2.9579851627349854\n",
      "    Forecasts | Train loss: 0.0010965315159410238\n",
      "Epoch: 1260\n",
      "    Predictions | Train loss: 0.017694029957056046 | Test loss: 2.916721820831299\n",
      "    Forecasts | Train loss: 0.0010908993426710367\n",
      "Epoch: 1270\n",
      "    Predictions | Train loss: 0.015522819943726063 | Test loss: 2.8745837211608887\n",
      "    Forecasts | Train loss: 0.0010858873138204217\n",
      "Epoch: 1280\n",
      "    Predictions | Train loss: 0.013617893680930138 | Test loss: 2.8327064514160156\n",
      "    Forecasts | Train loss: 0.0010811156826093793\n",
      "Epoch: 1290\n",
      "    Predictions | Train loss: 0.011943685822188854 | Test loss: 2.8027267456054688\n",
      "    Forecasts | Train loss: 0.00107674952596426\n",
      "Epoch: 1300\n",
      "    Predictions | Train loss: 0.010466997511684895 | Test loss: 2.763582229614258\n",
      "    Forecasts | Train loss: 0.0010723790619522333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 1385/2000 [00:04<00:01, 349.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1310\n",
      "    Predictions | Train loss: 0.00917682982981205 | Test loss: 2.7393319606781006\n",
      "    Forecasts | Train loss: 0.001068445504643023\n",
      "Epoch: 1320\n",
      "    Predictions | Train loss: 0.008036612533032894 | Test loss: 2.705852508544922\n",
      "    Forecasts | Train loss: 0.0010647744638845325\n",
      "Epoch: 1330\n",
      "    Predictions | Train loss: 0.00704112509265542 | Test loss: 2.6818106174468994\n",
      "    Forecasts | Train loss: 0.001061339513398707\n",
      "Epoch: 1340\n",
      "    Predictions | Train loss: 0.006166860926896334 | Test loss: 2.6576037406921387\n",
      "    Forecasts | Train loss: 0.001057961257174611\n",
      "Epoch: 1350\n",
      "    Predictions | Train loss: 0.005396716762334108 | Test loss: 2.6352956295013428\n",
      "    Forecasts | Train loss: 0.0010547414422035217\n",
      "Epoch: 1360\n",
      "    Predictions | Train loss: 0.004722003825008869 | Test loss: 2.6153578758239746\n",
      "    Forecasts | Train loss: 0.0010516414185985923\n",
      "Epoch: 1370\n",
      "    Predictions | Train loss: 0.004131287336349487 | Test loss: 2.5936684608459473\n",
      "    Forecasts | Train loss: 0.0010487415129318833\n",
      "Epoch: 1380\n",
      "    Predictions | Train loss: 0.0036154945846647024 | Test loss: 2.5791826248168945\n",
      "    Forecasts | Train loss: 0.0010458629112690687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1468/2000 [00:04<00:01, 378.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1390\n",
      "    Predictions | Train loss: 0.0031608943827450275 | Test loss: 2.5593748092651367\n",
      "    Forecasts | Train loss: 0.0010432045673951507\n",
      "Epoch: 1400\n",
      "    Predictions | Train loss: 0.0027647558599710464 | Test loss: 2.5483622550964355\n",
      "    Forecasts | Train loss: 0.0010403023334220052\n",
      "Epoch: 1410\n",
      "    Predictions | Train loss: 0.002415918977931142 | Test loss: 2.5310659408569336\n",
      "    Forecasts | Train loss: 0.0010375356068834662\n",
      "Epoch: 1420\n",
      "    Predictions | Train loss: 0.0021117152646183968 | Test loss: 2.519690990447998\n",
      "    Forecasts | Train loss: 0.0010350237134844065\n",
      "Epoch: 1430\n",
      "    Predictions | Train loss: 0.0018445947207510471 | Test loss: 2.507598638534546\n",
      "    Forecasts | Train loss: 0.0010323843453079462\n",
      "Epoch: 1440\n",
      "    Predictions | Train loss: 0.0016116659389808774 | Test loss: 2.4974005222320557\n",
      "    Forecasts | Train loss: 0.0010298979468643665\n",
      "Epoch: 1450\n",
      "    Predictions | Train loss: 0.0014070910401642323 | Test loss: 2.4871809482574463\n",
      "    Forecasts | Train loss: 0.0010275436798110604\n",
      "Epoch: 1460\n",
      "    Predictions | Train loss: 0.001228703884407878 | Test loss: 2.4768738746643066\n",
      "    Forecasts | Train loss: 0.0010248908074572682\n",
      "Epoch: 1470\n",
      "    Predictions | Train loss: 0.001072221901267767 | Test loss: 2.4705758094787598\n",
      "    Forecasts | Train loss: 0.0010223210556432605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1549/2000 [00:04<00:01, 360.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1480\n",
      "    Predictions | Train loss: 0.0009357182425446808 | Test loss: 2.4611120223999023\n",
      "    Forecasts | Train loss: 0.0010198326781392097\n",
      "Epoch: 1490\n",
      "    Predictions | Train loss: 0.0008163683814927936 | Test loss: 2.454838752746582\n",
      "    Forecasts | Train loss: 0.001017568982206285\n",
      "Epoch: 1500\n",
      "    Predictions | Train loss: 0.0007118709618225694 | Test loss: 2.446763515472412\n",
      "    Forecasts | Train loss: 0.0010151166934520006\n",
      "Epoch: 1510\n",
      "    Predictions | Train loss: 0.0006205535028129816 | Test loss: 2.443513870239258\n",
      "    Forecasts | Train loss: 0.0010127811692655087\n",
      "Epoch: 1520\n",
      "    Predictions | Train loss: 0.000540813896805048 | Test loss: 2.436382293701172\n",
      "    Forecasts | Train loss: 0.0010101401712745428\n",
      "Epoch: 1530\n",
      "    Predictions | Train loss: 0.00047121680108830333 | Test loss: 2.4311752319335938\n",
      "    Forecasts | Train loss: 0.0010078628547489643\n",
      "Epoch: 1540\n",
      "    Predictions | Train loss: 0.0004104871186427772 | Test loss: 2.4259884357452393\n",
      "    Forecasts | Train loss: 0.0010053652804344893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1633/2000 [00:04<00:00, 384.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1550\n",
      "    Predictions | Train loss: 0.0003572844434529543 | Test loss: 2.4235830307006836\n",
      "    Forecasts | Train loss: 0.001002939185127616\n",
      "Epoch: 1560\n",
      "    Predictions | Train loss: 0.0003108905802946538 | Test loss: 2.4184885025024414\n",
      "    Forecasts | Train loss: 0.0010005627991631627\n",
      "Epoch: 1570\n",
      "    Predictions | Train loss: 0.00027050095377489924 | Test loss: 2.4148364067077637\n",
      "    Forecasts | Train loss: 0.0009982092306017876\n",
      "Epoch: 1580\n",
      "    Predictions | Train loss: 0.0002351420116610825 | Test loss: 2.411079168319702\n",
      "    Forecasts | Train loss: 0.0009957067668437958\n",
      "Epoch: 1590\n",
      "    Predictions | Train loss: 0.00020434337784536183 | Test loss: 2.4094655513763428\n",
      "    Forecasts | Train loss: 0.0009934103582054377\n",
      "Epoch: 1600\n",
      "    Predictions | Train loss: 0.00017743106582202017 | Test loss: 2.4062323570251465\n",
      "    Forecasts | Train loss: 0.0009909083601087332\n",
      "Epoch: 1610\n",
      "    Predictions | Train loss: 0.0001540803350508213 | Test loss: 2.403557062149048\n",
      "    Forecasts | Train loss: 0.0009886038023978472\n",
      "Epoch: 1620\n",
      "    Predictions | Train loss: 0.00013369157386478037 | Test loss: 2.400681257247925\n",
      "    Forecasts | Train loss: 0.0009860448772087693\n",
      "Epoch: 1630\n",
      "    Predictions | Train loss: 0.00011595460819080472 | Test loss: 2.3994879722595215\n",
      "    Forecasts | Train loss: 0.0009836952667683363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1716/2000 [00:04<00:00, 396.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1640\n",
      "    Predictions | Train loss: 0.0001005084122880362 | Test loss: 2.397516965866089\n",
      "    Forecasts | Train loss: 0.0009811557829380035\n",
      "Epoch: 1650\n",
      "    Predictions | Train loss: 8.701872866367921e-05 | Test loss: 2.39554500579834\n",
      "    Forecasts | Train loss: 0.000978856929577887\n",
      "Epoch: 1660\n",
      "    Predictions | Train loss: 7.532109884778038e-05 | Test loss: 2.393460750579834\n",
      "    Forecasts | Train loss: 0.0009764390997588634\n",
      "Epoch: 1670\n",
      "    Predictions | Train loss: 6.518395093735307e-05 | Test loss: 2.392472982406616\n",
      "    Forecasts | Train loss: 0.0009738461812958121\n",
      "Epoch: 1680\n",
      "    Predictions | Train loss: 5.638032598653808e-05 | Test loss: 2.391418695449829\n",
      "    Forecasts | Train loss: 0.0009713945910334587\n",
      "Epoch: 1690\n",
      "    Predictions | Train loss: 4.8739871999714524e-05 | Test loss: 2.3898427486419678\n",
      "    Forecasts | Train loss: 0.000969165179412812\n",
      "Epoch: 1700\n",
      "    Predictions | Train loss: 4.208402242511511e-05 | Test loss: 2.3889517784118652\n",
      "    Forecasts | Train loss: 0.0009666156256571412\n",
      "Epoch: 1710\n",
      "    Predictions | Train loss: 3.630064020399004e-05 | Test loss: 2.3875107765197754\n",
      "    Forecasts | Train loss: 0.0009639393538236618\n",
      "Epoch: 1720\n",
      "    Predictions | Train loss: 3.130039112875238e-05 | Test loss: 2.3870785236358643\n",
      "    Forecasts | Train loss: 0.0009617279283702374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1797/2000 [00:05<00:00, 370.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1730\n",
      "    Predictions | Train loss: 2.6979350877809338e-05 | Test loss: 2.3860535621643066\n",
      "    Forecasts | Train loss: 0.0009591879206709564\n",
      "Epoch: 1740\n",
      "    Predictions | Train loss: 2.3221513401949778e-05 | Test loss: 2.3853368759155273\n",
      "    Forecasts | Train loss: 0.00095664820400998\n",
      "Epoch: 1750\n",
      "    Predictions | Train loss: 1.998883999476675e-05 | Test loss: 2.3847718238830566\n",
      "    Forecasts | Train loss: 0.000953890208620578\n",
      "Epoch: 1760\n",
      "    Predictions | Train loss: 1.718969360808842e-05 | Test loss: 2.3838958740234375\n",
      "    Forecasts | Train loss: 0.0009516162681393325\n",
      "Epoch: 1770\n",
      "    Predictions | Train loss: 1.4744469808647409e-05 | Test loss: 2.3835511207580566\n",
      "    Forecasts | Train loss: 0.0009490535594522953\n",
      "Epoch: 1780\n",
      "    Predictions | Train loss: 1.2661219443543814e-05 | Test loss: 2.382899761199951\n",
      "    Forecasts | Train loss: 0.00094651710242033\n",
      "Epoch: 1790\n",
      "    Predictions | Train loss: 1.084972609532997e-05 | Test loss: 2.3824191093444824\n",
      "    Forecasts | Train loss: 0.0009440571302548051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1880/2000 [00:05<00:00, 390.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1800\n",
      "    Predictions | Train loss: 9.296903954236768e-06 | Test loss: 2.3820855617523193\n",
      "    Forecasts | Train loss: 0.0009415600216016173\n",
      "Epoch: 1810\n",
      "    Predictions | Train loss: 7.958296919241548e-06 | Test loss: 2.381568670272827\n",
      "    Forecasts | Train loss: 0.000938881654292345\n",
      "Epoch: 1820\n",
      "    Predictions | Train loss: 6.816620953031816e-06 | Test loss: 2.381307601928711\n",
      "    Forecasts | Train loss: 0.0009365456062369049\n",
      "Epoch: 1830\n",
      "    Predictions | Train loss: 5.821741069667041e-06 | Test loss: 2.3810126781463623\n",
      "    Forecasts | Train loss: 0.0009338847594335675\n",
      "Epoch: 1840\n",
      "    Predictions | Train loss: 4.9778955144574866e-06 | Test loss: 2.380585193634033\n",
      "    Forecasts | Train loss: 0.0009312977199442685\n",
      "Epoch: 1850\n",
      "    Predictions | Train loss: 4.238063411321491e-06 | Test loss: 2.380398750305176\n",
      "    Forecasts | Train loss: 0.000928897294215858\n",
      "Epoch: 1860\n",
      "    Predictions | Train loss: 3.6198616726323962e-06 | Test loss: 2.380192995071411\n",
      "    Forecasts | Train loss: 0.0009263610700145364\n",
      "Epoch: 1870\n",
      "    Predictions | Train loss: 3.0868377507431433e-06 | Test loss: 2.379931926727295\n",
      "    Forecasts | Train loss: 0.0009238513885065913\n",
      "Epoch: 1880\n",
      "    Predictions | Train loss: 2.615794073790312e-06 | Test loss: 2.3797597885131836\n",
      "    Forecasts | Train loss: 0.0009211452561430633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1962/2000 [00:05<00:00, 398.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1890\n",
      "    Predictions | Train loss: 2.221922841272317e-06 | Test loss: 2.379636764526367\n",
      "    Forecasts | Train loss: 0.0009186103707179427\n",
      "Epoch: 1900\n",
      "    Predictions | Train loss: 1.894079105113633e-06 | Test loss: 2.379364490509033\n",
      "    Forecasts | Train loss: 0.0009160034242086112\n",
      "Epoch: 1910\n",
      "    Predictions | Train loss: 1.6062749637058005e-06 | Test loss: 2.3792264461517334\n",
      "    Forecasts | Train loss: 0.0009134296560660005\n",
      "Epoch: 1920\n",
      "    Predictions | Train loss: 1.351967512164265e-06 | Test loss: 2.3791391849517822\n",
      "    Forecasts | Train loss: 0.000911066890694201\n",
      "Epoch: 1930\n",
      "    Predictions | Train loss: 1.1485226423246786e-06 | Test loss: 2.3790433406829834\n",
      "    Forecasts | Train loss: 0.0009083664044737816\n",
      "Epoch: 1940\n",
      "    Predictions | Train loss: 9.753766789799556e-07 | Test loss: 2.3788557052612305\n",
      "    Forecasts | Train loss: 0.0009056509588845074\n",
      "Epoch: 1950\n",
      "    Predictions | Train loss: 8.269762474810705e-07 | Test loss: 2.378774642944336\n",
      "    Forecasts | Train loss: 0.0009033114765770733\n",
      "Epoch: 1960\n",
      "    Predictions | Train loss: 6.943610060261562e-07 | Test loss: 2.3786869049072266\n",
      "    Forecasts | Train loss: 0.0009005172178149223\n",
      "Epoch: 1970\n",
      "    Predictions | Train loss: 5.864039849257097e-07 | Test loss: 2.3786227703094482\n",
      "    Forecasts | Train loss: 0.0008978716214187443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:05<00:00, 345.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1980\n",
      "    Predictions | Train loss: 4.946541594108567e-07 | Test loss: 2.3785858154296875\n",
      "    Forecasts | Train loss: 0.000895430042874068\n",
      "Epoch: 1990\n",
      "    Predictions | Train loss: 4.1406201489735395e-07 | Test loss: 2.3784661293029785\n",
      "    Forecasts | Train loss: 0.0008927808376029134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# #times to loop through the training\n",
    "# Hyperparameter\n",
    "epochs = 2000\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "predict_optimizer = torch.optim.Adam(mlp_predict_model.parameters())\n",
    "predict_configs = [criterion, predict_optimizer]\n",
    "\n",
    "forecast_optimizer = torch.optim.Adam(mlp_forecast_model.parameters())\n",
    "forecast_configs = [criterion, forecast_optimizer]\n",
    "\n",
    "# Track different setups (ie: lr, etc) to compare this experiment to future experiments\n",
    "epoch_count = []\n",
    "train_pred_values = []\n",
    "test_pred_values = []\n",
    "\n",
    "predict_train_loss_values = []\n",
    "predict_test_loss_values = []\n",
    "\n",
    "forecast_train_loss_values = []\n",
    "forecast_test_loss_values = []\n",
    "\n",
    "### Training\n",
    "# 0. Loop through the training\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # In-Sample Prediction\n",
    "    train_predictions, predict_train_loss = mlp_predict_model.train_model(predict_X_train_df, predict_y_train_df, predict_configs)\n",
    "    test_predictions, predict_test_loss = mlp_predict_model.interpolate_predictions(predict_X_test_df, predict_y_test_df, predict_configs)\n",
    "    \n",
    "    # Out-Sample Forecasts\n",
    "    train_forecasts, forecast_train_loss = mlp_forecast_model.train_model(forecast_X_train_df, forecast_y_train_df, forecast_configs)\n",
    "    test_forecasts = mlp_forecast_model.extrapolate_forecasts(forecast_X_test_df)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "\n",
    "        print(f\"    Predictions | Train loss: {predict_train_loss} | Test loss: {predict_test_loss}\")\n",
    "        # print(f\"    Predictions Parameters: {mlp_predict_model.state_dict()}\")\n",
    "        predict_train_loss_values.append(predict_train_loss)\n",
    "        predict_test_loss_values.append(predict_test_loss)\n",
    "\n",
    "        print(f\"    Forecasts | Train loss: {forecast_train_loss}\")\n",
    "        # print(f\"    Forecasts Parameters: {mlp_forecast_model.state_dict()}\")\n",
    "        forecast_train_loss_values.append(forecast_train_loss)\n",
    "        # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7683feae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 2.378\n"
     ]
    }
   ],
   "source": [
    "EvaluationMetric.eval_mse(predict_y_test_df, test_predictions, False) # Matches Test MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51305f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHFCAYAAAAT5Oa6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABvlUlEQVR4nO3de1wU1f8/8NfslQVhBRQWEhEVL3nLSyFqqamoRWZWWvghKdNPmRqpaf5KxS6aVmrGNzQzNbXoqp8+ZaRW+tHwlkZ5LwtvCaIJCwgssHt+fyw7soKKCDuLvJ6Pxzx298yZmXN2sH33nnNmJCGEABEREVE9plK6AURERERKY0BERERE9R4DIiIiIqr3GBARERFRvceAiIiIiOo9BkRERERU7zEgIiIionqPARERERHVewyIiIiIqN5jQEREN2zlypWQJAk///yz0k2pkm3btmH48OG45ZZboNPpYDQa0aNHDyQlJeHixYtKN4+IFMCAiIjqlVmzZuGuu+7C33//jVdeeQWbNm1CcnIy+vXrh4SEBLz00ktKN5GIFKBRugFERK7y2Wef4eWXX8bo0aOxbNkySJIkrxs8eDCmTp2KHTt21MixCgoK4OnpWSP7IqLaxwwREbnM9u3b0a9fP3h7e8PT0xM9evTAN99841SnoKAAU6ZMQVhYGDw8PODn54du3brh448/luv89ddfeOSRRxAcHAy9Xo/AwED069cPaWlpVz3+yy+/DF9fXyxevNgpGHLw9vZGVFQUAOD48eOQJAkrV66sUE+SJCQkJMifExISIEkS9u3bh4ceegi+vr5o0aIFFi1aBEmScOzYsQr7mDZtGnQ6Hc6fPy+Xbd68Gf369YOPjw88PT3Rs2dPfP/9907bnTt3DmPHjkVISAj0ej0aN26Mnj17YvPmzVftOxFdHQMiInKJrVu34u6774bZbMby5cvx8ccfw9vbG/fddx8++eQTud6kSZOQlJSEiRMnIiUlBatXr8bDDz+Mf/75R65zzz33YO/evZg/fz42bdqEpKQkdO7cGTk5OVc8fkZGBg4cOICoqKhay9wMGzYMLVu2xGeffYYlS5bgX//6F3Q6XYWgymq1Ys2aNbjvvvvQqFEjAMCaNWsQFRUFHx8frFq1Cp9++in8/PwwcOBAp6AoNjYW69evx8yZM7Fx40a8//776N+/v9P3Q0TVIIiIbtCKFSsEALFnz54r1unevbsICAgQeXl5cllpaalo3769aNKkibDZbEIIIdq3by+GDh16xf2cP39eABCLFi26rjbu3LlTABAvvPBCleqnp6cLAGLFihUV1gEQs2bNkj/PmjVLABAzZ86sUHfYsGGiSZMmwmq1ymUbNmwQAMR///tfIYQQFy9eFH5+fuK+++5z2tZqtYpOnTqJO+64Qy5r0KCBiI+Pr1IfiKjqmCEiolp38eJF7Nq1Cw899BAaNGggl6vVasTGxuL06dM4evQoAOCOO+7At99+ixdeeAFbtmxBYWGh0778/PzQokULvPHGG1iwYAF++eUX2Gw2l/bnSh588MEKZY8//jhOnz7tdElrxYoVMJlMGDx4MAAgNTUVFy5cwKhRo1BaWiovNpsNgwYNwp49e+TZb3fccQdWrlyJV199FTt37kRJSYlrOkd0k2NARES1Ljs7G0IIBAUFVVgXHBwMAPIln8WLF2PatGlYv349+vbtCz8/PwwdOhR//PEHAPv4ne+//x4DBw7E/Pnz0aVLFzRu3BgTJ05EXl7eFdvQtGlTAEB6enpNd09WWf8GDx6MoKAgrFixAoD9u/jqq6/w2GOPQa1WAwDOnj0LAHjooYeg1Wqdlnnz5kEIgQsXLgAAPvnkE4waNQrvv/8+IiMj4efnh8ceewyZmZm11i+i+oCzzIio1vn6+kKlUiEjI6PCujNnzgCAPJbGy8sLs2fPxuzZs3H27Fk5W3TffffhyJEjAIDQ0FAsX74cAPD777/j008/RUJCAoqLi7FkyZJK2xAUFIQOHTpg48aNVZoB5uHhAQCwWCxO5Vcbq1PZQG1HFmzx4sXIycnBRx99BIvFgscff1yu4+j7O++8g+7du1e678DAQLnuokWLsGjRIpw8eRJfffUVXnjhBWRlZSElJeWqfSKiK2OGiIhqnZeXFyIiIvDll186XQKz2WxYs2YNmjRpglatWlXYLjAwEHFxcXj00Udx9OhRFBQUVKjTqlUrvPTSS+jQoQP27dt31XbMmDED2dnZmDhxIoQQFdbn5+dj48aN8rE9PDzw22+/OdX5z3/+U6U+l/f444+jqKgIH3/8MVauXInIyEi0adNGXt+zZ080bNgQhw4dQrdu3SpddDpdhf02bdoU48ePx4ABA67ZdyK6OmaIiKjG/PDDDzh+/HiF8nvuuQdz587FgAED0LdvX0yZMgU6nQ7vvvsuDhw4gI8//ljOrkRERCA6OhodO3aEr68vDh8+jNWrVyMyMhKenp747bffMH78eDz88MMIDw+HTqfDDz/8gN9++w0vvPDCVdv38MMPY8aMGXjllVdw5MgRjB49Gi1atEBBQQF27dqFpUuXYsSIEYiKioIkSfjXv/6FDz74AC1atECnTp2we/dufPTRR9f9vbRp0waRkZGYO3cuTp06hffee89pfYMGDfDOO+9g1KhRuHDhAh566CEEBATg3Llz+PXXX3Hu3DkkJSXBbDajb9++iImJQZs2beDt7Y09e/YgJSUFw4YNu+52EVE5Cg/qJqKbgGOW2ZWW9PR0IYQQ27ZtE3fffbfw8vISBoNBdO/eXZ5p5fDCCy+Ibt26CV9fX6HX60Xz5s3Fc889J86fPy+EEOLs2bMiLi5OtGnTRnh5eYkGDRqIjh07ioULF4rS0tIqtXfr1q3ioYceEkFBQUKr1QofHx8RGRkp3njjDZGbmyvXM5vN4sknnxSBgYHCy8tL3HfffeL48eNXnGV27ty5Kx7zvffeEwCEwWAQZrP5iu269957hZ+fn9BqteKWW24R9957r/jss8+EEEIUFRWJp556SnTs2FH4+PgIg8EgWrduLWbNmiUuXrxYpb4TUeUkISrJGxMRERHVIxxDRERERPUeAyIiIiKq9xgQERERUb3HgIiIiIjqPQZEREREVO8xICIiIqJ6jzdmrCKbzYYzZ87A29u70tvzExERkfsRQiAvLw/BwcFQqa6cB2JAVEVnzpxBSEiI0s0gIiKiajh16hSaNGlyxfUMiKrI29sbgP0L9fHxUbg1REREVBW5ubkICQmRf8evhAFRFTkuk/n4+DAgIiIiqmOuNdyFg6qJiIio3lM0ICotLcVLL72EsLAwGAwGNG/eHC+//DJsNptcRwiBhIQEBAcHw2AwoE+fPjh48KDTfiwWCyZMmIBGjRrBy8sLQ4YMwenTp53qZGdnIzY2FkajEUajEbGxscjJyXFFN4mIiMjNKRoQzZs3D0uWLEFiYiIOHz6M+fPn44033sA777wj15k/fz4WLFiAxMRE7NmzByaTCQMGDEBeXp5cJz4+HuvWrUNycjK2b9+O/Px8REdHw2q1ynViYmKQlpaGlJQUpKSkIC0tDbGxsS7tLxEREbknRZ92Hx0djcDAQCxfvlwue/DBB+Hp6YnVq1dDCIHg4GDEx8dj2rRpAOzZoMDAQMybNw///ve/YTab0bhxY6xevRojRowAcGlG2IYNGzBw4EAcPnwYt956K3bu3ImIiAgAwM6dOxEZGYkjR46gdevW12xrbm4ujEYjzGYzxxAR0U3LarWipKRE6WYQVZlWq4Varb7i+qr+fis6qLpXr15YsmQJfv/9d7Rq1Qq//vortm/fjkWLFgEA0tPTkZmZiaioKHkbvV6P3r17IzU1Ff/+97+xd+9elJSUONUJDg5G+/btkZqaioEDB2LHjh0wGo1yMAQA3bt3h9FoRGpqaqUBkcVigcVikT/n5ubWwjdAROQehBDIzMzkUAKqkxo2bAiTyXRD9wlUNCCaNm0azGYz2rRpA7VaDavVitdeew2PPvooACAzMxMAEBgY6LRdYGAgTpw4IdfR6XTw9fWtUMexfWZmJgICAiocPyAgQK5zublz52L27Nk31kEiojrCEQwFBATA09OTN6ClOkEIgYKCAmRlZQEAgoKCqr0vRQOiTz75BGvWrMFHH32Edu3aIS0tDfHx8QgODsaoUaPkepf/wxRCXPMf6+V1Kqt/tf1Mnz4dkyZNkj877mNARHSzsVqtcjDk7++vdHOIrovBYAAAZGVlISAg4KqXz65G0YDo+eefxwsvvIBHHnkEANChQwecOHECc+fOxahRo2AymQDY/8+lfNSXlZUlZ41MJhOKi4uRnZ3tlCXKyspCjx495Dpnz56tcPxz585VyD456PV66PX6mukoEZEbc4wZ8vT0VLglRNXj+NstKSmpdkCk6CyzgoKCCs8VUavV8rT7sLAwmEwmbNq0SV5fXFyMrVu3ysFO165dodVqnepkZGTgwIEDcp3IyEiYzWbs3r1brrNr1y6YzWa5DhFRfcfLZFRX1cTfrqIZovvuuw+vvfYamjZtinbt2uGXX37BggUL8MQTTwCwdzA+Ph5z5sxBeHg4wsPDMWfOHHh6eiImJgYAYDQaMXr0aEyePBn+/v7w8/PDlClT0KFDB/Tv3x8A0LZtWwwaNAhjxozB0qVLAQBjx45FdHR0lWaYERER0U1OKCg3N1c8++yzomnTpsLDw0M0b95cvPjii8Jisch1bDabmDVrljCZTEKv14u77rpL7N+/32k/hYWFYvz48cLPz08YDAYRHR0tTp486VTnn3/+ESNHjhTe3t7C29tbjBw5UmRnZ1e5rWazWQAQZrP5hvpMRORuCgsLxaFDh0RhYaHSTXFrs2bNEp06dZI/jxo1Stx///2KtacqVqxYIYxGo+L7qG1X+xuu6u+3ovchqkt4HyIiulkVFRUhPT0dYWFh8PDwULo51yUuLg6rVq0CAGg0GoSEhGDYsGGYPXs2vLy8avRYCQkJWL9+PdLS0gAAZrMZQgg0bNjwmtseP34cYWFh+OWXX3Dbbbddsd6WLVvQt29fZGdnV2m/11JYWIi8vLxKZ1pX1cqVKxEfH+/Wt2S42t9wnbgPEQG4eB4ovgh4+gH6qz+Jl4iIKho0aBBWrFiBkpISbNu2DU8++SQuXryIpKSkCnVLSkqg1Wpr5LhGo7FG9lMdxcXF0Ol016xnMBjkWVh0dXy4q9I+fwJ4uyNw9FulW0JEVCfp9XqYTCaEhIQgJiYGI0eOxPr16wHYszq33XYbPvjgAzRv3hx6vR5CCJjNZowdOxYBAQHw8fHB3XffjV9//dVpv6+//joCAwPh7e2N0aNHo6ioyGl9XFwchg4dKn+22WyYN28eWrZsCb1ej6ZNm+K1114DYJ8kBACdO3eGJEno06dPhX4cP34cffv2BQD4+vpCkiTExcUBAPr06YPx48dj0qRJaNSoEQYMGAAAWLBgATp06AAvLy+EhIRg3LhxyM/Pl/e5cuVKp0yT4/tYvXo1mjVrBqPRiEceecTpcVhVkZSUhBYtWkCn06F169ZYvXq10/qEhAQ0bdoUer0ewcHBmDhxorzu3XffRXh4ODw8PBAYGIiHHnrouo5dW5ghUpq6LMK3FivbDiKicoQQKCyxXrtiDTNo1Tc8Y8hgMDg9fuTYsWP49NNP8cUXX8hTsu+99174+flhw4YNMBqNWLp0Kfr164fff/8dfn5++PTTTzFr1iz83//9H+68806sXr0aixcvRvPmza943OnTp2PZsmVYuHAhevXqhYyMDBw5cgQAsHv3btxxxx3YvHkz2rVrV2l2JyQkBF988QUefPBBHD16FD4+Pk7ZnVWrVuHpp5/GTz/9BMdoF5VKhcWLF6NZs2ZIT0/HuHHjMHXqVLz77rtXbOeff/6J9evX4+uvv0Z2djaGDx+O119/XQ7ermXdunV49tlnsWjRIvTv3x9ff/01Hn/8cTRp0gR9+/bF559/joULFyI5ORnt2rVDZmamHGz+/PPPmDhxIlavXo0ePXrgwoUL2LZtW5WOW9sYEClNXZa6tfLZQUTkPgpLrLh15ncuP+6hlwfCU1f9n6bdu3fjo48+Qr9+/eSy4uJirF69Go0bNwYA/PDDD9i/fz+ysrLk+829+eabWL9+PT7//HOMHTsWixYtwhNPPIEnn3wSAPDqq69i8+bNFbJEDnl5eXj77beRmJgo31i4RYsW6NWrFwDIx/b395fvsXc5tVoNPz8/APYnKVw+hqhly5aYP3++U1l8fLz8PiwsDK+88gqefvrpqwZENpsNK1euhLe3fZhGbGwsvv/++yoHRG+++Sbi4uIwbtw4AMCkSZOwc+dOvPnmm+jbty9OnjwJk8mE/v37Q6vVomnTprjjjjsAACdPnoSXlxeio6Ph7e2N0NBQdO7cuUrHrW28ZKY0BkRERDfk66+/RoMGDeDh4YHIyEjcddddeOedd+T1oaGhckACAHv37kV+fj78/f3RoEEDeUlPT8eff/4JADh8+DAiIyOdjnP55/IOHz4Mi8XiFIjVtG7dulUo+/HHHzFgwADccsst8Pb2xmOPPYZ//vkHFy9evOJ+mjVrJgdDgP1xF45HX1TF4cOH0bNnT6eynj174vDhwwCAhx9+GIWFhWjevDnGjBmDdevWobS0FAAwYMAAhIaGonnz5oiNjcXatWtRUFBQ5WPXJmaIlKYqC4hsDIiIyH0YtGocenmgIse9Xn379kVSUhK0Wi2Cg4MrDJq+fLaZzWZDUFAQtmzZUmFf1Z3Z5YqBy5f348SJE7jnnnvw1FNP4ZVXXoGfnx+2b9+O0aNHO10yvNzl348kSfINkavqao/UCgkJwdGjR7Fp0yZs3rwZ48aNwxtvvIGtW7fC29sb+/btw5YtW7Bx40bMnDkTCQkJ2LNnT43MqrsRzBApjWOIiMgNSZIET53G5Ut1xg95eXmhZcuWCA0NrdIMsi5duiAzMxMajQYtW7Z0Who1agTAfkPfnTt3Om13+efywsPDYTAY8P3331e63jFmyGq9+risqtYD7ONxSktL8dZbb6F79+5o1aoVzpw5c83tblTbtm2xfft2p7LU1FS0bdtW/mwwGDBkyBAsXrwYW7ZswY4dO7B//34A9tsj9O/fH/Pnz8dvv/2G48eP44cffqj1dl8LM0RKU5edAmupsu0gIqon+vfvj8jISAwdOhTz5s1D69atcebMGWzYsAFDhw5Ft27d8Oyzz2LUqFHo1q0bevXqhbVr1+LgwYNXHFTt4eGBadOmYerUqdDpdOjZsyfOnTuHgwcPYvTo0QgICIDBYEBKSgqaNGkCDw+PSqfth4aGQpIkfP3117jnnntgMBjQoEGDSo/ZokULlJaW4p133sF9992Hn376CUuWLKnR76oyzz//PIYPH44uXbqgX79++O9//4svv/wSmzdvBmCf2Wa1WhEREQFPT0+sXr0aBoMBoaGh+Prrr/HXX3/hrrvugq+vLzZs2ACbzeYWT41ghkhpjgwRL5kREbmEJEnYsGED7rrrLjzxxBNo1aoVHnnkERw/flx+4PeIESMwc+ZMTJs2DV27dsWJEyfw9NNPX3W/M2bMwOTJkzFz5ky0bdsWI0aMkMfmaDQaLF68GEuXLkVwcDDuv//+Svdxyy23YPbs2XjhhRcQGBiI8ePHX/F4t912GxYsWIB58+ahffv2WLt2LebOnVvNb6Xqhg4dirfffhtvvPEG2rVrh6VLl2LFihXyrQQaNmyIZcuWoWfPnujYsSO+//57/Pe//4W/vz8aNmyIL7/8EnfffTfatm2LJUuW4OOPP0a7du1qvd3XwjtVV1Gt3an62xeAXUlAr+eA/gk1t18ioiqqy3eqJgJq5k7VzBApjbPMiIiIFMeASGkMiIiIiBTHgEhpHENERESkOAZESlM5Zplx2j0REZFSGBApTb4PEafdExERKYUBkdLkMUTMEBERESmFAZHSHJfMOIaIiIhIMQyIlCZfMmNAREREpBQGRErjtHsiIiLFMSBSGqfdExHVCQkJCbjtttvkz3FxcRg6dKhi7alpW7ZsgSRJyMnJUbopimBApDR52j0DIiKi6xUXFwdJkiBJErRaLZo3b44pU6bg4sWLtX7st99+GytXrqxS3ePHj0OSJKSlpV21Xm0EJVU9dn3Hp90rjWOIiIhuyKBBg7BixQqUlJRg27ZtePLJJ3Hx4kUkJSVVqFtSUgKtVlsjx63safVUdzFDpDROuyciuiF6vR4mkwkhISGIiYnByJEjsX79egCXLnN98MEHaN68OfR6PYQQMJvNGDt2LAICAuDj44O7774bv/76q9N+X3/9dQQGBsLb2xujR49GUVGR0/rLL5nZbDbMmzcPLVu2hF6vR9OmTfHaa68BAMLCwgAAnTt3hiRJ8pPhyzt+/Dj69u0LAPD19YUkSYiLiwMACCEwf/58NG/eHAaDAZ06dcLnn38ub5udnY2RI0eicePGMBgMCA8Px4oVK6p87Cv54osv0K5dO+j1ejRr1gxvvfWW0/p3330X4eHh8PDwQGBgIB566CF53eeff44OHTrAYDDA398f/fv3d0nmrrqYIVKaIyCy8caMRORGhABKClx/XK0nIEk3tAuDwYCSkktZ92PHjuHTTz/FF198AbVaDQC499574efnhw0bNsBoNGLp0qXo168ffv/9d/j5+eHTTz/FrFmz8H//93+48847sXr1aixevBjNmze/4nGnT5+OZcuWYeHChejVqxcyMjJw5MgRAMDu3btxxx13YPPmzWjXrh10Ol2F7UNCQvDFF1/gwQcfxNGjR+Hj4wODwQAAeOmll/Dll18iKSkJ4eHh+N///od//etfaNy4MXr37o0ZM2bg0KFD+Pbbb9GoUSMcO3YMhYWFVT52Zfbu3Yvhw4cjISEBI0aMQGpqKsaNGwd/f3/ExcXh559/xsSJE7F69Wr06NEDFy5cwLZt2wAAGRkZePTRRzF//nw88MADyMvLw7Zt2yCEqNKxlcCASGkqZoiIyA2VFABzgl1/3P93BtB5VXvz3bt346OPPkK/fv3ksuLiYqxevRqNGzcGAPzwww/Yv38/srKyoNfrAQBvvvkm1q9fj88//xxjx47FokWL8MQTT+DJJ58EALz66qvYvHlzhSyRQ15eHt5++20kJiZi1KhRAIAWLVqgV69eACAf29/fHyaTqdJ9qNVq+Pn5AQACAgLQsGFDAMDFixexYMEC/PDDD4iMjAQANG/eHNu3b8fSpUvRu3dvnDx5Ep07d0a3bt0AAM2aNZP3W5VjV2bBggXo168fZsyYAQBo1aoVDh06hDfeeANxcXE4efIkvLy8EB0dDW9vb4SGhqJz584A7AFRaWkphg0bhtDQUABAhw4dqnxsJfCSmdI4hoiI6IZ8/fXXaNCgATw8PBAZGYm77roL77zzjrw+NDRUDgoAe+YjPz8f/v7+aNCggbykp6fjzz//BAAcPnxYDj4cLv9c3uHDh2GxWJwCsZpy6NAhFBUVYcCAAU7t/fDDD+X2Pv3000hOTsZtt92GqVOnIjU19YaPe/jwYfTs2dOprGfPnvjjjz9gtVoxYMAAhIaGonnz5oiNjcXatWtRUGDPKnbq1An9+vVDhw4d8PDDD2PZsmXIzs6+4TbVJmaIlKbmLDMickNaT3u2RonjXqe+ffsiKSkJWq0WwcHBFQZNe3k5Z5xsNhuCgoKwZcuWCvtyZGWul+PSVm2w2WwAgG+++Qa33HKL0zpHhmvw4ME4ceIEvvnmG2zevBn9+vXDM888gzfffLPaxxVCQLrs8mX5S17e3t7Yt28ftmzZgo0bN2LmzJlISEjAnj170LBhQ2zatAmpqanYuHEj3nnnHbz44ovYtWuXPKbJ3TBDpDTeh4iI3JEk2S9duXqpxvghLy8vtGzZEqGhoVWaQdalSxdkZmZCo9GgZcuWTkujRo0AAG3btsXOnTudtrv8c3nh4eEwGAz4/vvvK13vGLdjtVqv2rbK6t16663Q6/U4efJkhfaGhITI9Ro3boy4uDisWbMGixYtwnvvvXddx77crbfeiu3btzuVpaamolWrVvJYLI1Gg/79+2P+/Pn47bffcPz4cfzwww8AAEmS0LNnT8yePRu//PILdDod1q1bd11tcCVmiJTGMURERC7Vv39/REZGYujQoZg3bx5at26NM2fOYMOGDRg6dCi6deuGZ599FqNGjUK3bt3Qq1cvrF27FgcPHrzioGoPDw9MmzYNU6dOhU6nQ8+ePXHu3DkcPHgQo0ePRkBAAAwGA1JSUtCkSRN4eHhUOm0/NDQUkiTh66+/xj333AODwQBvb29MmTIFzz33HGw2G3r16oXc3FykpqaiQYMGGDVqFGbOnImuXbuiXbt2sFgs+Prrr9G2bVsAqPKxLzd58mTcfvvteOWVVzBixAjs2LEDiYmJePfddwHYL1X+9ddfuOuuu+Dr64sNGzbAZrOhdevW2LVrF77//ntERUUhICAAu3btwrlz5+Q2uSVBVWI2mwUAYTaba3bH//wpxCwfIV4Nqtn9EhFVUWFhoTh06JAoLCxUuinXbdSoUeL++++/4vpZs2aJTp06VSjPzc0VEyZMEMHBwUKr1YqQkBAxcuRIcfLkSbnOa6+9Jho1aiQaNGggRo0aJaZOneq0r8uPbbVaxauvvipCQ0OFVqsVTZs2FXPmzJHXL1u2TISEhAiVSiV69+59xTa//PLLwmQyCUmSxKhRo4QQQthsNvH222+L1q1bC61WKxo3biwGDhwotm7dKoQQ4pVXXhFt27YVBoNB+Pn5ifvvv1/89ddf13XsH3/8UQAQ2dnZctnnn38ubr31Vrk/b7zxhrxu27Ztonfv3sLX11cYDAbRsWNH8cknnwghhDh06JAYOHCgaNy4sdDr9aJVq1binXfeuWKfb9TV/oar+vstCeHGc+DcSG5uLoxGI8xmM3x8fGpux+bTwMJ29ktnM87V3H6JiKqoqKgI6enpCAsLg4eHh9LNIbpuV/sbrurvN8cQKa38JTPGpkRERIpQNCBq1qyZ/Aya8sszzzwDwD6aPSEhAcHBwTAYDOjTpw8OHjzotA+LxYIJEyagUaNG8PLywpAhQ3D69GmnOtnZ2YiNjYXRaITRaERsbKz7PLxOXW4AoO36BrwRERFRzVA0INqzZw8yMjLkZdOmTQCAhx9+GAAwf/58LFiwAImJidizZw9MJhMGDBiAvLw8eR/x8fFYt24dkpOTsX37duTn5yM6OtppNH1MTAzS0tKQkpKClJQUpKWlITY21rWdvZLyAREHVhMRESmjVkY3VdOzzz4rWrRoIWw2m7DZbMJkMonXX39dXl9UVCSMRqNYsmSJEEKInJwcodVqRXJyslzn77//FiqVSqSkpAgh7AO7AIidO3fKdXbs2CEAiCNHjlS5bbU2qLqkyD6oepaPEIU5NbtvIqIqqMuDqomEqJlB1W4zhqi4uBhr1qzBE088AUmSkJ6ejszMTERFRcl19Ho9evfuLd+Bc+/evSgpKXGqExwcjPbt28t1duzYAaPRiIiICLlO9+7dYTQar3onT4vFgtzcXKelVqjKZ4h4LyIiIiIluE1AtH79euTk5MhP9s3MzAQABAYGOtULDAyU12VmZkKn08HX1/eqdQICAiocLyAgQK5Tmblz58pjjoxGo9PNr2qUSgVI9htcMSAiIiJShtsERMuXL8fgwYMRHOz8MMHKbht+ednlLq9TWf1r7Wf69Okwm83ycurUqap0o3rUvDkjERGRktwiIDpx4gQ2b94sP1UYgPxE3suzOFlZWXLWyGQyobi4uMID4y6vc/bs2QrHPHfuXIXsU3l6vR4+Pj5OS62RH99RWnvHICIioityi4BoxYoVCAgIwL333iuXhYWFwWQyyTPPAPs4o61bt6JHjx4AgK5du0Kr1TrVycjIwIEDB+Q6kZGRMJvN2L17t1xn165dMJvNch3FqRwPeGWGiIiISAmKP8vMZrNhxYoVGDVqFDSaS82RJAnx8fGYM2cOwsPDER4ejjlz5sDT0xMxMTEAAKPRiNGjR2Py5Mnw9/eHn58fpkyZgg4dOqB///4A7A/oGzRoEMaMGYOlS5cCAMaOHYvo6Gi0bt3a9R2ujCNDxDFERESkkLi4OOTk5GD9+vWK7kMpimeINm/ejJMnT+KJJ56osG7q1KmIj4/HuHHj0K1bN/z999/YuHEjvL295ToLFy7E0KFDMXz4cPTs2ROenp7473//Kz+JFwDWrl2LDh06ICoqClFRUejYsSNWr17tkv5ViWMMEZ94T0R0XeLi4iq9we+xY8eUblq1rVy5Eg0bNrxmvYSEBNx22201dty3334bK1eurLH91TWKZ4iioqIgrvDICkmSkJCQgISEhCtu7+HhgXfeeQfvvPPOFev4+flhzZo1N9rU2iMPqmZARER0vQYNGoQVK1Y4lTVu3Lha+youLoZOp6uJZrmNkpISaLXaa9YzGo0uaI37UjxDRCj3PDMGRERE10uv18NkMjktjqsEW7duxR133AG9Xo+goCC88MILKC29NIGlT58+GD9+PCZNmoRGjRphwIABAIBDhw7hnnvuQYMGDRAYGIjY2FicP39e3s5ms2HevHlo2bIl9Ho9mjZtitdee01eP23aNLRq1Qqenp5o3rw5ZsyYgZKSS/+N//XXX9G3b194e3vDx8cHXbt2xc8//4wtW7bg8ccfh9lslrNdlSUFVq5cidmzZ+PXX3+V6zmyO5IkYcmSJbj//vvh5eWFV199FVarFaNHj0ZYWBgMBgNat26Nt99+22mfcXFxGDp0qNN3M3HiREydOhV+fn4wmUxXTVBUxmKxYOLEiQgICICHhwd69eqFPXv2yOuzs7MxcuRING7cGAaDAeHh4XJwW1xcjPHjxyMoKAgeHh5o1qwZ5s6de13Hvx6KZ4gInHZPRG5HCIHC0kKXH9egMVzz1ipV9ffff+Oee+5BXFwcPvzwQxw5cgRjxoyBh4eH0w/7qlWr8PTTT+Onn36CEAIZGRno3bs3xowZgwULFqCwsBDTpk3D8OHD8cMPPwCw35pl2bJlWLhwIXr16oWMjAwcOXJE3qe3tzdWrlyJ4OBg7N+/H2PGjIG3tzemTp0KABg5ciQ6d+6MpKQkqNVqpKWlQavVokePHli0aBFmzpyJo0ePAgAaNGhQoW8jRozAgQMHkJKSgs2bNwNwzvDMmjULc+fOxcKFC6FWq2Gz2dCkSRN8+umnaNSoEVJTUzF27FgEBQVh+PDhV/wOV61ahUmTJmHXrl3YsWMH4uLi0LNnTzlwvJapU6fiiy++wKpVqxAaGor58+dj4MCBOHbsGPz8/DBjxgwcOnQI3377LRo1aoRjx46hsND+d7d48WJ89dVX+PTTT9G0aVOcOnWqVm+Bw4DIHchjiDjtnojcQ2FpISI+irh2xRq2K2YXPLWe17XN119/7RQ0DB48GJ999hneffddhISEIDExEZIkoU2bNjhz5gymTZuGmTNnQqWyXyRp2bIl5s+fL28/c+ZMdOnSBXPmzJHLPvjgA4SEhOD3339HUFAQ3n77bSQmJmLUqFEAgBYtWqBXr15y/Zdeekl+36xZM0yePBmffPKJHBCdPHkSzz//PNq0aQMACA8Pl+sbjUZIkiTffqYyBoMBDRo0gEajqbReTExMhbG5s2fPlt+HhYUhNTUVn3766VUDoo4dO2LWrFlyGxMTE/H9999XKSC6ePEikpKSsHLlSgwePBgAsGzZMmzatAnLly/H888/j5MnT6Jz587o1q0bAPt35XDy5EmEh4ejV69ekCQJoaGh1zzmjWBA5A5UzBAREVVX3759kZSUJH/28vICABw+fBiRkZFOGaeePXsiPz8fp0+fRtOmTQFA/jF22Lt3L3788cdKMzN//vkncnJyYLFY0K9fvyu26fPPP8eiRYtw7Ngx5Ofno7S01Ol+dpMmTcKTTz6J1atXo3///nj44YfRokWL6n0Blbi8TwCwZMkSvP/++zhx4gQKCwtRXFx8zUHZHTt2dPocFBSErKysKrXhzz//RElJCXr27CmXabVa3HHHHTh8+DAA4Omnn8aDDz6Iffv2ISoqCkOHDpVviRMXF4cBAwagdevWGDRoEKKjo50e1VXTGBC5A067JyI3Y9AYsCtmlyLHvV5eXl5o2bJlhfLKnkjgmMRTvtwRQDnYbDbcd999mDdvXoV9BgUF4a+//rpqe3bu3IlHHnkEs2fPxsCBA2E0GpGcnIy33npLrpOQkICYmBh88803+PbbbzFr1iwkJyfjgQceuHaHq+DyPn366ad47rnn8NZbbyEyMhLe3t544403sGvX1c/x5YOxJUmCzWarUhsq+64d5Y6ywYMH48SJE/jmm2+wefNm9OvXD8888wzefPNNdOnSBenp6fj222+xefNmDB8+HP3798fnn39epeNfLwZE7kDtuDEjAyIicg+SJF33pSt3c+utt+KLL75w+gFOTU2Ft7c3brnllitu16VLF3zxxRdo1qyZ0/3xHMLDw2EwGPD99987PWHB4aeffkJoaChefPFFuezEiRMV6rVq1QqtWrXCc889h0cffRQrVqzAAw88AJ1OB6vVes3+VbUeAGzbtg09evTAuHHj5LI///yzSttWV8uWLaHT6bB9+3b5/oElJSX4+eefER8fL9dr3Lgx4uLiEBcXhzvvvBPPP/883nzzTQCAj48PRowYgREjRuChhx7CoEGDcOHCBfj5+dV4eznLzB3Ij+5gQEREVFPGjRuHU6dOYcKECThy5Aj+85//YNasWZg0aZI8fqgyzzzzDC5cuIBHH30Uu3fvxl9//YWNGzfiiSeegNVqhYeHB6ZNm4apU6fiww8/xJ9//omdO3di+fLlAOyBwMmTJ5GcnIw///wTixcvxrp16+T9FxYWYvz48diyZQtOnDiBn376CXv27EHbtm0B2MfR5Ofn4/vvv8f58+dRUFBQaTubNWuG9PR0pKWl4fz587BYLFfsU8uWLfHzzz/ju+++w++//44ZM2Y4zfaqDV5eXnj66afx/PPPIyUlBYcOHcKYMWNQUFCA0aNHA7CP1/rPf/6DY8eO4eDBg/j666/l72HhwoVITk7GkSNH8Pvvv+Ozzz6DyWSq0j2aqoMBkTvgGCIiohp3yy23YMOGDdi9ezc6deqEp556CqNHj3Ya8FyZ4OBg/PTTT7BarRg4cCDat2+PZ599FkajUQ6kZsyYgcmTJ2PmzJlo27YtRowYIY+tuf/++/Hcc89h/PjxuO2225CamooZM2bI+1er1fjnn3/w2GOPoVWrVhg+fDgGDx4sD3ru0aMHnnrqKYwYMQKNGzd2GvBd3oMPPohBgwahb9++aNy4MT7++OMr9umpp57CsGHDMGLECEREROCff/5xyhbVltdffx0PPvggYmNj0aVLFxw7dgzfffcdfH19AdizXNOnT0fHjh1x1113Qa1WIzk5GYB9dt28efPQrVs33H777Th+/Dg2bNhw1WD2RkjiSndFJCe5ubkwGo0wm801/6DXT0cBh9YDg98AIsbW7L6JiK6hqKgI6enpCAsLg4eHh9LNIbpuV/sbrurvNzNE7oCP7iAiIlIUAyJ3IM8y4yUzIiIiJTAgcgcqxywz3piRiIhICQyI3AEzRERERIpiQOQOOIaIiNwA59hQXVUTf7sMiNyBijdmJCLlOO5GfKX73RC5O8ff7uV31r4evFO1O+CjO4hIQWq1Gg0bNpTvo+Pp6VljT5wnqk1CCBQUFCArKwsNGzaEWq2u9r4YELkDNW/MSETKcjwxvaoP7iRyJw0bNpT/hquLAZE74BgiIlKYJEkICgpCQEAASkr43yKqO7Ra7Q1lhhwYELkD+dEd/I8QESlLrVbXyI8LUV3DQdXugGOIiIiIFMWAyB2oyxJ1vGRGRESkCAZE7oAZIiIiIkUxIHIHHENERESkKAZE7oDT7omIiBTFgMgdyNPu+XBXIiIiJTAgcgd8uCsREZGiGBC5A44hIiIiUhQDInegZkBERESkJAZE7oCP7iAiIlIUAyJ3oOIsMyIiIiUxIHIH8iUzzjIjIiJSAgMid8BLZkRERIpSPCD6+++/8a9//Qv+/v7w9PTEbbfdhr1798rrhRBISEhAcHAwDAYD+vTpg4MHDzrtw2KxYMKECWjUqBG8vLwwZMgQnD592qlOdnY2YmNjYTQaYTQaERsbi5ycHFd08do47Z6IiEhRigZE2dnZ6NmzJ7RaLb799lscOnQIb731Fho2bCjXmT9/PhYsWIDExETs2bMHJpMJAwYMQF5enlwnPj4e69atQ3JyMrZv3478/HxER0fDarXKdWJiYpCWloaUlBSkpKQgLS0NsbGxruzulanKHu7KS2ZERETKEAqaNm2a6NWr1xXX22w2YTKZxOuvvy6XFRUVCaPRKJYsWSKEECInJ0dotVqRnJws1/n777+FSqUSKSkpQgghDh06JACInTt3ynV27NghAIgjR45Uqa1ms1kAEGaz+br6WCU5p4WY5SPEbP+a3zcREVE9VtXfb0UzRF999RW6deuGhx9+GAEBAejcuTOWLVsmr09PT0dmZiaioqLkMr1ej969eyM1NRUAsHfvXpSUlDjVCQ4ORvv27eU6O3bsgNFoREREhFyne/fuMBqNch1FlR9DJISybSEiIqqHFA2I/vrrLyQlJSE8PBzfffcdnnrqKUycOBEffvghACAzMxMAEBgY6LRdYGCgvC4zMxM6nQ6+vr5XrRMQEFDh+AEBAXKdy1ksFuTm5jottcYREAF8nhkREZECNEoe3GazoVu3bpgzZw4AoHPnzjh48CCSkpLw2GOPyfUkSXLaTghRoexyl9eprP7V9jN37lzMnj27yn25IapyAZG1xDlAIiIiolqnaIYoKCgIt956q1NZ27ZtcfLkSQCAyWQCgApZnKysLDlrZDKZUFxcjOzs7KvWOXv2bIXjnzt3rkL2yWH69Okwm83ycurUqWr0sIocs8wAzjQjIiJSgKIBUc+ePXH06FGnst9//x2hoaEAgLCwMJhMJmzatEleX1xcjK1bt6JHjx4AgK5du0Kr1TrVycjIwIEDB+Q6kZGRMJvN2L17t1xn165dMJvNcp3L6fV6+Pj4OC21hpfMiIiIFKXoJbPnnnsOPXr0wJw5czB8+HDs3r0b7733Ht577z0A9stc8fHxmDNnDsLDwxEeHo45c+bA09MTMTExAACj0YjRo0dj8uTJ8Pf3h5+fH6ZMmYIOHTqgf//+AOxZp0GDBmHMmDFYunQpAGDs2LGIjo5G69atlel8eZJkn3pvK2WGiIiISAGKBkS333471q1bh+nTp+Pll19GWFgYFi1ahJEjR8p1pk6disLCQowbNw7Z2dmIiIjAxo0b4e3tLddZuHAhNBoNhg8fjsLCQvTr1w8rV66EWq2W66xduxYTJ06UZ6MNGTIEiYmJruvstai0ZQER71ZNRETkapIQnOddFbm5uTAajTCbzbVz+WxuCGDJBSbsA/xb1Pz+iYiI6qGq/n4r/ugOKqPmE++JiIiUwoDIXTim3vOSGRERkcsxIHIX8gNeGRARERG5GgMid6EuG99uY0BERETkagyI3IWcIeIYIiIiIldjQOQuOIaIiIhIMQyI3IWaAREREZFSGBC5C0dAxDFERERELseAyF1wDBEREZFiGBC5C1XZLDMrH+5KRETkagyI3IUjQ8RLZkRERC7HgMhd8NEdREREimFA5C54yYyIiEgxDIjcBQdVExERKYYBkbvgtHsiIiLFMCByF7wxIxERkWIYELkLPrqDiIhIMQyI3AXHEBERESmGAZG7UJfNMrNxlhkREZGrMSByF8wQERERKYYBkbvgGCIiIiLFMCByF5x2T0REpBgGRO7CccmslJfMiIiIXI0BkbuQxxBZlG0HERFRPcSAyF1oHAERL5kRERG5GgMid6HW219LmSEiIiJyNQZE7kLDafdERERKYUDkLpghIiIiUoxG6QbUdxarBUWlRfBQqaAHOKiaiIhIAcwQKeyZ759Br+Re+D77kL2A0+6JiIhcjgGRwnQq+9ghOS/EMUREREQux4BIYfqysUPFkrAXMCAiIiJyOUUDooSEBEiS5LSYTCZ5vRACCQkJCA4OhsFgQJ8+fXDw4EGnfVgsFkyYMAGNGjWCl5cXhgwZgtOnTzvVyc7ORmxsLIxGI4xGI2JjY5GTk+OKLl6TruyGjBZRFhBxUDUREZHLKZ4hateuHTIyMuRl//798rr58+djwYIFSExMxJ49e2AymTBgwADk5eXJdeLj47Fu3TokJydj+/btyM/PR3R0NKxWq1wnJiYGaWlpSElJQUpKCtLS0hAbG+vSfl6JnCGCzV7AQdVEREQup/gsM41G45QVchBCYNGiRXjxxRcxbNgwAMCqVasQGBiIjz76CP/+979hNpuxfPlyrF69Gv379wcArFmzBiEhIdi8eTMGDhyIw4cPIyUlBTt37kRERAQAYNmyZYiMjMTRo0fRunVr13W2Eo4MUbEoC4g4qJqIiMjlFM8Q/fHHHwgODkZYWBgeeeQR/PXXXwCA9PR0ZGZmIioqSq6r1+vRu3dvpKamAgD27t2LkpISpzrBwcFo3769XGfHjh0wGo1yMAQA3bt3h9FolOsoyZEhsghmiIiIiJSiaIYoIiICH374IVq1aoWzZ8/i1VdfRY8ePXDw4EFkZmYCAAIDA522CQwMxIkTJwAAmZmZ0Ol08PX1rVDHsX1mZiYCAgIqHDsgIECuUxmLxQKL5VJwkpubW71OXoOcIULZJT5hA6ylgFrx5B0REVG9oeiv7uDBg+X3HTp0QGRkJFq0aIFVq1ahe/fuAABJkpy2EUJUKLvc5XUqq3+t/cydOxezZ8+uUj9uhDyo2lZ6qdBazICIiIjIhRS/ZFael5cXOnTogD/++EMeV3R5FicrK0vOGplMJhQXFyM7O/uqdc6ePVvhWOfOnauQfSpv+vTpMJvN8nLq1Kkb6tuVXLpkdmkQOC+bERERuZZbBUQWiwWHDx9GUFAQwsLCYDKZsGnTJnl9cXExtm7dih49egAAunbtCq1W61QnIyMDBw4ckOtERkbCbDZj9+7dcp1du3bBbDbLdSqj1+vh4+PjtNQGeZaZrQRAWcaKA6uJiIhcStHrMlOmTMF9992Hpk2bIisrC6+++ipyc3MxatQoSJKE+Ph4zJkzB+Hh4QgPD8ecOXPg6emJmJgYAIDRaMTo0aMxefJk+Pv7w8/PD1OmTEGHDh3kWWdt27bFoEGDMGbMGCxduhQAMHbsWERHRys+wwwoN4bIWgxo9EBpETNERERELqZoQHT69Gk8+uijOH/+PBo3bozu3btj586dCA0NBQBMnToVhYWFGDduHLKzsxEREYGNGzfC29tb3sfChQuh0WgwfPhwFBYWol+/fli5ciXUarVcZ+3atZg4caI8G23IkCFITEx0bWevQL5kZrPYn3hfWsQMERERkYtJQjhukUxXk5ubC6PRCLPZXKOXz1LSU/D8/57H7abb8cGvW4GC88DTqUBguxo7BhERUX1V1d9vtxpDVB/Js8ysFvslM4CP7yAiInIxBkQKkwdVW4uBsuAI1hIFW0RERFT/MCBSWKUZIg6qJiIicikGRAqrNEPEQdVEREQuxYBIYU4BETNEREREimBApDCtWgug7JKZmoOqiYiIlMCASGHOl8zswRGsvGRGRETkSgyIFCbfmNFqgZBnmTEgIiIiciUGRApzzDITECh1ZIh4yYyIiMilGBApzJEhAoBiDTNERERESmBApDCdSie/t6jKHi3HDBEREZFLMSBSmCRJ0Krsl8qK1WUBETNERERELsWAyA3IA6tVansBM0REREQuxYDIDciP71CVnQ5miIiIiFyKAZEbkO9F5MgQMSAiIiJyKQZEbqBCQMRLZkRERC7FgMgN8JIZERGRshgQuQHH1Ptiqex0MENERETkUgyI3ICcIZLKCpghIiIicikGRG5AnnYvlUVEzBARERG5FAMiNyAPqnYUWBkQERERuRIDIjfguGRWLF8yK1GuMURERPUQAyI3UCFDxEtmRERELsWAyA1cGlQt7AUcVE1ERORSDIjcgBwQibKAiBkiIiIil2JA5AYuXTKz2Qs4qJqIiMilGBC5gUsZIqu9oJSXzIiIiFyJAZEbqJghYkBERETkSgyI3IAcEDkyRAyIiIiIXKpaAdGpU6dw+vRp+fPu3bsRHx+P9957r8YaVp9oVVoAgMXmuGTGMURERESuVK2AKCYmBj/++CMAIDMzEwMGDMDu3bvx//7f/8PLL79cow2sDypkiGwlgM2mYIuIiIjql2oFRAcOHMAdd9wBAPj000/Rvn17pKam4qOPPsLKlStrsn31gjyo2lbuDtW8bEZEROQy1QqISkpKoNfbsxqbN2/GkCFDAABt2rRBRkZGtRoyd+5cSJKE+Ph4uUwIgYSEBAQHB8NgMKBPnz44ePCg03YWiwUTJkxAo0aN4OXlhSFDhjhdzgOA7OxsxMbGwmg0wmg0IjY2Fjk5OdVqZ00b++HPmPbZYQCAxVZ6aQWn3hMREblMtQKidu3aYcmSJdi2bRs2bdqEQYMGAQDOnDkDf3//697fnj178N5776Fjx45O5fPnz8eCBQuQmJiIPXv2wGQyYcCAAcjLy5PrxMfHY926dUhOTsb27duRn5+P6OhoWK1WuU5MTAzS0tKQkpKClJQUpKWlITY2tjpdr3GlNgFLqf00FNvKZYU49Z6IiMhlqhUQzZs3D0uXLkWfPn3w6KOPolOnTgCAr776Sr6UVlX5+fkYOXIkli1bBl9fX7lcCIFFixbhxRdfxLBhw9C+fXusWrUKBQUF+OijjwAAZrMZy5cvx1tvvYX+/fujc+fOWLNmDfbv34/NmzcDAA4fPoyUlBS8//77iIyMRGRkJJYtW4avv/4aR48erU73a5SXXgPYNACAYlsJUDbAmpfMiIiIXKdaAVGfPn1w/vx5nD9/Hh988IFcPnbsWCxZsuS69vXMM8/g3nvvRf/+/Z3K09PTkZmZiaioKLlMr9ejd+/eSE1NBQDs3bsXJSUlTnWCg4PlMU0AsGPHDhiNRkRERMh1unfvDqPRKNdRkpdODYiygMhaDGjslyJ5yYyIiMh1NNXZqLCwEEIIOaNz4sQJrFu3Dm3btsXAgQOrvJ/k5GTs27cPe/bsqbAuMzMTABAYGOhUHhgYiBMnTsh1dDqdU2bJUcexfWZmJgICAirsPyAgQK5TGYvFAovlUlCSm5tbxV5dH0+dBqIsILJYLUDZAGteMiMiInKdamWI7r//fnz44YcAgJycHEREROCtt97C0KFDkZSUVKV9nDp1Cs8++yzWrFkDDw+PK9aTJMnpsxCiQtnlLq9TWf1r7Wfu3LnyIGyj0YiQkJCrHrO6vPRqQJTdh8hqYYaIiIhIAdUKiPbt24c777wTAPD555/LWZsPP/wQixcvrtI+9u7di6ysLHTt2hUajQYajQZbt27F4sWLodFo5MzQ5VmcrKwseZ3JZEJxcTGys7OvWufs2bMVjn/u3LkK2afypk+fDrPZLC+nTp2qUr+ul6dOA2Erd8mMGSIiIiKXq1ZAVFBQAG9vbwDAxo0bMWzYMKhUKnTv3l2+nHUt/fr1w/79+5GWliYv3bp1w8iRI5GWlobmzZvDZDJh06ZN8jbFxcXYunUrevToAQDo2rUrtFqtU52MjAwcOHBArhMZGQmz2Yzdu3fLdXbt2gWz2SzXqYxer4ePj4/TUhvsGaJKLpkxQ0REROQy1RpD1LJlS6xfvx4PPPAAvvvuOzz33HMA7JmZqgYO3t7eaN++vVOZl5cX/P395fL4+HjMmTMH4eHhCA8Px5w5c+Dp6YmYmBgAgNFoxOjRozF58mT4+/vDz88PU6ZMQYcOHeRB2m3btsWgQYMwZswYLF26FIB98Hd0dDRat25dne7XKE+dRg6ISmwlEBpvSAAf30FERORC1QqIZs6ciZiYGDz33HO4++67ERkZCcCeLercuXONNW7q1KkoLCzEuHHjkJ2djYiICGzcuFHOTgHAwoULodFoMHz4cBQWFqJfv35YuXIl1Gq1XGft2rWYOHGiPBttyJAhSExMrLF23ogGejVE2RgiAChW66AHAGvJFbchIiKimiUJIUR1NszMzERGRgY6deoElcp+5W337t3w8fFBmzZtarSR7iA3NxdGoxFms7lGL5/97/dzeOyDVHi3fQkA8JM1CD4ndwHDPwRuvb/GjkNERFQfVfX3u1oZIsA+WNlkMuH06dOQJAm33HLLdd+UkcrGEEENCAmQBIrVZaeEg6qJiIhcplqDqm02G15++WUYjUaEhoaiadOmaNiwIV555RXY+JT26+Kp0wCQLg2sVjvuVM0xRERERK5SrQzRiy++iOXLl+P1119Hz549IYTATz/9hISEBBQVFeG1116r6XbetLx09lMghAYSSmBROTJEDIiIiIhcpVoB0apVq/D+++/LT7kHgE6dOuGWW27BuHHjGBBdB0+9ffC3sGkgqYESxyUzPsuMiIjIZap1yezChQuVDpxu06YNLly4cMONqk8a6MsCIMfdqlUMiIiIiFytWgFRp06dKp22npiYiI4dO95wo+oTvUYFlQQIYc8UWcpm7HFQNRERketU65LZ/Pnzce+992Lz5s2IjIyEJElITU3FqVOnsGHDhppu401NkiR46TSwOp5477h/EgdVExERuUy1MkS9e/fG77//jgceeAA5OTm4cOEChg0bhoMHD2LFihU13cabnqdeDdjKLplJjgwRAyIiIiJXqfZ9iIKDgysMnv7111+xatUqfPDBBzfcsPrES6dBriNDpHJkiHjJjIiIyFWqlSGimuVZ7gGvxZJkL2SGiIiIyGUYELkBL50GwnFjRkdAxAwRERGRyzAgcgNeeg1guyxDxICIiIjIZa5rDNGwYcOuuj4nJ+dG2lJveeouXTKzlMVDvGRGRETkOtcVEBmNxmuuf+yxx26oQfWR/ZJZ2SwzRyEzRERERC5zXQERp9TXDqdB1RD2QmaIiIiIXIZjiNyAl04DIY8hKitkhoiIiMhlGBC5gfIZIouw2QuZISIiInIZBkRuoIFecykgQllAxEd3EBERuQwDIjfgqdNAOB7d4cgQWUsUbBEREVH9woDIDXjp1EDZLLMiUWov5CUzIiIil2FA5AY89RoImw4AUGQrC4g4qJqIiMhlGBC5AecMUdmlstIiBVtERERUvzAgcgP2MURlGSLH2KESBkRERESuwoDIDTTQa4CyQdWFtrJLZaWFgBAKtoqIiKj+YEDkBjz1avnRHYWO6fbCxplmRERELsKAyA146TRA2SWzwvL3HyotVKhFRERE9QsDIjfgoVVdGlRdagFQ9vwOjiMiIiJyCQZEbkCSJHhqDACAYpsFNq39PTNERERErsGAyE0YtB7y+yLHe2aIiIiIXIIBkZtooDPI74uYISIiInIpBkRuwkuvhbDZH/BapNHbC5khIiIicgkGRG7Cs9xMsyKN/ZUZIiIiItdQNCBKSkpCx44d4ePjAx8fH0RGRuLbb7+V1wshkJCQgODgYBgMBvTp0wcHDx502ofFYsGECRPQqFEjeHl5YciQITh9+rRTnezsbMTGxsJoNMJoNCI2NhY5OTmu6GKVeenK3YtIWxYQMUNERETkEooGRE2aNMHrr7+On3/+GT///DPuvvtu3H///XLQM3/+fCxYsACJiYnYs2cPTCYTBgwYgLy8PHkf8fHxWLduHZKTk7F9+3bk5+cjOjoaVqtVrhMTE4O0tDSkpKQgJSUFaWlpiI2NdXl/r8az3N2qi9TMEBEREbmUcDO+vr7i/fffFzabTZhMJvH666/L64qKioTRaBRLliwRQgiRk5MjtFqtSE5Oluv8/fffQqVSiZSUFCGEEIcOHRIAxM6dO+U6O3bsEADEkSNHqtwus9ksAAiz2XyjXazU85+libZLBoj2K9uL7R8OFGKWjxD71tTKsYiIiOqLqv5+u80YIqvViuTkZFy8eBGRkZFIT09HZmYmoqKi5Dp6vR69e/dGamoqAGDv3r0oKSlxqhMcHIz27dvLdXbs2AGj0YiIiAi5Tvfu3WE0GuU67sDpAa8q++BqZoiIiIhcQ6N0A/bv34/IyEgUFRWhQYMGWLduHW699VY5WAkMDHSqHxgYiBMnTgAAMjMzodPp4OvrW6FOZmamXCcgIKDCcQMCAuQ6lbFYLLBYLj1GIzc3t3odrCL7A17tAVGBuuy0cAwRERGRSyieIWrdujXS0tKwc+dOPP300xg1ahQOHTokr5ckyam+EKJC2eUur1NZ/WvtZ+7cufIgbKPRiJCQkKp2qVrKP+C1SFV2WpghIiIicgnFAyKdToeWLVuiW7dumDt3Ljp16oS3334bJpMJACpkcbKysuSskclkQnFxMbKzs69a5+zZsxWOe+7cuQrZp/KmT58Os9ksL6dOnbqhfl5Lg/KDqlVqe2Gp5SpbEBERUU1RPCC6nBACFosFYWFhMJlM2LRpk7yuuLgYW7duRY8ePQAAXbt2hVardaqTkZGBAwcOyHUiIyNhNpuxe/duuc6uXbtgNpvlOpXR6/Xy7QAcS23y9tCUyxA5Hu7KDBEREZErKDqG6P/9v/+HwYMHIyQkBHl5eUhOTsaWLVuQkpICSZIQHx+POXPmIDw8HOHh4ZgzZw48PT0RExMDADAajRg9ejQmT54Mf39/+Pn5YcqUKejQoQP69+8PAGjbti0GDRqEMWPGYOnSpQCAsWPHIjo6Gq1bt1as75fz1mvlMUSFkuOSGccQERERuYKiAdHZs2cRGxuLjIwMGI1GdOzYESkpKRgwYAAAYOrUqSgsLMS4ceOQnZ2NiIgIbNy4Ed7e3vI+Fi5cCI1Gg+HDh6OwsBD9+vXDypUroVar5Tpr167FxIkT5dloQ4YMQWJioms7ew0NPDQQjktmjqFNHFRNRETkEpIQQijdiLogNzcXRqMRZrO5Vi6fHTxjxgMfJUDfeDMeNt6KmWkpQPsHgYc+qPFjERER1RdV/f12uzFE9ZWPh/bSfYhQFqMyQ0REROQSDIjcRAO9BigbVF0Am72Q0+6JiIhcggGRmyg/hqjAVvYcNmaIiIiIXIIBkZvQqlXQqTwAAAWOB9MyQ0REROQSDIjciIemLCCyldgLmCEiIiJyCQZEbsRTaw+ICm2l9gJmiIiIiFyCAZEb8dJ4AgAKbcX2AmaIiIiIXIIBkRtpoLMHRBbHJTNmiIiIiFyCAZEb8dbbA6JiwQwRERGRKzEgciPeegMAoEQU22/NaLUANpuibSIiIqoPGBC5kYb6BgAAAYESRyEf8EpERFTrGBC5kYYGT/l9oarsCa8MiIiIiGodAyI3YjR4QAj7KSlS2+9azYCIiIio9jEgciPeHhqg7PEdRRr7eCKUcKYZERFRbWNA5Ea8PbQQouyJ9zq9vZAZIiIiolrHgMiNNNBfyhAVlj3Gg1PviYiIah8DIjfiXe6J90UaxxgiXjIjIiKqbQyI3Ii3hxZwXDJT21+ZISIiIqp9DIjcSPkMUSEzRERERC7DgMiN2GeZ2TNDBSq1vZAZIiIiolrHgMiNGLRqQNgzQxelsoCIGSIiIqJax4DIjUiSBI3KPt3+olR2apghIiIiqnUMiNyMzhEQwfHoDmaIiIiIahsDIjejU9nvP1QAZoiIiIhchQGRm/FQ2wOii44CZoiIiIhqHQMiN+NRdofqAiHsBcwQERER1ToGRG7Gs+yhrgUoC4iYISIiIqp1DIjcjKeuLCBihoiIiMhlGBC5GS+tPSAqEjZ7ATNEREREtY4BkZvx1nsCAIrgCIgsCraGiIiofmBA5Ga8dY4MkdVeUMIMERERUW1jQORmjB5eAIBilAVEpRxDREREVNsUDYjmzp2L22+/Hd7e3ggICMDQoUNx9OhRpzpCCCQkJCA4OBgGgwF9+vTBwYMHnepYLBZMmDABjRo1gpeXF4YMGYLTp0871cnOzkZsbCyMRiOMRiNiY2ORk5NT2128bnJAJJXaC5ghIiIiqnWKBkRbt27FM888g507d2LTpk0oLS1FVFQULl6Ub0uI+fPnY8GCBUhMTMSePXtgMpkwYMAA5OXlyXXi4+Oxbt06JCcnY/v27cjPz0d0dDSsVqtcJyYmBmlpaUhJSUFKSgrS0tIQGxvr0v5WhZ/BGwBQghJ7ATNEREREtU4SwjG/W3nnzp1DQEAAtm7dirvuugtCCAQHByM+Ph7Tpk0DYM8GBQYGYt68efj3v/8Ns9mMxo0bY/Xq1RgxYgQA4MyZMwgJCcGGDRswcOBAHD58GLfeeit27tyJiIgIAMDOnTsRGRmJI0eOoHXr1tdsW25uLoxGI8xmM3x8fGrtO9h5/ATGbI0GAPyafhIqY1Pguf21djwiIqKbWVV/v91qDJHZbAYA+Pn5AQDS09ORmZmJqKgouY5er0fv3r2RmpoKANi7dy9KSkqc6gQHB6N9+/ZynR07dsBoNMrBEAB0794dRqNRruMugnyM8vsCSeK0eyIiIhfQKN0AByEEJk2ahF69eqF9+/YAgMzMTABAYGCgU93AwECcOHFCrqPT6eDr61uhjmP7zMxMBAQEVDhmQECAXOdyFosFFsulKe+5ubnV7Nn1aezVAEKoIUlW5KtUaMAbMxIREdU6t8kQjR8/Hr/99hs+/vjjCuskSXL6LISoUHa5y+tUVv9q+5k7d648ANtoNCIkJKQq3bhhBp0asOkBABdVzBARERG5glsERBMmTMBXX32FH3/8EU2aNJHLTSYTAFTI4mRlZclZI5PJhOLiYmRnZ1+1ztmzZysc99y5cxWyTw7Tp0+H2WyWl1OnTlW/g9dBkiSohP0Br/kqFWArBaylLjk2ERFRfaVoQCSEwPjx4/Hll1/ihx9+QFhYmNP6sLAwmEwmbNq0SS4rLi7G1q1b0aNHDwBA165dodVqnepkZGTgwIEDcp3IyEiYzWbs3r1brrNr1y6YzWa5zuX0ej18fHycFldRw35zxouqstPDLBEREVGtUnQM0TPPPIOPPvoI//nPf+Dt7S1ngoxGIwwGAyRJQnx8PObMmYPw8HCEh4djzpw58PT0RExMjFx39OjRmDx5Mvz9/eHn54cpU6agQ4cO6N+/PwCgbdu2GDRoEMaMGYOlS5cCAMaOHYvo6OgqzTBzNa3kiVIA+Y7LeSVFgN5b0TYRERHdzBQNiJKSkgAAffr0cSpfsWIF4uLiAABTp05FYWEhxo0bh+zsbERERGDjxo3w9r4UICxcuBAajQbDhw9HYWEh+vXrh5UrV0KtVst11q5di4kTJ8qz0YYMGYLExMTa7WA16dWeKASQq9YBKGSGiIiIqJa51X2I3Jmr7kMEAFFrxiLDugPPZRfiiZxzwDN7gMatavWYREREN6M6eR8isvPU2h/fkavW2guK8xVsDRER0c2PAZEbaqBtAAAwq8quaDIgIiIiqlUMiNyQj94eEOVKZWOgii9epTYRERHdKAZEbqhh2YwyOSCyMENERERUmxgQuSFfg33QV55j2n1xnoKtISIiuvkxIHJD/p72gOii46kizBARERHVKgZEbqix12UBEQdVExER1SoGRG4ooEFDAECRymYv4KBqIiKiWsWAyA01LrtkZnEERBaOISIiIqpNDIjcUAOdfdp9icoKAfCSGRERUS1jQOSGHDdmFBJQJEkcVE1ERFTLGBC5IYPGYI+GAFxUScwQERER1TIGRG5IkiSo4QEAyJdUDIiIiIhqGQMiN6VVeQIALqpUvGRGRERUyxgQuSmdygAAyOclMyIiolrHgMhNGdReAIB8ZoiIiIhqHQMiN+WpsQdEF1UqoOQiYLMp3CIiIqKbFwMiN+WlK8sQOR7wWsK7VRMREdUWBkRuyrvsXkR5KrW9gJfNiIiIag0DIjdl9LAHRDkqnb2AA6uJiIhqDQMiN+XrYX+eWY6ksRfweWZERES1hgGRm/Ire8BrruOSGZ94T0REVGsYELkpf4M3gHJjiHjJjIiIqNYwIHJT3jp7QJSvKjtFHFRNRERUaxgQuSkvrX3afYFj2n0xxxARERHVFgZEbqqBzj7LrNBxhpghIiIiqjUMiNyUI0NUpBL2Ag6qJiIiqjUMiNxUg7IbM1pUZY/s4KBqIiKiWsOAyE05MkRWlUAJwPsQERER1SIGRG7KERABZQ94ZYaIiIio1jAgclMalQY6lQcAIF8lcQwRERFRLWJA5MYaaO33IjKr1JxlRkREVIsYELkxf4MfAOCCWgXBMURERES1RtGA6H//+x/uu+8+BAcHQ5IkrF+/3mm9EAIJCQkIDg6GwWBAnz59cPDgQac6FosFEyZMQKNGjeDl5YUhQ4bg9OnTTnWys7MRGxsLo9EIo9GI2NhY5OTk1HLvblxjT38AwAW1GtYiBkRERES1RdGA6OLFi+jUqRMSExMrXT9//nwsWLAAiYmJ2LNnD0wmEwYMGIC8vEvBQXx8PNatW4fk5GRs374d+fn5iI6OhtVqlevExMQgLS0NKSkpSElJQVpaGmJjY2u9fzfKz4MZIiIiIlfQKHnwwYMHY/DgwZWuE0Jg0aJFePHFFzFs2DAAwKpVqxAYGIiPPvoI//73v2E2m7F8+XKsXr0a/fv3BwCsWbMGISEh2Lx5MwYOHIjDhw8jJSUFO3fuREREBABg2bJliIyMxNGjR9G6dWvXdLYa5IBIpYZUUqBwa4iIiG5ebjuGKD09HZmZmYiKipLL9Ho9evfujdTUVADA3r17UVJS4lQnODgY7du3l+vs2LEDRqNRDoYAoHv37jAajXKdylgsFuTm5jotrlY+Q6QpvQjYbC5vAxERUX3gtgFRZmYmACAwMNCpPDAwUF6XmZkJnU4HX1/fq9YJCAiosP+AgAC5TmXmzp0rjzkyGo0ICQm5of5UhyMg+kettheUcOo9ERFRbXDbgMhBcjztvYwQokLZ5S6vU1n9a+1n+vTpMJvN8nLq1KnrbPmN8zfYB1VnOwIiTr0nIiKqFW4bEJlMJgCokMXJysqSs0YmkwnFxcXIzs6+ap2zZ89W2P+5c+cqZJ/K0+v18PHxcVpcrUKGiHerJiIiqhVuGxCFhYXBZDJh06ZNcllxcTG2bt2KHj16AAC6du0KrVbrVCcjIwMHDhyQ60RGRsJsNmP37t1ynV27dsFsNst13NWlQdUqCIABERERUS1RdJZZfn4+jh07Jn9OT09HWloa/Pz80LRpU8THx2POnDkIDw9HeHg45syZA09PT8TExAAAjEYjRo8ejcmTJ8Pf3x9+fn6YMmUKOnToIM86a9u2LQYNGoQxY8Zg6dKlAICxY8ciOjrarWeYAYCvh31sVIlKwkVJQgNeMiMiIqoVigZEP//8M/r27St/njRpEgBg1KhRWLlyJaZOnYrCwkKMGzcO2dnZiIiIwMaNG+Ht7S1vs3DhQmg0GgwfPhyFhYXo168fVq5cCbXjMhOAtWvXYuLEifJstCFDhlzx3kfuxKAxwENtQJG1EBfUajRghoiIiKhWSEIIoXQj6oLc3FwYjUaYzWaXjieK+nwQMi7+jdVnMnHroEToOo9w2bGJiIjquqr+frvtGCKya2S4NLD6Yl72NWoTERFRdTAgcnP+Ho7nmalQaP5H4dYQERHdnBgQuTk/+Yn3apTkVrx9ABEREd04BkRuzjH1Plulhi3/nMKtISIiujkxIHJz5Z9nJl1kQERERFQbGBC5Oce9iC6o1dAWcQwRERFRbWBA5OYuPb5DBc+SCwq3hoiI6ObEgMjNXZplpoaPzQxhLVW4RURERDcfBkRuzpEhylGpAEkg5x/ONCMiIqppDIjcXEOPhgAAmyTBrFIh48xJZRtERER0E2JA5Oa0Ki2MeiMA+2WzC1l/K9wiIiKimw8DojpAvheRWoX88xkKt4aIiOjmw4CoDrg000yNInOmwq0hIiK6+TAgqgMcAdE5tRq2vCyFW0NERHTzYUBUB4T6hAIAjms10BSeV7g1RERENx8GRHVAc2NzAMAxnRZepdm4aOG9iIiIiGoSA6I6oGXDlgCAP7Va+Es5OHmhQOEWERER3VwYENUBzYzNIEGCWa2GRp2HE/8wICIiIqpJDIjqAIPGgCaeJgCAWVeIk//kK9wiIiKimwsDojqiha/9stlJnYTMc+cUbg0REdHNhQFRHdHcNxwA8KdOi7NnTincGiIiopsLA6I6ovzA6vNnT6OgmDPNiIiIagoDojqieUP71Pu/dFo0FGbsO5GjbIOIiIhuIgyI6ojmxuaQYH/Aq4/mHHb+9Y/STSIiIrppMCCqIwwaA4JVHgAASZfFgIiIiKgGMSCqQ1rofAEApfps/Ho6B4XF1sorCgGUFAH554BSiwtbSEREVDdplG4AVV0LzyD8rygDFo88lFgF9p3MRs+WjZwrndoDfBYH5J62f9b7AJ0eBW4fDTRu7fI2ExER1QXMENUhbQO7AACOeF4EUFLxstn5Y8BHwy8FQwBgyQV2LwX+7w5gZTRwcB1g4Y0diYiIymOGqA65u9PjaHRgKbI0atzS8Efs/Cvg0sr8LGDNMKDwAhDcBRj5GeDREEjfCuxZDvz+LXB8m32R1EBQR6BRK8CrsT2LpFIBKo19nUpd9r6sTP6sBtQaQOsF6DzLXsu/9wQ0HoAkKfYdERERVQcDojpEr/fBY+rGWIALsPnvxN6/+uO30zno2KQh8O1UIOcE4BsGxHwKeJVdSmvZz77knAL2rQJ++wTIOQmc+cW+1DRJdSk40nld9r7s9arvL9tW7w14+DDQIiKiWiUJIYTSjagLcnNzYTQaYTab4ePjo1g78rfORdSfa5CnVqHw9L/QxqcH1g/zgWbZXQAk4KntgKn91XeScwo4tQvI/dueWSq+CAgrYLMBttKy96WAzWpfRNmrrdS+FF8ESgrsr473pUW123GV1h4Y6X0uvTrelw+qtJ7OGSv5tZIATK2t3TYTEZHiqvr7zQxRHdOgxQA8kpaEZQ2NMJj+i9+zM7Hxq0Mw6fWwNe8Ng1ZCg9wT8NJ6wVPjCYPGAOnyzErDEPtSk2zWygOly99fa738vgAozgcseQAEYCsBCv6xLzVFpa08aKoQVHleI+iqZL1Gz4wWEVEdUq8yRO+++y7eeOMNZGRkoF27dli0aBHuvPPOKm3rLhkiWEtx4Y0wPNy4AbI0145nVVDBQ2OAQeMJg9oTnhovGLSecrCk1+jhofaAh1oPD40HPDT2V4PGA54aD/t7rQF6tR76sjp6tX0bx7Z6tR5qlbp2+muzlQVGuUBR7mWvZvtrcUHFgMsRVJVcdF7vyIbVNkl9KXAqfymwSkHVVTJcWk9Aa2CwRURURcwQXeaTTz5BfHw83n33XfTs2RNLly7F4MGDcejQITRt2lTp5lWdWgO/kEis+3Mjfmh/L/5z7gAy1MUoFB44LxoCqmJIKov9VRKwwYaC0osoKL1Yu+0SakhCCwlaSEIHCVqooIUKOqiggxpaqCQd1NBBLdkXDXRQq3TQSHpoJR00KvurVqWHVuV41UOn1kOn0kGn0kOv9oBeY4RG0kKrVkGlkqDxkKD2lKBW2ReNyvm9SpKgUZe9ShI0KIHWVgSttRA6WyE01oqLurQQamsB1KWFUJUUQFVaCFVpAVQlBZBKCyCV2IMs6fJgzFpc9n1YgeI8+1LjpHKBk8E+vkqtt2elNB6ARldWVvaq0V9a1PorlF2+rd5+SVGttWfS1JqyAfaOMk25dVoGaERU59WbDFFERAS6dOmCpKQkuaxt27YYOnQo5s6de83t3SZDBACp7wAbX5I/lmoa4K2w9/HN3x4osdogBGAVNthQDIEi2KQiWFEEIVlgQxGEVAShssCGYkAqAaQSSKpS+3tVCST5tbRsXUklr6X2bRQihAQINSDUEGWvEGoA5T9rIIRKfm+vqyr33l7/0n5UACRAqACoyl6lq5arJRUkSQW1pIYKKmgkwEOywgM2GFAKD5XV/iqVwgMl9kUqgR4lMKAYepRAL8peYYFeFEMr7GU6YYHOVvYqLNCKEkj2lgAC8nv7IuAISSQAkij33rFNbZ4PSQWbSgMB+6xEodLYF6ncZ0kNSGXlKjWESmtvtWNmowRAUkNIKvvgfNhf5c9SZZ/V9mCs3HshqSFJKghV2T5U5ffnOE7ZtyLZFwmAkCRIUMnfmCR/cSrn+o5v8/Iyqdw3LjnOSLmzIlXcTkCqZF1l5+sqZ/CKwWjl5eJK+3JuQhWOXZ02XXGDSkuv3Nar7b8629Qv7vxVhIR1R8OGQTW6T2aIyikuLsbevXvxwgsvOJVHRUUhNTW10m0sFgsslkt3ec7Nza3VNl6XsLsuvb+lGzTD3sM0/xaYVo1dCSFgE4DVJmATAlabgFUI2GzO5aU2e5nVZn9vtQmUWK0oKrWg0FqEopJCFFmLUVhaiKJSCyylRSiyWmCxFsFitcBitaC47HOxzWJfrMUosVnKFvv7UnHptVQUw1ru1YpiAPZfekkSgFQKoLTWf+yvRymA/LKlZujKFu8a26Pr2QAUV29TAccpJ6J64IWzsRg5aKoix64XAdH58+dhtVoRGBjoVB4YGIjMzMxKt5k7dy5mz57tiuZdP1NHoO+L9jEld/zbfjmjmiRJgloC1Cp3CisqJ4RAia0ERdYiWEotKLWVosRWIi/yZ2vJVdc5fXYs1hJYhRU2YYNVWC+9t9nfW202lNqsKLWVwirs7+3lVljlejZYy9bbt7dvZxM2CAh78Fn2Kiq8Qv4MR3m5dShfv9xnlPsMx6fy21QhmnCqUa2Esaj4vlyRdIU2XKn8aseQKpSUL6te5FTxL7/ifqqy55r6F6RE/HfltjMaJdeS1B6KHbteBEQOl8+2EkJUnIFVZvr06Zg0aZL8OTc3FyEhNTwzq7okCeitTAStJEmSoFProFPr7EkTIiKiGlIvAqJGjRpBrVZXyAZlZWVVyBo56PV66PV6VzSPiIiIFFYvnmWm0+nQtWtXbNq0yal806ZN6NGjh0KtIiIiIndRLzJEADBp0iTExsaiW7duiIyMxHvvvYeTJ0/iqaeeUrppREREpLB6ExCNGDEC//zzD15++WVkZGSgffv22LBhA0JDQ5VuGhERESms3tyH6Ea51X2IiIiIqEqq+vtdL8YQEREREV0NAyIiIiKq9xgQERERUb3HgIiIiIjqPQZEREREVO8xICIiIqJ6jwERERER1XsMiIiIiKjeY0BERERE9V69eXTHjXLc0Ds3N1fhlhAREVFVOX63r/VgDgZEVZSXlwcACAkJUbglREREdL3y8vJgNBqvuJ7PMqsim82GM2fOwNvbG5Ik1dh+c3NzERISglOnTt20z0hjH+u+m71/APt4M7jZ+wfc/H2sjf4JIZCXl4fg4GCoVFceKcQMURWpVCo0adKk1vbv4+NzU/5xl8c+1n03e/8A9vFmcLP3D7j5+1jT/btaZsiBg6qJiIio3mNARERERPUeAyKF6fV6zJo1C3q9Xumm1Br2se672fsHsI83g5u9f8DN30cl+8dB1URERFTvMUNERERE9R4DIiIiIqr3GBARERFRvceAiIiIiOo9BkQKe/fddxEWFgYPDw907doV27ZtU7pJVTJ37lzcfvvt8Pb2RkBAAIYOHYqjR4861YmLi4MkSU5L9+7dnepYLBZMmDABjRo1gpeXF4YMGYLTp0+7siuVSkhIqNB2k8kkrxdCICEhAcHBwTAYDOjTpw8OHjzotA937ZtDs2bNKvRRkiQ888wzAOrm+fvf//6H++67D8HBwZAkCevXr3daX1PnLTs7G7GxsTAajTAajYiNjUVOTk4t9+7q/SspKcG0adPQoUMHeHl5ITg4GI899hjOnDnjtI8+ffpUOK+PPPKIW/QPuPY5rKm/S3fuY2X/LiVJwhtvvCHXcefzWJXfB3f8t8iASEGffPIJ4uPj8eKLL+KXX37BnXfeicGDB+PkyZNKN+2atm7dimeeeQY7d+7Epk2bUFpaiqioKFy8eNGp3qBBg5CRkSEvGzZscFofHx+PdevWITk5Gdu3b0d+fj6io6NhtVpd2Z1KtWvXzqnt+/fvl9fNnz8fCxYsQGJiIvbs2QOTyYQBAwbIz7wD3LtvALBnzx6n/m3atAkA8PDDD8t16tr5u3jxIjp16oTExMRK19fUeYuJiUFaWhpSUlKQkpKCtLQ0xMbGKtq/goIC7Nu3DzNmzMC+ffvw5Zdf4vfff8eQIUMq1B0zZozTeV26dKnTeqX6B1z7HAI183fpzn0s37eMjAx88MEHkCQJDz74oFM9dz2PVfl9cMt/i4IUc8cdd4innnrKqaxNmzbihRdeUKhF1ZeVlSUAiK1bt8plo0aNEvfff/8Vt8nJyRFarVYkJyfLZX///bdQqVQiJSWlNpt7TbNmzRKdOnWqdJ3NZhMmk0m8/vrrcllRUZEwGo1iyZIlQgj37tuVPPvss6JFixbCZrMJIer2+RNCCABi3bp18ueaOm+HDh0SAMTOnTvlOjt27BAAxJEjR2q5V5dc3r/K7N69WwAQJ06ckMt69+4tnn322Stu4y79E6LyPtbE36W79/Fy999/v7j77rudyurSebz898Fd/y0yQ6SQ4uJi7N27F1FRUU7lUVFRSE1NVahV1Wc2mwEAfn5+TuVbtmxBQEAAWrVqhTFjxiArK0tet3fvXpSUlDh9B8HBwWjfvr1bfAd//PEHgoODERYWhkceeQR//fUXACA9PR2ZmZlO7dbr9ejdu7fcbnfv2+WKi4uxZs0aPPHEE04PL67L5+9yNXXeduzYAaPRiIiICLlO9+7dYTQa3a7fZrMZkiShYcOGTuVr165Fo0aN0K5dO0yZMsXp/8rrQv9u9O+yLvTR4ezZs/jmm28wevToCuvqynm8/PfBXf8t8uGuCjl//jysVisCAwOdygMDA5GZmalQq6pHCIFJkyahV69eaN++vVw+ePBgPPzwwwgNDUV6ejpmzJiBu+++G3v37oVer0dmZiZ0Oh18fX2d9ucO30FERAQ+/PBDtGrVCmfPnsWrr76KHj164ODBg3LbKjt3J06cAAC37ltl1q9fj5ycHMTFxclldfn8VaamzltmZiYCAgIq7D8gIMCt+l1UVIQXXngBMTExTg/JHDlyJMLCwmAymXDgwAFMnz4dv/76q3zJ1N37VxN/l+7ex/JWrVoFb29vDBs2zKm8rpzHyn4f3PXfIgMihZX/v3HA/sdzeZm7Gz9+PH777Tds377dqXzEiBHy+/bt26Nbt24IDQ3FN998U+Efd3nu8B0MHjxYft+hQwdERkaiRYsWWLVqlTyAszrnzh36Vpnly5dj8ODBCA4Olsvq8vm7mpo4b5XVd6d+l5SU4JFHHoHNZsO7777rtG7MmDHy+/bt2yM8PBzdunXDvn370KVLFwDu3b+a+rt05z6W98EHH2DkyJHw8PBwKq8r5/FKvw+A+/1b5CUzhTRq1AhqtbpCFJuVlVUhanZnEyZMwFdffYUff/wRTZo0uWrdoKAghIaG4o8//gAAmEwmFBcXIzs726meO34HXl5e6NChA/744w95ttnVzl1d6tuJEyewefNmPPnkk1etV5fPH4AaO28mkwlnz56tsP9z5865Rb9LSkowfPhwpKenY9OmTU7Zocp06dIFWq3W6by6c/8uV52/y7rSx23btuHo0aPX/LcJuOd5vNLvg7v+W2RApBCdToeuXbvK6U2HTZs2oUePHgq1quqEEBg/fjy+/PJL/PDDDwgLC7vmNv/88w9OnTqFoKAgAEDXrl2h1WqdvoOMjAwcOHDA7b4Di8WCw4cPIygoSE5Tl293cXExtm7dKre7LvVtxYoVCAgIwL333nvVenX5/AGosfMWGRkJs9mM3bt3y3V27doFs9mseL8dwdAff/yBzZs3w9/f/5rbHDx4ECUlJfJ5def+VaY6f5d1pY/Lly9H165d0alTp2vWdafzeK3fB7f9t3jdw7CpxiQnJwutViuWL18uDh06JOLj44WXl5c4fvy40k27pqeffloYjUaxZcsWkZGRIS8FBQVCCCHy8vLE5MmTRWpqqkhPTxc//vijiIyMFLfccovIzc2V9/PUU0+JJk2aiM2bN4t9+/aJu+++W3Tq1EmUlpYq1TUhhBCTJ08WW7ZsEX/99ZfYuXOniI6OFt7e3vK5ef3114XRaBRffvml2L9/v3j00UdFUFBQnehbeVarVTRt2lRMmzbNqbyunr+8vDzxyy+/iF9++UUAEAsWLBC//PKLPMuqps7boEGDRMeOHcWOHTvEjh07RIcOHUR0dLSi/SspKRFDhgwRTZo0EWlpaU7/Li0WixBCiGPHjonZs2eLPXv2iPT0dPHNN9+INm3aiM6dO7tF/67Vx5r8u3TXPjqYzWbh6ekpkpKSKmzv7ufxWr8PQrjnv0UGRAr7v//7PxEaGip0Op3o0qWL07R1dwag0mXFihVCCCEKCgpEVFSUaNy4sdBqtaJp06Zi1KhR4uTJk077KSwsFOPHjxd+fn7CYDCI6OjoCnWUMGLECBEUFCS0Wq0IDg4Ww4YNEwcPHpTX22w2MWvWLGEymYRerxd33XWX2L9/v9M+3LVv5X333XcCgDh69KhTeV09fz/++GOlf5ejRo0SQtTcefvnn3/EyJEjhbe3t/D29hYjR44U2dnZivYvPT39iv8uf/zxRyGEECdPnhR33XWX8PPzEzqdTrRo0UJMnDhR/PPPP27Rv2v1sSb/Lt21jw5Lly4VBoNB5OTkVNje3c/jtX4fhHDPf4tSWeOJiIiI6i2OISIiIqJ6jwERERER1XsMiIiIiKjeY0BERERE9R4DIiIiIqr3GBARERFRvceAiIiIiOo9BkRERFUkSRLWr1+vdDOIqBYwICKiOiEuLg6SJFVYBg0apHTTiOgmoFG6AUREVTVo0CCsWLHCqUyv1yvUGiK6mTBDRER1hl6vh8lkclp8fX0B2C9nJSUlYfDgwTAYDAgLC8Nnn33mtP3+/ftx9913w2AwwN/fH2PHjkV+fr5TnQ8++ADt2rWDXq9HUFAQxo8f77T+/PnzeOCBB+Dp6Ynw8HB89dVX8rrs7GyMHDkSjRs3hsFgQHh4eIUAjojcEwMiIrppzJgxAw8++CB+/fVX/Otf/8Kjjz6Kw4cPAwAKCgowaNAg+Pr6Ys+ePfjss8+wefNmp4AnKSkJzzzzDMaOHYv9+/fjq6++QsuWLZ2OMXv2bAwfPhy//fYb7rnnHowcORIXLlyQj3/o0CF8++23OHz4MJKSktCoUSPXfQFEVH3VeiQsEZGLjRo1SqjVauHl5eW0vPzyy0II+xO2n3rqKadtIiIixNNPPy2EEOK9994Tvr6+Ij8/X17/zTffCJVKJTIzM4UQQgQHB4sXX3zxim0AIF566SX5c35+vpAkSXz77bdCCCHuu+8+8fjjj9dMh4nIpTiGiIjqjL59+yIpKcmpzM/PT34fGRnptC4yMhJpaWkAgMOHD6NTp07w8vKS1/fs2RM2mw1Hjx6FJEk4c+YM+vXrd9U2dOzYUX7v5eUFb29vZGVlAQCefvppPPjgg9i3bx+ioqIwdOhQ9OjRo1p9JSLXYkBERHWGl5dXhUtY1yJJEgBACCG/r6yOwWCo0v60Wm2FbW02GwBg8ODBOHHiBL755hts3rwZ/fr1wzPPPIM333zzutpMRK7HMUREdNPYuXNnhc9t2rQBANx6661IS0vDxYsX5fU//fQTVCoVWrVqBW9vbzRr1gzff//9DbWhcePGiIuLw5o1a7Bo0SK89957N7Q/InINZoiIqM6wWCzIzMx0KtNoNPLA5c8++wzdunVDr169sHbtWuzevRvLly8HAIwcORKzZs3CqFGjkJCQgHPnzmHChAmIjY1FYGAgACAhIQFPPfUUAgICMHjwYOTl5eGnn37ChAkTqtS+mTNnomvXrmjXrh0sFgu+/vprtG3btga/ASKqLQyIiKjOSElJQVBQkFNZ69atceTIEQD2GWDJyckYN24cTCYT1q5di1tvvRUA4Onpie+++w7PPvssbr/9dnh6euLBBx/EggUL5H2NGjUKRUVFWLhwIaZMmYJGjRrhoYceqnL7dDodpk+fjuPHj8NgMODOO+9EcnJyDfSciGqbJIQQSjeCiOhGSZKEdevWYejQoUo3hYjqII4hIiIionqPARERERHVexxDREQ3BV79J6IbwQwRERER1XsMiIiIiKjeY0BERERE9R4DIiIiIqr3GBARERFRvceAiIiIiOo9BkRERERU7zEgIiIionqPARERERHVe/8fgZUFBpXO2mAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curves\n",
    "plt.plot(epoch_count, np.array(torch.tensor(predict_train_loss_values).numpy()), label=\"Predict train loss\")\n",
    "plt.plot(epoch_count, predict_test_loss_values, label=\"Predict test loss\")\n",
    "\n",
    "plt.plot(epoch_count, np.array(torch.tensor(forecast_train_loss_values).numpy()), label=\"Forecast train loss\")\n",
    "\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c93aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
