{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a93950b4",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron Model\n",
    "\n",
    "- BOOK: [Predict the Future with MLPs, CNNs and LSTMs in Python](https://machinelearningmastery.com/deep-learning-for-time-series-forecasting/) by Jason Brownlee\n",
    "- NOTES: [TS -> ML split function](https://detraviousjbrinkley.notion.site/TS-ML-split-function-9ab51cbb49d244aa8b4ab434d009f8a7?pvs=4) by Detravious J.B. \n",
    "    - See for Forecast vs Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a0382d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchviz in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (0.0.3)\n",
      "Requirement already satisfied: keras in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (3.9.2)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp39-cp39-macosx_12_0_arm64.whl (252.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 252.5 MB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from torchviz) (2.6.0)\n",
      "Requirement already satisfied: graphviz in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from torchviz) (0.20.3)\n",
      "Requirement already satisfied: optree in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from keras) (0.15.0)\n",
      "Requirement already satisfied: numpy in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from keras) (2.0.2)\n",
      "Requirement already satisfied: packaging in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from keras) (24.2)\n",
      "Requirement already satisfied: rich in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from keras) (14.0.0)\n",
      "Requirement already satisfied: namex in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from keras) (3.13.0)\n",
      "Requirement already satisfied: absl-py in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from keras) (2.2.2)\n",
      "Requirement already satisfied: ml-dtypes in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from keras) (0.5.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 21.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "\u001b[K     |████████████████████████████████| 417 kB 17.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 3.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.13.1)\n",
      "Collecting tensorboard~=2.19.0\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5 MB 32.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.8 MB 27.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-macosx_12_0_arm64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 21.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.71.0-cp39-cp39-macosx_10_14_universal2.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 31.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 16.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 30.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.4 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (8.6.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from torch->torchviz) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from torch->torchviz) (1.13.1)\n",
      "Requirement already satisfied: filelock in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from torch->torchviz) (3.18.0)\n",
      "Requirement already satisfied: networkx in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from torch->torchviz) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from torch->torchviz) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, protobuf, markdown, grpcio, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 libclang-18.1.1 markdown-3.7 opt-einsum-3.4.0 protobuf-5.29.4 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.0.1 werkzeug-3.1.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchviz keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2335e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../framework_for_time_series_data/tslearn/'))\n",
    "from ml_models import MLP\n",
    "from ts_models import EvaluationMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f86d7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = [10, 20, 30, 40, 50, 60, 70, 80, 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45624d9b",
   "metadata": {},
   "source": [
    "# Book's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f03ecb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out): \n",
    "    X, y = list(), list() \n",
    "    for i in range(len(sequence)): \n",
    "        # find the end of this pattern \n",
    "        end_ix = i + n_steps_in \n",
    "        out_end_ix = end_ix + n_steps_out \n",
    "        # check if we are beyond the sequence \n",
    "        if out_end_ix > len(sequence): \n",
    "            break\n",
    "        # gather input and output parts of the pattern \n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix] \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1dc84b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_sequence(observations, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a17514bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20, 30],\n",
       "       [20, 30, 40],\n",
       "       [30, 40, 50],\n",
       "       [40, 50, 60]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d9dd5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 50, 60],\n",
       "       [50, 60, 70],\n",
       "       [60, 70, 80],\n",
       "       [70, 80, 90]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0e431",
   "metadata": {},
   "source": [
    "# My implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e506fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_uts_sequence_to_sml(uts_observations, prior_observations, forecasting_step):\n",
    "    \"\"\"Splits a given UTS into multiple input rows where each input row has a specified number of timestamps and the output is a single timestamp.\n",
    "    \n",
    "    Parameters:\n",
    "    uts_observations -- 1D np array (of UTS data to transform to SML data with size  b rows/length x 1 dimension)\n",
    "    prior_observations -- py int (of all observations before we get to where we want to start making the predictions)\n",
    "    forecasting_step -- py int (of how far out to forecast, 1 only the next timestamp, 2 the next two timestamps, ... n the next n timestamps)\n",
    "    \n",
    "    Return:\n",
    "    agg.values -- np array (of new sml data)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(uts_observations)\n",
    "    cols = list()\n",
    "    \n",
    "    lag_col_names = []\n",
    "    count_lag = 0\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for prior_observation in range(prior_observations, 0, -1):\n",
    "        # print(\"prior_observation: \", prior_observation)\n",
    "        cols.append(df.shift(prior_observation))\n",
    "        new_col_name = \"t - \" + str(prior_observation)\n",
    "        # print(new_col_name)\n",
    "        lag_col_names.append(new_col_name)\n",
    "        \n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, forecasting_step):\n",
    "        cols.append(df.shift(-i))\n",
    "        # print(f\"t + {i}\")\n",
    "        if i == 0:\n",
    "            new_col_name = f\"t\"\n",
    "        else:\n",
    "            new_col_name = f\"t + {i}\"\n",
    "        # print(new_col_name)\n",
    "        lag_col_names.append(new_col_name)\n",
    "        \n",
    "        # put it all together\n",
    "        uts_sml_df = pd.concat(cols, axis=1) \n",
    "        uts_sml_df.columns=[lag_col_names]\n",
    "        # drop rows with NaN values\n",
    "        uts_sml_df.dropna(inplace=True)\n",
    "    \n",
    "    # print(uts_sml_df)\n",
    "    \n",
    "    # colums to use to make prediction for last col\n",
    "    X_train = uts_sml_df.iloc[:, 0: -1]\n",
    "    \n",
    "    # last column\n",
    "    y_train = uts_sml_df.iloc[:, [-1]]\n",
    "    return uts_sml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c1f6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 3\n",
    "output_size = 2\n",
    "converted_seq_df = convert_uts_sequence_to_sml(observations, n_steps, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9cf9a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 3</th>\n",
       "      <th>t - 2</th>\n",
       "      <th>t - 1</th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 3 t - 2 t - 1   t t + 1\n",
       "3  10.0  20.0  30.0  40  50.0\n",
       "4  20.0  30.0  40.0  50  60.0\n",
       "5  30.0  40.0  50.0  60  70.0\n",
       "6  40.0  50.0  60.0  70  80.0\n",
       "7  50.0  60.0  70.0  80  90.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_seq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4216c4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 3</th>\n",
       "      <th>t - 2</th>\n",
       "      <th>t - 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 3 t - 2 t - 1\n",
       "3  10.0  20.0  30.0\n",
       "4  20.0  30.0  40.0\n",
       "5  30.0  40.0  50.0\n",
       "6  40.0  50.0  60.0\n",
       "7  50.0  60.0  70.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_X_train_df = converted_seq_df.iloc[:, :n_steps]\n",
    "forecast_X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3030b03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t t + 1\n",
       "3  40  50.0\n",
       "4  50  60.0\n",
       "5  60  70.0\n",
       "6  70  80.0\n",
       "7  80  90.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_y_train_df = converted_seq_df.iloc[:, -output_size:]\n",
    "forecast_y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b13497cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 1</th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70.0</td>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 1   t t + 1\n",
       "7  70.0  80  90.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_X_test_df = converted_seq_df.iloc[[-1], -n_steps:]\n",
    "forecast_X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42d3307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 3</th>\n",
       "      <th>t - 2</th>\n",
       "      <th>t - 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 3 t - 2 t - 1\n",
       "3  10.0  20.0  30.0\n",
       "4  20.0  30.0  40.0\n",
       "5  30.0  40.0  50.0\n",
       "6  40.0  50.0  60.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X_train_df = converted_seq_df.iloc[:-1, :n_steps]\n",
    "predict_X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c2da8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t t + 1\n",
       "3  40  50.0\n",
       "4  50  60.0\n",
       "5  60  70.0\n",
       "6  70  80.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_train_df = converted_seq_df.iloc[:-1, -output_size:]\n",
    "predict_y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da43b0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 1</th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 1   t t + 1\n",
       "5  50.0  60  70.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X_test_df = converted_seq_df.iloc[[-n_steps], -n_steps:]\n",
    "predict_X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c11b99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t t + 1\n",
       "7  80  90.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_test_df = converted_seq_df.iloc[[-1], -output_size:]\n",
    "predict_y_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31c65e",
   "metadata": {},
   "source": [
    "# Book's implementation\n",
    "- Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c3248",
   "metadata": {},
   "source": [
    "## Forecast model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2586bf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/detraviousjamaribrinkley/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "\n",
    "forecast_model = Sequential() \n",
    "forecast_model.add(Dense(100, activation='relu' , input_dim=n_steps)) \n",
    "forecast_model.add(Dense(output_size)) \n",
    "forecast_model.compile(optimizer='adam' , loss='mse') \n",
    "\n",
    "predict_model = Sequential() \n",
    "predict_model.add(Dense(100, activation='relu' , input_dim=n_steps)) \n",
    "predict_model.add(Dense(output_size)) \n",
    "predict_model.compile(optimizer='adam' , loss='mse') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a7c14ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3646bd4f0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model \n",
    "forecast_model.fit(forecast_X_train_df, forecast_y_train_df, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e475fd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[70., 80., 90.]]), 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_X_test = np.array(forecast_X_test_df)\n",
    "forecast_X_test, forecast_X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90b9f8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70., 80., 90.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = forecast_X_test.reshape((forecast_X_test.shape[0]), n_steps)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a0262d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102.27615 , 115.172455]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts = forecast_model.predict(X_test, verbose=0)\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ff7db",
   "metadata": {},
   "source": [
    "## Predict model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a17a48c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1571598b0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model.fit(predict_X_train_df, predict_y_train_df, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aea502e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[50., 60., 70.]]), 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X_test = np.array(predict_X_test_df)\n",
    "predict_X_test, predict_X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ece813e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70., 80., 90.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_X_test = forecast_X_test.reshape((predict_X_test.shape[0]), n_steps)\n",
    "predict_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1cabd8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70.81254 , 44.407104]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_model_predictions = predict_model.predict(predict_X_test, verbose=0)\n",
    "book_model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7afabf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t + 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t t + 1\n",
       "7  80  90.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67322618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1081.561\n"
     ]
    }
   ],
   "source": [
    "EvaluationMetric.eval_mse(predict_y_test_df, book_model_predictions, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ac988a",
   "metadata": {},
   "source": [
    "## My implementation\n",
    "\n",
    "- Using my TSLearn library\n",
    "\n",
    "### Prediction model\n",
    "\n",
    "- Interpolation of in sample values \n",
    "- Use `50, 60, 70`, so X_test\n",
    "- True predictions `80, 90`, so y_test\n",
    "\n",
    "### Forecast model\n",
    "\n",
    "- Extrapolation of future values `\n",
    "- Use `70, 80, 90`, so X_test\n",
    "- Expected `100, 110`. We say expected because we don't know the actual values, thus no y_test. Expected as in we increment by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c3c3df5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=3, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "\n",
    "mlp_predict_model = MLP(n_steps, hidden_size, output_size)\n",
    "mlp_predict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ffb43a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=3, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_forecast_model = MLP(n_steps, hidden_size, output_size)\n",
    "mlp_forecast_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8559b466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>t - 3</th>\n",
       "      <th>t - 2</th>\n",
       "      <th>t - 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t - 3 t - 2 t - 1\n",
       "3  10.0  20.0  30.0\n",
       "4  20.0  30.0  40.0\n",
       "5  30.0  40.0  50.0\n",
       "6  40.0  50.0  60.0\n",
       "7  50.0  60.0  70.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fcae1763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 446/2000 [00:00<00:00, 2260.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "    Predictions | Train loss: 3612.525390625 | Test loss: 6705.201171875\n",
      "    Forecasts | Train loss: 3860.21484375\n",
      "Epoch: 10\n",
      "    Predictions | Train loss: 2514.178955078125 | Test loss: 4318.04345703125\n",
      "    Forecasts | Train loss: 2439.859130859375\n",
      "Epoch: 20\n",
      "    Predictions | Train loss: 1615.9520263671875 | Test loss: 2449.9228515625\n",
      "    Forecasts | Train loss: 1360.2803955078125\n",
      "Epoch: 30\n",
      "    Predictions | Train loss: 930.2633056640625 | Test loss: 1128.3590087890625\n",
      "    Forecasts | Train loss: 629.0550537109375\n",
      "Epoch: 40\n",
      "    Predictions | Train loss: 465.7862243652344 | Test loss: 361.6680603027344\n",
      "    Forecasts | Train loss: 224.9041748046875\n",
      "Epoch: 50\n",
      "    Predictions | Train loss: 204.73916625976562 | Test loss: 64.7137222290039\n",
      "    Forecasts | Train loss: 74.0799789428711\n",
      "Epoch: 60\n",
      "    Predictions | Train loss: 91.78459930419922 | Test loss: 53.30860900878906\n",
      "    Forecasts | Train loss: 52.65333938598633\n",
      "Epoch: 70\n",
      "    Predictions | Train loss: 56.633426666259766 | Test loss: 128.10501098632812\n",
      "    Forecasts | Train loss: 55.98839569091797\n",
      "Epoch: 80\n",
      "    Predictions | Train loss: 47.878841400146484 | Test loss: 175.05825805664062\n",
      "    Forecasts | Train loss: 52.49047088623047\n",
      "Epoch: 90\n",
      "    Predictions | Train loss: 45.281219482421875 | Test loss: 180.05162048339844\n",
      "    Forecasts | Train loss: 48.009178161621094\n",
      "Epoch: 100\n",
      "    Predictions | Train loss: 44.12367248535156 | Test loss: 166.71116638183594\n",
      "    Forecasts | Train loss: 45.9263801574707\n",
      "Epoch: 110\n",
      "    Predictions | Train loss: 43.10200881958008 | Test loss: 152.39666748046875\n",
      "    Forecasts | Train loss: 44.551307678222656\n",
      "Epoch: 120\n",
      "    Predictions | Train loss: 41.992897033691406 | Test loss: 142.98294067382812\n",
      "    Forecasts | Train loss: 43.02025604248047\n",
      "Epoch: 130\n",
      "    Predictions | Train loss: 40.94809341430664 | Test loss: 137.72019958496094\n",
      "    Forecasts | Train loss: 41.49311828613281\n",
      "Epoch: 140\n",
      "    Predictions | Train loss: 39.97053146362305 | Test loss: 134.05291748046875\n",
      "    Forecasts | Train loss: 39.994422912597656\n",
      "Epoch: 150\n",
      "    Predictions | Train loss: 38.993080139160156 | Test loss: 130.55047607421875\n",
      "    Forecasts | Train loss: 38.515777587890625\n",
      "Epoch: 160\n",
      "    Predictions | Train loss: 37.9971923828125 | Test loss: 127.10592651367188\n",
      "    Forecasts | Train loss: 37.02240753173828\n",
      "Epoch: 170\n",
      "    Predictions | Train loss: 36.99203872680664 | Test loss: 123.92790222167969\n",
      "    Forecasts | Train loss: 35.544700622558594\n",
      "Epoch: 180\n",
      "    Predictions | Train loss: 35.97614669799805 | Test loss: 120.92533111572266\n",
      "    Forecasts | Train loss: 34.070499420166016\n",
      "Epoch: 190\n",
      "    Predictions | Train loss: 34.94978332519531 | Test loss: 118.28939819335938\n",
      "    Forecasts | Train loss: 32.60559844970703\n",
      "Epoch: 200\n",
      "    Predictions | Train loss: 33.914695739746094 | Test loss: 115.69387817382812\n",
      "    Forecasts | Train loss: 31.151906967163086\n",
      "Epoch: 210\n",
      "    Predictions | Train loss: 32.87206268310547 | Test loss: 113.03636169433594\n",
      "    Forecasts | Train loss: 29.709590911865234\n",
      "Epoch: 220\n",
      "    Predictions | Train loss: 31.822263717651367 | Test loss: 110.4184341430664\n",
      "    Forecasts | Train loss: 28.28716468811035\n",
      "Epoch: 230\n",
      "    Predictions | Train loss: 30.7657470703125 | Test loss: 107.88294982910156\n",
      "    Forecasts | Train loss: 26.88556480407715\n",
      "Epoch: 240\n",
      "    Predictions | Train loss: 29.70262908935547 | Test loss: 105.410888671875\n",
      "    Forecasts | Train loss: 25.508434295654297\n",
      "Epoch: 250\n",
      "    Predictions | Train loss: 28.633485794067383 | Test loss: 102.97184753417969\n",
      "    Forecasts | Train loss: 24.156044006347656\n",
      "Epoch: 260\n",
      "    Predictions | Train loss: 27.56304359436035 | Test loss: 100.51587677001953\n",
      "    Forecasts | Train loss: 22.830461502075195\n",
      "Epoch: 270\n",
      "    Predictions | Train loss: 26.490345001220703 | Test loss: 98.0171127319336\n",
      "    Forecasts | Train loss: 21.54057502746582\n",
      "Epoch: 280\n",
      "    Predictions | Train loss: 25.436391830444336 | Test loss: 95.58628845214844\n",
      "    Forecasts | Train loss: 20.283235549926758\n",
      "Epoch: 290\n",
      "    Predictions | Train loss: 24.43487548828125 | Test loss: 93.1925277709961\n",
      "    Forecasts | Train loss: 19.06048011779785\n",
      "Epoch: 300\n",
      "    Predictions | Train loss: 23.45272445678711 | Test loss: 90.68090057373047\n",
      "    Forecasts | Train loss: 17.88155174255371\n",
      "Epoch: 310\n",
      "    Predictions | Train loss: 22.480438232421875 | Test loss: 87.56793212890625\n",
      "    Forecasts | Train loss: 16.732501983642578\n",
      "Epoch: 320\n",
      "    Predictions | Train loss: 21.528776168823242 | Test loss: 84.6453857421875\n",
      "    Forecasts | Train loss: 15.628703117370605\n",
      "Epoch: 330\n",
      "    Predictions | Train loss: 20.590988159179688 | Test loss: 81.57009887695312\n",
      "    Forecasts | Train loss: 14.567639350891113\n",
      "Epoch: 340\n",
      "    Predictions | Train loss: 19.672428131103516 | Test loss: 78.88335418701172\n",
      "    Forecasts | Train loss: 13.54938793182373\n",
      "Epoch: 350\n",
      "    Predictions | Train loss: 18.77501678466797 | Test loss: 76.07701110839844\n",
      "    Forecasts | Train loss: 12.574600219726562\n",
      "Epoch: 360\n",
      "    Predictions | Train loss: 17.892833709716797 | Test loss: 73.3454818725586\n",
      "    Forecasts | Train loss: 11.643774032592773\n",
      "Epoch: 370\n",
      "    Predictions | Train loss: 17.038942337036133 | Test loss: 70.92456817626953\n",
      "    Forecasts | Train loss: 10.757774353027344\n",
      "Epoch: 380\n",
      "    Predictions | Train loss: 16.19989776611328 | Test loss: 68.1680908203125\n",
      "    Forecasts | Train loss: 9.917512893676758\n",
      "Epoch: 390\n",
      "    Predictions | Train loss: 15.387951850891113 | Test loss: 65.92887878417969\n",
      "    Forecasts | Train loss: 9.120599746704102\n",
      "Epoch: 400\n",
      "    Predictions | Train loss: 14.597556114196777 | Test loss: 63.310035705566406\n",
      "    Forecasts | Train loss: 8.368111610412598\n",
      "Epoch: 410\n",
      "    Predictions | Train loss: 13.83012580871582 | Test loss: 60.91653060913086\n",
      "    Forecasts | Train loss: 7.6595659255981445\n",
      "Epoch: 420\n",
      "    Predictions | Train loss: 13.090089797973633 | Test loss: 58.51161193847656\n",
      "    Forecasts | Train loss: 6.996413230895996\n",
      "Epoch: 430\n",
      "    Predictions | Train loss: 12.369891166687012 | Test loss: 56.155601501464844\n",
      "    Forecasts | Train loss: 6.379690647125244\n",
      "Epoch: 440\n",
      "    Predictions | Train loss: 11.681361198425293 | Test loss: 54.07823944091797\n",
      "    Forecasts | Train loss: 5.795865058898926\n",
      "Epoch: 450\n",
      "    Predictions | Train loss: 11.01091480255127 | Test loss: 51.666812896728516\n",
      "    Forecasts | Train loss: 5.255232810974121\n",
      "Epoch: 460\n",
      "    Predictions | Train loss: 10.371971130371094 | Test loss: 49.710693359375\n",
      "    Forecasts | Train loss: 4.754974365234375\n",
      "Epoch: 470\n",
      "    Predictions | Train loss: 9.752763748168945 | Test loss: 47.44951248168945\n",
      "    Forecasts | Train loss: 4.291929244995117\n",
      "Epoch: 480\n",
      "    Predictions | Train loss: 9.163166999816895 | Test loss: 45.66116714477539\n",
      "    Forecasts | Train loss: 3.8651726245880127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 927/2000 [00:00<00:00, 2355.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 490\n",
      "    Predictions | Train loss: 8.595949172973633 | Test loss: 43.549560546875\n",
      "    Forecasts | Train loss: 3.4727587699890137\n",
      "Epoch: 500\n",
      "    Predictions | Train loss: 8.054636001586914 | Test loss: 41.81932830810547\n",
      "    Forecasts | Train loss: 3.1126437187194824\n",
      "Epoch: 510\n",
      "    Predictions | Train loss: 7.538937568664551 | Test loss: 39.920570373535156\n",
      "    Forecasts | Train loss: 2.7850518226623535\n",
      "Epoch: 520\n",
      "    Predictions | Train loss: 7.045387268066406 | Test loss: 38.228580474853516\n",
      "    Forecasts | Train loss: 2.483768939971924\n",
      "Epoch: 530\n",
      "    Predictions | Train loss: 6.579269886016846 | Test loss: 36.588565826416016\n",
      "    Forecasts | Train loss: 2.2110962867736816\n",
      "Epoch: 540\n",
      "    Predictions | Train loss: 6.134133815765381 | Test loss: 34.88982009887695\n",
      "    Forecasts | Train loss: 1.9640388488769531\n",
      "Epoch: 550\n",
      "    Predictions | Train loss: 5.713842391967773 | Test loss: 33.33481979370117\n",
      "    Forecasts | Train loss: 1.7407481670379639\n",
      "Epoch: 560\n",
      "    Predictions | Train loss: 5.313006401062012 | Test loss: 31.826629638671875\n",
      "    Forecasts | Train loss: 1.539396047592163\n",
      "Epoch: 570\n",
      "    Predictions | Train loss: 4.9385809898376465 | Test loss: 30.640323638916016\n",
      "    Forecasts | Train loss: 1.3591978549957275\n",
      "Epoch: 580\n",
      "    Predictions | Train loss: 4.579966068267822 | Test loss: 29.063261032104492\n",
      "    Forecasts | Train loss: 1.1963937282562256\n",
      "Epoch: 590\n",
      "    Predictions | Train loss: 4.249081611633301 | Test loss: 28.003252029418945\n",
      "    Forecasts | Train loss: 1.0514391660690308\n",
      "Epoch: 600\n",
      "    Predictions | Train loss: 3.938052177429199 | Test loss: 26.674476623535156\n",
      "    Forecasts | Train loss: 0.9222692251205444\n",
      "Epoch: 610\n",
      "    Predictions | Train loss: 3.648231029510498 | Test loss: 25.67138671875\n",
      "    Forecasts | Train loss: 0.8074007034301758\n",
      "Epoch: 620\n",
      "    Predictions | Train loss: 3.373821973800659 | Test loss: 24.448692321777344\n",
      "    Forecasts | Train loss: 0.7056439518928528\n",
      "Epoch: 630\n",
      "    Predictions | Train loss: 3.118163585662842 | Test loss: 23.514307022094727\n",
      "    Forecasts | Train loss: 0.6153292655944824\n",
      "Epoch: 640\n",
      "    Predictions | Train loss: 2.8765816688537598 | Test loss: 22.405241012573242\n",
      "    Forecasts | Train loss: 0.5359391570091248\n",
      "Epoch: 650\n",
      "    Predictions | Train loss: 2.653149127960205 | Test loss: 21.547618865966797\n",
      "    Forecasts | Train loss: 0.4657660126686096\n",
      "Epoch: 660\n",
      "    Predictions | Train loss: 2.4420900344848633 | Test loss: 20.54179573059082\n",
      "    Forecasts | Train loss: 0.4042414724826813\n",
      "Epoch: 670\n",
      "    Predictions | Train loss: 2.2469797134399414 | Test loss: 19.763580322265625\n",
      "    Forecasts | Train loss: 0.35030966997146606\n",
      "Epoch: 680\n",
      "    Predictions | Train loss: 2.064021587371826 | Test loss: 18.88262939453125\n",
      "    Forecasts | Train loss: 0.3029908835887909\n",
      "Epoch: 690\n",
      "    Predictions | Train loss: 1.8940293788909912 | Test loss: 18.060701370239258\n",
      "    Forecasts | Train loss: 0.26192009449005127\n",
      "Epoch: 700\n",
      "    Predictions | Train loss: 1.7356383800506592 | Test loss: 17.349388122558594\n",
      "    Forecasts | Train loss: 0.22586259245872498\n",
      "Epoch: 710\n",
      "    Predictions | Train loss: 1.5891411304473877 | Test loss: 16.62526512145996\n",
      "    Forecasts | Train loss: 0.1947142630815506\n",
      "Epoch: 720\n",
      "    Predictions | Train loss: 1.4532029628753662 | Test loss: 15.987359046936035\n",
      "    Forecasts | Train loss: 0.1674821674823761\n",
      "Epoch: 730\n",
      "    Predictions | Train loss: 1.3268113136291504 | Test loss: 15.331676483154297\n",
      "    Forecasts | Train loss: 0.14399664103984833\n",
      "Epoch: 740\n",
      "    Predictions | Train loss: 1.2108291387557983 | Test loss: 14.876206398010254\n",
      "    Forecasts | Train loss: 0.12353017181158066\n",
      "Epoch: 750\n",
      "    Predictions | Train loss: 1.1026771068572998 | Test loss: 14.230940818786621\n",
      "    Forecasts | Train loss: 0.1059933453798294\n",
      "Epoch: 760\n",
      "    Predictions | Train loss: 1.0040380954742432 | Test loss: 13.741827011108398\n",
      "    Forecasts | Train loss: 0.09073305130004883\n",
      "Epoch: 770\n",
      "    Predictions | Train loss: 0.9120694398880005 | Test loss: 13.207785606384277\n",
      "    Forecasts | Train loss: 0.07766981422901154\n",
      "Epoch: 780\n",
      "    Predictions | Train loss: 0.8284409046173096 | Test loss: 12.800769805908203\n",
      "    Forecasts | Train loss: 0.06642172485589981\n",
      "Epoch: 790\n",
      "    Predictions | Train loss: 0.7507333755493164 | Test loss: 12.325057029724121\n",
      "    Forecasts | Train loss: 0.056723129004240036\n",
      "Epoch: 800\n",
      "    Predictions | Train loss: 0.6799678802490234 | Test loss: 11.872808456420898\n",
      "    Forecasts | Train loss: 0.04843020439147949\n",
      "Epoch: 810\n",
      "    Predictions | Train loss: 0.6150070428848267 | Test loss: 11.534883499145508\n",
      "    Forecasts | Train loss: 0.04128525033593178\n",
      "Epoch: 820\n",
      "    Predictions | Train loss: 0.5554491877555847 | Test loss: 11.126672744750977\n",
      "    Forecasts | Train loss: 0.03518802300095558\n",
      "Epoch: 830\n",
      "    Predictions | Train loss: 0.5012587904930115 | Test loss: 10.807210922241211\n",
      "    Forecasts | Train loss: 0.02995302341878414\n",
      "Epoch: 840\n",
      "    Predictions | Train loss: 0.45142871141433716 | Test loss: 10.479005813598633\n",
      "    Forecasts | Train loss: 0.02549450658261776\n",
      "Epoch: 850\n",
      "    Predictions | Train loss: 0.4065997004508972 | Test loss: 10.243034362792969\n",
      "    Forecasts | Train loss: 0.021668532863259315\n",
      "Epoch: 860\n",
      "    Predictions | Train loss: 0.3650517463684082 | Test loss: 9.89944076538086\n",
      "    Forecasts | Train loss: 0.018408680334687233\n",
      "Epoch: 870\n",
      "    Predictions | Train loss: 0.32771021127700806 | Test loss: 9.645268440246582\n",
      "    Forecasts | Train loss: 0.015628818422555923\n",
      "Epoch: 880\n",
      "    Predictions | Train loss: 0.29373347759246826 | Test loss: 9.419744491577148\n",
      "    Forecasts | Train loss: 0.013256097212433815\n",
      "Epoch: 890\n",
      "    Predictions | Train loss: 0.2629369795322418 | Test loss: 9.18544864654541\n",
      "    Forecasts | Train loss: 0.01123806182295084\n",
      "Epoch: 900\n",
      "    Predictions | Train loss: 0.23514115810394287 | Test loss: 8.9833345413208\n",
      "    Forecasts | Train loss: 0.009521989151835442\n",
      "Epoch: 910\n",
      "    Predictions | Train loss: 0.20989422500133514 | Test loss: 8.741419792175293\n",
      "    Forecasts | Train loss: 0.008071204647421837\n",
      "Epoch: 920\n",
      "    Predictions | Train loss: 0.18724337220191956 | Test loss: 8.571993827819824\n",
      "    Forecasts | Train loss: 0.006820416543632746\n",
      "Epoch: 930\n",
      "    Predictions | Train loss: 0.16668710112571716 | Test loss: 8.386804580688477\n",
      "    Forecasts | Train loss: 0.005765839479863644\n",
      "Epoch: 940\n",
      "    Predictions | Train loss: 0.14835040271282196 | Test loss: 8.25186824798584\n",
      "    Forecasts | Train loss: 0.004870728589594364\n",
      "Epoch: 950\n",
      "    Predictions | Train loss: 0.13168954849243164 | Test loss: 8.085481643676758\n",
      "    Forecasts | Train loss: 0.004112122114747763\n",
      "Epoch: 960\n",
      "    Predictions | Train loss: 0.11684966087341309 | Test loss: 7.92185115814209\n",
      "    Forecasts | Train loss: 0.0034691165201365948\n",
      "Epoch: 970\n",
      "    Predictions | Train loss: 0.10356105864048004 | Test loss: 7.809459209442139\n",
      "    Forecasts | Train loss: 0.0029240113217383623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1405/2000 [00:00<00:00, 2355.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 980\n",
      "    Predictions | Train loss: 0.09159791469573975 | Test loss: 7.666587829589844\n",
      "    Forecasts | Train loss: 0.002462598495185375\n",
      "Epoch: 990\n",
      "    Predictions | Train loss: 0.08100102841854095 | Test loss: 7.571208477020264\n",
      "    Forecasts | Train loss: 0.0020720355678349733\n",
      "Epoch: 1000\n",
      "    Predictions | Train loss: 0.07144390046596527 | Test loss: 7.4520368576049805\n",
      "    Forecasts | Train loss: 0.0017416926566511393\n",
      "Epoch: 1010\n",
      "    Predictions | Train loss: 0.06300245225429535 | Test loss: 7.3583455085754395\n",
      "    Forecasts | Train loss: 0.0014627411728724837\n",
      "Epoch: 1020\n",
      "    Predictions | Train loss: 0.05545007437467575 | Test loss: 7.266138553619385\n",
      "    Forecasts | Train loss: 0.0012275691842660308\n",
      "Epoch: 1030\n",
      "    Predictions | Train loss: 0.048756152391433716 | Test loss: 7.165471076965332\n",
      "    Forecasts | Train loss: 0.001029315171763301\n",
      "Epoch: 1040\n",
      "    Predictions | Train loss: 0.04285266995429993 | Test loss: 7.096758842468262\n",
      "    Forecasts | Train loss: 0.0008622694876976311\n",
      "Epoch: 1050\n",
      "    Predictions | Train loss: 0.03756342828273773 | Test loss: 7.008942127227783\n",
      "    Forecasts | Train loss: 0.0007217393140308559\n",
      "Epoch: 1060\n",
      "    Predictions | Train loss: 0.0329219214618206 | Test loss: 6.935644149780273\n",
      "    Forecasts | Train loss: 0.0006032058736309409\n",
      "Epoch: 1070\n",
      "    Predictions | Train loss: 0.028809290379285812 | Test loss: 6.876443386077881\n",
      "    Forecasts | Train loss: 0.0005037889932282269\n",
      "Epoch: 1080\n",
      "    Predictions | Train loss: 0.025177249684929848 | Test loss: 6.8071746826171875\n",
      "    Forecasts | Train loss: 0.0004205807053949684\n",
      "Epoch: 1090\n",
      "    Predictions | Train loss: 0.021995000541210175 | Test loss: 6.758984565734863\n",
      "    Forecasts | Train loss: 0.0003503805201034993\n",
      "Epoch: 1100\n",
      "    Predictions | Train loss: 0.01917148195207119 | Test loss: 6.704415321350098\n",
      "    Forecasts | Train loss: 0.00029136912780813873\n",
      "Epoch: 1110\n",
      "    Predictions | Train loss: 0.01670769788324833 | Test loss: 6.653388023376465\n",
      "    Forecasts | Train loss: 0.00024220030172728002\n",
      "Epoch: 1120\n",
      "    Predictions | Train loss: 0.01454263087362051 | Test loss: 6.60696268081665\n",
      "    Forecasts | Train loss: 0.00020114475046284497\n",
      "Epoch: 1130\n",
      "    Predictions | Train loss: 0.012641625478863716 | Test loss: 6.564182758331299\n",
      "    Forecasts | Train loss: 0.0001668869226705283\n",
      "Epoch: 1140\n",
      "    Predictions | Train loss: 0.010988976806402206 | Test loss: 6.532947063446045\n",
      "    Forecasts | Train loss: 0.00013818775187246501\n",
      "Epoch: 1150\n",
      "    Predictions | Train loss: 0.009532883763313293 | Test loss: 6.493281364440918\n",
      "    Forecasts | Train loss: 0.0001142945111496374\n",
      "Epoch: 1160\n",
      "    Predictions | Train loss: 0.008267965167760849 | Test loss: 6.4538798332214355\n",
      "    Forecasts | Train loss: 9.44177809287794e-05\n",
      "Epoch: 1170\n",
      "    Predictions | Train loss: 0.007168191950768232 | Test loss: 6.423590183258057\n",
      "    Forecasts | Train loss: 7.791412645019591e-05\n",
      "Epoch: 1180\n",
      "    Predictions | Train loss: 0.00620812876150012 | Test loss: 6.397737503051758\n",
      "    Forecasts | Train loss: 6.425550964195281e-05\n",
      "Epoch: 1190\n",
      "    Predictions | Train loss: 0.005374881438910961 | Test loss: 6.368642807006836\n",
      "    Forecasts | Train loss: 5.2834169764537364e-05\n",
      "Epoch: 1200\n",
      "    Predictions | Train loss: 0.004654258023947477 | Test loss: 6.342220306396484\n",
      "    Forecasts | Train loss: 4.3447809730423614e-05\n",
      "Epoch: 1210\n",
      "    Predictions | Train loss: 0.004027822986245155 | Test loss: 6.320224761962891\n",
      "    Forecasts | Train loss: 3.5605022276286036e-05\n",
      "Epoch: 1220\n",
      "    Predictions | Train loss: 0.003488713875412941 | Test loss: 6.296860218048096\n",
      "    Forecasts | Train loss: 2.9195845854701474e-05\n",
      "Epoch: 1230\n",
      "    Predictions | Train loss: 0.0030171056278049946 | Test loss: 6.2779154777526855\n",
      "    Forecasts | Train loss: 2.3918584702187218e-05\n",
      "Epoch: 1240\n",
      "    Predictions | Train loss: 0.00261433026753366 | Test loss: 6.259437561035156\n",
      "    Forecasts | Train loss: 1.9558883650461212e-05\n",
      "Epoch: 1250\n",
      "    Predictions | Train loss: 0.002265774644911289 | Test loss: 6.241584777832031\n",
      "    Forecasts | Train loss: 1.5910140064079314e-05\n",
      "Epoch: 1260\n",
      "    Predictions | Train loss: 0.0019660689868032932 | Test loss: 6.226617336273193\n",
      "    Forecasts | Train loss: 1.2981469808437396e-05\n",
      "Epoch: 1270\n",
      "    Predictions | Train loss: 0.0017081816913560033 | Test loss: 6.211958408355713\n",
      "    Forecasts | Train loss: 1.0558549547567964e-05\n",
      "Epoch: 1280\n",
      "    Predictions | Train loss: 0.0014874425251036882 | Test loss: 6.197777271270752\n",
      "    Forecasts | Train loss: 8.573520062782336e-06\n",
      "Epoch: 1290\n",
      "    Predictions | Train loss: 0.0012984329368919134 | Test loss: 6.184396266937256\n",
      "    Forecasts | Train loss: 6.948567261133576e-06\n",
      "Epoch: 1300\n",
      "    Predictions | Train loss: 0.0011364613892510533 | Test loss: 6.172599792480469\n",
      "    Forecasts | Train loss: 5.642601081490284e-06\n",
      "Epoch: 1310\n",
      "    Predictions | Train loss: 0.000997584662400186 | Test loss: 6.161481857299805\n",
      "    Forecasts | Train loss: 4.552040081762243e-06\n",
      "Epoch: 1320\n",
      "    Predictions | Train loss: 0.0008796667098067701 | Test loss: 6.151383399963379\n",
      "    Forecasts | Train loss: 3.6740079849550966e-06\n",
      "Epoch: 1330\n",
      "    Predictions | Train loss: 0.0007785891066305339 | Test loss: 6.140378475189209\n",
      "    Forecasts | Train loss: 2.972439688164741e-06\n",
      "Epoch: 1340\n",
      "    Predictions | Train loss: 0.000692752015311271 | Test loss: 6.131960868835449\n",
      "    Forecasts | Train loss: 2.3816246539354324e-06\n",
      "Epoch: 1350\n",
      "    Predictions | Train loss: 0.0006194474408403039 | Test loss: 6.125321388244629\n",
      "    Forecasts | Train loss: 1.9088504359388025e-06\n",
      "Epoch: 1360\n",
      "    Predictions | Train loss: 0.000557322462555021 | Test loss: 6.118068695068359\n",
      "    Forecasts | Train loss: 1.5407974842673866e-06\n",
      "Epoch: 1370\n",
      "    Predictions | Train loss: 0.0005048129823990166 | Test loss: 6.111109256744385\n",
      "    Forecasts | Train loss: 1.2174917856100365e-06\n",
      "Epoch: 1380\n",
      "    Predictions | Train loss: 0.000459860049886629 | Test loss: 6.1057233810424805\n",
      "    Forecasts | Train loss: 9.88011038316472e-07\n",
      "Epoch: 1390\n",
      "    Predictions | Train loss: 0.00042093233787454665 | Test loss: 6.102556228637695\n",
      "    Forecasts | Train loss: 7.877679308876395e-07\n",
      "Epoch: 1400\n",
      "    Predictions | Train loss: 0.0003873294044751674 | Test loss: 6.101799964904785\n",
      "    Forecasts | Train loss: 6.282687650127627e-07\n",
      "Epoch: 1410\n",
      "    Predictions | Train loss: 0.00035763837513513863 | Test loss: 6.101802825927734\n",
      "    Forecasts | Train loss: 4.994261075808026e-07\n",
      "Epoch: 1420\n",
      "    Predictions | Train loss: 0.0003315493813715875 | Test loss: 6.101499080657959\n",
      "    Forecasts | Train loss: 3.9679434848949313e-07\n",
      "Epoch: 1430\n",
      "    Predictions | Train loss: 0.00030864804284647107 | Test loss: 6.100888252258301\n",
      "    Forecasts | Train loss: 3.1424860935658216e-07\n",
      "Epoch: 1440\n",
      "    Predictions | Train loss: 0.0002884107525460422 | Test loss: 6.100037097930908\n",
      "    Forecasts | Train loss: 2.4910406182243605e-07\n",
      "Epoch: 1450\n",
      "    Predictions | Train loss: 0.00027065182803198695 | Test loss: 6.099231719970703\n",
      "    Forecasts | Train loss: 1.9908911497168447e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1887/2000 [00:00<00:00, 2382.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1460\n",
      "    Predictions | Train loss: 0.0002548148622736335 | Test loss: 6.098480224609375\n",
      "    Forecasts | Train loss: 1.54247388195472e-07\n",
      "Epoch: 1470\n",
      "    Predictions | Train loss: 0.00024084217147901654 | Test loss: 6.097908020019531\n",
      "    Forecasts | Train loss: 1.231179282967787e-07\n",
      "Epoch: 1480\n",
      "    Predictions | Train loss: 0.00022865259961690754 | Test loss: 6.097314357757568\n",
      "    Forecasts | Train loss: 9.727373395662653e-08\n",
      "Epoch: 1490\n",
      "    Predictions | Train loss: 0.00021770462626591325 | Test loss: 6.096795558929443\n",
      "    Forecasts | Train loss: 7.674388768919016e-08\n",
      "Epoch: 1500\n",
      "    Predictions | Train loss: 0.00020806703832931817 | Test loss: 6.096225738525391\n",
      "    Forecasts | Train loss: 5.861074825475043e-08\n",
      "Epoch: 1510\n",
      "    Predictions | Train loss: 0.00019957330368924886 | Test loss: 6.0957231521606445\n",
      "    Forecasts | Train loss: 4.5748311805482444e-08\n",
      "Epoch: 1520\n",
      "    Predictions | Train loss: 0.00019201880786567926 | Test loss: 6.095250129699707\n",
      "    Forecasts | Train loss: 3.707391371676749e-08\n",
      "Epoch: 1530\n",
      "    Predictions | Train loss: 0.00018548639491200447 | Test loss: 6.094778060913086\n",
      "    Forecasts | Train loss: 2.8393696283046665e-08\n",
      "Epoch: 1540\n",
      "    Predictions | Train loss: 0.0001795131538528949 | Test loss: 6.094379425048828\n",
      "    Forecasts | Train loss: 2.21698428504169e-08\n",
      "Epoch: 1550\n",
      "    Predictions | Train loss: 0.0001743768953019753 | Test loss: 6.093907833099365\n",
      "    Forecasts | Train loss: 1.7683486674968663e-08\n",
      "Epoch: 1560\n",
      "    Predictions | Train loss: 0.00016962057270575315 | Test loss: 6.0935468673706055\n",
      "    Forecasts | Train loss: 1.3827230027629867e-08\n",
      "Epoch: 1570\n",
      "    Predictions | Train loss: 0.00016561693337280303 | Test loss: 6.093149185180664\n",
      "    Forecasts | Train loss: 1.075823075069593e-08\n",
      "Epoch: 1580\n",
      "    Predictions | Train loss: 0.00016202780534513295 | Test loss: 6.09284782409668\n",
      "    Forecasts | Train loss: 8.606003021327524e-09\n",
      "Epoch: 1590\n",
      "    Predictions | Train loss: 0.00015877866826485842 | Test loss: 6.092531204223633\n",
      "    Forecasts | Train loss: 7.264316259636416e-09\n",
      "Epoch: 1600\n",
      "    Predictions | Train loss: 0.00015604931104462594 | Test loss: 6.092266082763672\n",
      "    Forecasts | Train loss: 5.579204209738009e-09\n",
      "Epoch: 1610\n",
      "    Predictions | Train loss: 0.00015351464389823377 | Test loss: 6.091913223266602\n",
      "    Forecasts | Train loss: 4.480534609996312e-09\n",
      "Epoch: 1620\n",
      "    Predictions | Train loss: 0.0001512725866632536 | Test loss: 6.091663360595703\n",
      "    Forecasts | Train loss: 3.627792510840777e-09\n",
      "Epoch: 1630\n",
      "    Predictions | Train loss: 0.00014935978106223047 | Test loss: 6.091427803039551\n",
      "    Forecasts | Train loss: 3.0719093935260844e-09\n",
      "Epoch: 1640\n",
      "    Predictions | Train loss: 0.00014757498865947127 | Test loss: 6.091192722320557\n",
      "    Forecasts | Train loss: 2.459273673593998e-09\n",
      "Epoch: 1650\n",
      "    Predictions | Train loss: 0.00014621569425798953 | Test loss: 6.0909576416015625\n",
      "    Forecasts | Train loss: 1.9266734874179292e-09\n",
      "Epoch: 1660\n",
      "    Predictions | Train loss: 0.00014476224896498024 | Test loss: 6.090869903564453\n",
      "    Forecasts | Train loss: 1.6283593362587112e-09\n",
      "Epoch: 1670\n",
      "    Predictions | Train loss: 0.0001436359016224742 | Test loss: 6.090590476989746\n",
      "    Forecasts | Train loss: 1.3184034974855763e-09\n",
      "Epoch: 1680\n",
      "    Predictions | Train loss: 0.00014259712770581245 | Test loss: 6.090488433837891\n",
      "    Forecasts | Train loss: 1.0200892353040558e-09\n",
      "Epoch: 1690\n",
      "    Predictions | Train loss: 0.00014172334340400994 | Test loss: 6.0903120040893555\n",
      "    Forecasts | Train loss: 7.8580342233181e-10\n",
      "Epoch: 1700\n",
      "    Predictions | Train loss: 0.00014092709170654416 | Test loss: 6.090142726898193\n",
      "    Forecasts | Train loss: 7.450580707946131e-10\n",
      "Epoch: 1710\n",
      "    Predictions | Train loss: 0.00014021192328073084 | Test loss: 6.090010643005371\n",
      "    Forecasts | Train loss: 6.519257911286047e-10\n",
      "Epoch: 1720\n",
      "    Predictions | Train loss: 0.0001395223953295499 | Test loss: 6.08984899520874\n",
      "    Forecasts | Train loss: 6.199115665239674e-10\n",
      "Epoch: 1730\n",
      "    Predictions | Train loss: 0.0001389907265547663 | Test loss: 6.0897536277771\n",
      "    Forecasts | Train loss: 5.704350880542108e-10\n",
      "Epoch: 1740\n",
      "    Predictions | Train loss: 0.0001385117939207703 | Test loss: 6.089658737182617\n",
      "    Forecasts | Train loss: 5.704350880542108e-10\n",
      "Epoch: 1750\n",
      "    Predictions | Train loss: 0.00013800847227685153 | Test loss: 6.089540958404541\n",
      "    Forecasts | Train loss: 5.704350880542108e-10\n",
      "Epoch: 1760\n",
      "    Predictions | Train loss: 0.00013762332673650235 | Test loss: 6.089408874511719\n",
      "    Forecasts | Train loss: 5.704350880542108e-10\n",
      "Epoch: 1770\n",
      "    Predictions | Train loss: 0.00013730692444369197 | Test loss: 6.0893425941467285\n",
      "    Forecasts | Train loss: 5.122274271407434e-10\n",
      "Epoch: 1780\n",
      "    Predictions | Train loss: 0.00013700290583074093 | Test loss: 6.089254379272461\n",
      "    Forecasts | Train loss: 4.758476390698263e-10\n",
      "Epoch: 1790\n",
      "    Predictions | Train loss: 0.000136763381306082 | Test loss: 6.089240550994873\n",
      "    Forecasts | Train loss: 4.758476390698263e-10\n",
      "Epoch: 1800\n",
      "    Predictions | Train loss: 0.0001363945921184495 | Test loss: 6.089174270629883\n",
      "    Forecasts | Train loss: 4.758476390698263e-10\n",
      "Epoch: 1810\n",
      "    Predictions | Train loss: 0.0001362029870506376 | Test loss: 6.089093208312988\n",
      "    Forecasts | Train loss: 4.758476390698263e-10\n",
      "Epoch: 1820\n",
      "    Predictions | Train loss: 0.00013601401587948203 | Test loss: 6.0890421867370605\n",
      "    Forecasts | Train loss: 4.3946785099890917e-10\n",
      "Epoch: 1830\n",
      "    Predictions | Train loss: 0.00013591934111900628 | Test loss: 6.08897590637207\n",
      "    Forecasts | Train loss: 4.976755119123766e-10\n",
      "Epoch: 1840\n",
      "    Predictions | Train loss: 0.0001356536231469363 | Test loss: 6.088961601257324\n",
      "    Forecasts | Train loss: 4.903995542981932e-10\n",
      "Epoch: 1850\n",
      "    Predictions | Train loss: 0.00013557389320340008 | Test loss: 6.088872909545898\n",
      "    Forecasts | Train loss: 4.3946785099890917e-10\n",
      "Epoch: 1860\n",
      "    Predictions | Train loss: 0.00013536543701775372 | Test loss: 6.088814735412598\n",
      "    Forecasts | Train loss: 4.700268507740191e-10\n",
      "Epoch: 1870\n",
      "    Predictions | Train loss: 0.00013509354903362691 | Test loss: 6.088881015777588\n",
      "    Forecasts | Train loss: 4.452886115391408e-10\n",
      "Epoch: 1880\n",
      "    Predictions | Train loss: 0.0001350318780168891 | Test loss: 6.088837146759033\n",
      "    Forecasts | Train loss: 4.249159357705423e-10\n",
      "Epoch: 1890\n",
      "    Predictions | Train loss: 0.00013499442138709128 | Test loss: 6.088837623596191\n",
      "    Forecasts | Train loss: 4.0308806292799204e-10\n",
      "Epoch: 1900\n",
      "    Predictions | Train loss: 0.0001348460209555924 | Test loss: 6.088845252990723\n",
      "    Forecasts | Train loss: 3.914465140919532e-10\n",
      "Epoch: 1910\n",
      "    Predictions | Train loss: 0.00013471530110109597 | Test loss: 6.088852405548096\n",
      "    Forecasts | Train loss: 3.92901711165905e-10\n",
      "Epoch: 1920\n",
      "    Predictions | Train loss: 0.00013457749446388334 | Test loss: 6.088793754577637\n",
      "    Forecasts | Train loss: 4.0454323224636823e-10\n",
      "Epoch: 1930\n",
      "    Predictions | Train loss: 0.0001344808842986822 | Test loss: 6.0887861251831055\n",
      "    Forecasts | Train loss: 3.594323172428915e-10\n",
      "Epoch: 1940\n",
      "    Predictions | Train loss: 0.0001343253388768062 | Test loss: 6.088771343231201\n",
      "    Forecasts | Train loss: 3.92901711165905e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2352.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1950\n",
      "    Predictions | Train loss: 0.00013431679690256715 | Test loss: 6.088793754577637\n",
      "    Forecasts | Train loss: 3.434252049405728e-10\n",
      "Epoch: 1960\n",
      "    Predictions | Train loss: 0.00013421641779132187 | Test loss: 6.088823318481445\n",
      "    Forecasts | Train loss: 3.1868693795011893e-10\n",
      "Epoch: 1970\n",
      "    Predictions | Train loss: 0.0001340676099061966 | Test loss: 6.088793754577637\n",
      "    Forecasts | Train loss: 2.9685906510756865e-10\n",
      "Epoch: 1980\n",
      "    Predictions | Train loss: 0.00013398198643699288 | Test loss: 6.088809013366699\n",
      "    Forecasts | Train loss: 2.721208258726904e-10\n",
      "Epoch: 1990\n",
      "    Predictions | Train loss: 0.00013394173583947122 | Test loss: 6.088846206665039\n",
      "    Forecasts | Train loss: 2.721208258726904e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# #times to loop through the training\n",
    "# Hyperparameter\n",
    "epochs = 2000\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "predict_optimizer = torch.optim.Adam(mlp_predict_model.parameters())\n",
    "predict_configs = [criterion, predict_optimizer]\n",
    "\n",
    "forecast_optimizer = torch.optim.Adam(mlp_forecast_model.parameters())\n",
    "forecast_configs = [criterion, forecast_optimizer]\n",
    "\n",
    "# Track different setups (ie: lr, etc) to compare this experiment to future experiments\n",
    "epoch_count = []\n",
    "train_pred_values = []\n",
    "test_pred_values = []\n",
    "\n",
    "predict_train_loss_values = []\n",
    "predict_test_loss_values = []\n",
    "\n",
    "forecast_train_loss_values = []\n",
    "forecast_test_loss_values = []\n",
    "\n",
    "### Training\n",
    "# 0. Loop through the training\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # In-Sample Prediction\n",
    "    train_predictions, predict_train_loss = mlp_predict_model.train_model(predict_X_train_df, predict_y_train_df, predict_configs)\n",
    "    test_predictions, predict_test_loss = mlp_predict_model.interpolate_predictions(predict_X_test_df, predict_y_test_df, predict_configs)\n",
    "    \n",
    "    # Out-Sample Forecasts\n",
    "    train_forecasts, forecast_train_loss = mlp_forecast_model.train_model(forecast_X_train_df, forecast_y_train_df, forecast_configs)\n",
    "    test_forecasts = mlp_forecast_model.extrapolate_forecasts(forecast_X_test_df)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "\n",
    "        print(f\"    Predictions | Train loss: {predict_train_loss} | Test loss: {predict_test_loss}\")\n",
    "        # print(f\"    Predictions Parameters: {mlp_predict_model.state_dict()}\")\n",
    "        predict_train_loss_values.append(predict_train_loss)\n",
    "        predict_test_loss_values.append(predict_test_loss)\n",
    "\n",
    "        print(f\"    Forecasts | Train loss: {forecast_train_loss}\")\n",
    "        # print(f\"    Forecasts Parameters: {mlp_forecast_model.state_dict()}\")\n",
    "        forecast_train_loss_values.append(forecast_train_loss)\n",
    "        # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7683feae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 6.089\n"
     ]
    }
   ],
   "source": [
    "EvaluationMetric.eval_mse(predict_y_test_df, test_predictions, False) # Matches Test MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "51305f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curves\n",
    "plt.plot(epoch_count, np.array(torch.tensor(predict_train_loss_values).numpy()), label=\"Predict train loss\")\n",
    "plt.plot(epoch_count, predict_test_loss_values, label=\"Predict test loss\")\n",
    "\n",
    "plt.plot(epoch_count, np.array(torch.tensor(forecast_train_loss_values).numpy()), label=\"Forecast train loss\")\n",
    "\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c93aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c980c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b5822e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
